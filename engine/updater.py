import pandas as pd
import time
from datetime import datetime, timedelta
from sqlalchemy import text
from interface.tushare_client import ts_client
from database.models import (
    SessionLocal, StockBasic, Watchlist, 
    ODSMarketDaily, ODSAdjFactor, ODSFinanceReport, 
    DWSMarketIndicators, DWSFinanceStd, ODSDailyBasic
)
from core.mapping import SOURCE_TABLE_MAP

class DataUpdater:
    def __init__(self):
        self.db = SessionLocal()

    def close(self):
        self.db.close()

    def _get_universe_pool(self) -> set:
        """[PRD 1.2] è·å–ä¸­è¯800+è‡ªé€‰è‚¡çš„å¹¶é›†"""
        csi800 = self.db.query(StockBasic.ts_code).filter(StockBasic.is_csi800 == True).all()
        watchlist = self.db.query(Watchlist.ts_code).all()
        pool = {row.ts_code for row in csi800} | {row.ts_code for row in watchlist}
        return pool

    def sync_stock_list(self):
        """[PRD 3.1] å…¨é‡åŒæ­¥è‚¡ç¥¨åˆ—è¡¨å¹¶æ ‡è®°ä¸­è¯800"""
        print("ğŸ”„ Syncing Stock List...")
        df_basics = ts_client.fetch_stock_basic()
        if df_basics.empty: return

        # Mark CSI 800
        try:
            now_str = datetime.now().strftime("%Y%m%d")
            df_csi800 = ts_client.pro.index_weight(index_code='000906.SH', start_date='20240101', end_date=now_str)
            
            if not df_csi800.empty:
                latest_date = df_csi800['trade_date'].max()
                df_latest = df_csi800[df_csi800['trade_date'] == latest_date]
                csi800_set = set(df_latest['con_code'].tolist())
            else:
                csi800_set = set()
        except Exception as e:
            print(f"âš ï¸ CSI800 Fetch Error: {e}")
            csi800_set = set()

        # Processing
        df_basics['is_csi800'] = False
        if csi800_set:
            df_basics.loc[df_basics['ts_code'].isin(csi800_set), 'is_csi800'] = True

        # Upsert Logic
        for _, row in df_basics.iterrows():
            stock = StockBasic(
                ts_code=row['ts_code'],
                symbol=row['symbol'],
                name=row['name'],
                area=row['area'],
                industry=row['industry'],
                market=row['market'],
                list_date=row['list_date'],
                is_csi800=row['is_csi800']
            )
            self.db.merge(stock)
        
        self.db.commit()
        print(f"âœ… Stock List Synced. CSI800 Count: {len(csi800_set)}")

    # --- åœºæ™¯ S1/S2/S5: å‚ç›´å†å²å›æº¯ (æŒ‰ä»£ç åŒæ­¥) ---

    def sync_stock_history(self, ts_code: str, start_date="20150101"):
        """è¡¥å…¨å•åªè‚¡ç¥¨çš„æ‰€æœ‰å†å²æ•°æ® (è¡Œæƒ…+è´¢æŠ¥)"""
        # 1. è¡Œæƒ…ä¸å¤æƒå› å­ [cite: 15-16]
        df_daily = ts_client.fetch_daily(ts_code=ts_code, start_date=start_date)
        df_adj = ts_client.fetch_adj_factor(ts_code=ts_code, start_date=start_date)
        
        if not df_daily.empty:
            for _, row in df_daily.iterrows():
                self.db.merge(ODSMarketDaily(
                    ts_code=row['ts_code'], trade_date=row['trade_date'],
                    open=row['open'], high=row['high'], low=row['low'], close=row['close'],
                    pre_close=row['pre_close'], change=row['change'], pct_chg=row['pct_chg'],
                    vol=row['vol'], amount=row['amount']
                ))

        if not df_adj.empty:
            for _, row in df_adj.iterrows():
                self.db.merge(ODSAdjFactor(ts_code=row['ts_code'], trade_date=row['trade_date'], adj_factor=row['adj_factor']))

        # 1.1 æ¯æ—¥æŒ‡æ ‡ (PE/PB/å¸‚å€¼)
        self.sync_daily_basic(ts_code, start_date)

        # 2. å››å¤§è´¢æŠ¥åŒæ­¥ (JSONB å­˜å‚¨) [cite: 90-95]
        tasks = {
            "income": ts_client.fetch_income,
            "balancesheet": ts_client.fetch_balancesheet,
            "cashflow": ts_client.fetch_cashflow,
            "fina_indicator": ts_client.fetch_fina_indicator
        }
        for category, api_func in tasks.items():
            df = api_func(ts_code=ts_code, start_date=start_date)
            if not df.empty:
                # --- æ ¸å¿ƒä¿®å¤ï¼šå†…å­˜é¢„å»é‡ ---
                # å®šä¹‰æˆ‘ä»¬çš„äº”ç»´ä¸»é”® (category åœ¨å¾ªç¯ä¸­å›ºå®š)
                pk_cols = ['ts_code', 'end_date', 'report_type', 'update_flag']
                # Tushare æ¥å£è¿”å›çš„å­—æ®µåå¯èƒ½ç•¥æœ‰ä¸åŒï¼Œå…ˆåšä¸ªå®‰å…¨æ£€æŸ¥
                actual_pk = [c for c in pk_cols if c in df.columns]
                # æ ¹æ®ä¸»é”®å»é‡ï¼Œä¿ç•™æœ€åä¸€æ¡ï¼ˆé€šå¸¸æ˜¯æœ€æ–°çš„ï¼‰
                df = df.drop_duplicates(subset=actual_pk, keep='last')

                df = df.astype(object).where(pd.notnull(df), None)
                for record in df.to_dict('records'):
                    self.db.merge(ODSFinanceReport(
                        ts_code=record['ts_code'], end_date=record['end_date'],
                        report_type=record.get('report_type', '1'),
                        update_flag=record.get('update_flag', '0'),
                        category=category, data=record, ann_date=record.get('ann_date')
                    ))
                # æ¯ä¸€ç±»æŠ¥è¡¨æäº¤ä¸€æ¬¡ï¼Œç¼©å°å†²çªèŒƒå›´å¹¶æå‡è°ƒè¯•æ•ˆç‡
                self.db.commit()

    def sync_daily_basic(self, ts_code: str, start_date: str):
        """åŒæ­¥ ODS å±‚æ¯æ—¥æŒ‡æ ‡"""
        df = ts_client.pro.daily_basic(ts_code=ts_code, start_date=start_date)
        if df.empty: return
        
        for _, row in df.iterrows():
            self.db.merge(ODSDailyBasic(
                ts_code=row['ts_code'],
                trade_date=row['trade_date'],
                pe_ttm=row.get('pe_ttm'),
                pb=row.get('pb'),
                turnover_rate=row.get('turnover_rate'),
                total_mv=row.get('total_mv')
            ))
        self.db.commit()

    # --- åœºæ™¯ S3: æ°´å¹³æ¯æ—¥è¡Œæƒ… (æŒ‰æ—¥æœŸåŒæ­¥) ---

    def sync_daily_market(self, trade_date: str):
        """[PRD S3] æ¯æ—¥å¢é‡è¡Œæƒ…åŒæ­¥ (æ°´å¹³æ¨¡å¼)"""
        universe = self._get_universe_pool()
        if not universe: return

        try:
            # 1. Fetch Full Market
            df_daily = ts_client.fetch_daily(trade_date=trade_date)
            df_adj = ts_client.fetch_adj_factor(trade_date=trade_date)
            
            if df_daily.empty: return

            # 2. Funnel Filter
            df_daily_filtered = df_daily[df_daily['ts_code'].isin(universe)]
            
            # 3. Save ODS
            for _, row in df_daily_filtered.iterrows():
                self.db.merge(ODSMarketDaily(
                    ts_code=row['ts_code'], trade_date=row['trade_date'],
                    open=row['open'], high=row['high'], low=row['low'], close=row['close'],
                    pre_close=row['pre_close'], change=row['change'], pct_chg=row['pct_chg'],
                    vol=row['vol'], amount=row['amount']
                ))

            if not df_adj.empty:
                df_adj_filtered = df_adj[df_adj['ts_code'].isin(universe)]
                for _, row in df_adj_filtered.iterrows():
                    self.db.merge(ODSAdjFactor(
                        ts_code=row['ts_code'], trade_date=row['trade_date'],
                        adj_factor=row['adj_factor']
                    ))

            self.db.commit()
            print(f"  âœ… Market Snapshot {trade_date}: Saved {len(df_daily_filtered)} records.")

        except Exception as e:
            self.db.rollback()
            print(f"  âŒ Market Snapshot Failed: {e}")

    # --- åœºæ™¯ S4: æ°´å¹³æ¯æ—¥è´¢æŠ¥ (æŒ‰å…¬å‘Šæ—¥åŒæ­¥) ---

    def sync_financial_daily(self, ann_date: str):
        """
        [PRD S4 ä¿®æ­£ç‰ˆ] æ¯æ—¥å¢é‡è´¢æŠ¥åŒæ­¥
        é’ˆå¯¹ 2000 ç§¯åˆ†ä¼˜åŒ–ï¼šé€šè¿‡æŠ«éœ²è®¡åˆ’åæŸ¥ä¸ªè‚¡ï¼Œé¿å…å…¨å¸‚åœºæ‹‰å–æŠ¥é”™
        """
        universe = self._get_universe_pool()
        if not universe:
            return

        try:
            # 1. è·å–å½“æ—¥å®é™…æŠ«éœ²è´¢æŠ¥çš„åå• (actual_date)
            # Ref: Tushare PDF 
            df_ann = ts_client.pro.disclosure_date(actual_date=ann_date)
            if df_ann.empty:
                yield f"  â˜• {ann_date} æ— è´¢æŠ¥æŠ«éœ²ã€‚"
                return

            # 2. ç­›é€‰å‡ºå±äºæˆ‘ä»¬ Universe çš„æ ‡çš„
            targets = df_ann[df_ann['ts_code'].isin(universe)]['ts_code'].unique().tolist()
            
            if not targets:
                yield f"  â˜• {ann_date} æŠ«éœ²çš„ {len(df_ann)} å®¶å…¬å¸å‡ä¸åœ¨æ ¸å¿ƒæ± ä¸­ã€‚"
                return

            yield f"  ğŸ“¢ å‘ç° {len(targets)} åªæ ¸å¿ƒæ ‡çš„æŠ«éœ²è´¢æŠ¥ï¼Œå¼€å§‹ç²¾å‡†åŒæ­¥..."

            # 3. é€ä¸ªåŒæ­¥ä¸ªè‚¡è´¢æŠ¥ (å¤ç”¨ S1/S2 çš„å‚ç›´åŒæ­¥é€»è¾‘)
            for i, ts_code in enumerate(targets):
                yield f"    > [{i+1}/{len(targets)}] åŒæ­¥è´¢æŠ¥: {ts_code}"
                # æ­¤å¤„ä»…åŒæ­¥å…¬å‘Šæ—¥å‰åçš„æ•°æ®å³å¯ï¼Œä¸ºä¿é™©èµ·è§åŒæ­¥æœ€è¿‘ä¸€å¹´
                # start_date è®¾ä¸ºå…¬å‘Šæ—¥å‰ä¸€å¹´
                sync_start = (datetime.strptime(ann_date, "%Y%m%d") - timedelta(days=365)).strftime("%Y%m%d")
                self.sync_stock_history(ts_code, start_date=sync_start)
                
                # é¢‘æ¬¡ä¿æŠ¤
                time.sleep(0.2)

            self.db.commit()
            yield f"  âœ… {ann_date} è´¢æŠ¥å¢é‡åŒæ­¥å®Œæˆã€‚"

        except Exception as e:
            self.db.rollback()
            yield f"  âŒ è´¢æŠ¥å¢é‡åŒæ­¥å¤±è´¥: {str(e)}"

    # --- DWS è®¡ç®—é€»è¾‘ ---

    def process_market_dws(self, ts_code: str):
        """DWS: è®¡ç®—å‡çº¿ã€QFQ å¹¶è¡¥å…¨åŸºæœ¬é¢æŒ‡æ ‡"""
        # 1. è”åˆæŸ¥è¯¢ ODS è¡Œæƒ…å’Œæ¯æ—¥æŒ‡æ ‡ (daily_basic)
        query = text("""
            SELECT m.*, b.pe_ttm, b.pb, b.total_mv, b.turnover_rate, a.adj_factor
            FROM ods_market_daily m
            LEFT JOIN ods_daily_basic b ON m.ts_code = b.ts_code AND m.trade_date = b.trade_date
            LEFT JOIN ods_adj_factor a ON m.ts_code = a.ts_code AND m.trade_date = a.trade_date
            WHERE m.ts_code = :ts_code
            ORDER BY m.trade_date
        """)
        
        df = pd.read_sql(query, self.db.bind, params={"ts_code": ts_code})
        if df.empty: return

        # 2. è®¡ç®—å‰å¤æƒ
        df['adj_factor'] = df['adj_factor'].ffill()
        latest_factor = df['adj_factor'].iloc[-1] if not df['adj_factor'].isnull().all() else 1.0
        df['close_qfq'] = df['close'] * (df['adj_factor'] / latest_factor)

        # 3. è®¡ç®—å‡çº¿ [cite: 843]
        for ma in [20, 50, 120, 250, 850]:
            df[f'ma_{ma}'] = df['close_qfq'].rolling(window=ma, min_periods=ma).mean()

        # 4. Upsert å†™å…¥ DWS
        for _, row in df.iterrows():
            self.db.merge(DWSMarketIndicators(
                ts_code=row['ts_code'],
                trade_date=row['trade_date'],
                pe_ttm=row.get('pe_ttm'),
                pb=row.get('pb'),
                total_mv=row.get('total_mv'),
                turnover_rate=row.get('turnover_rate'),
                close_qfq=row['close_qfq'],
                ma_20=row['ma_20'] if pd.notna(row['ma_20']) else None,
                ma_50=row['ma_50'] if pd.notna(row['ma_50']) else None,
                ma_120=row['ma_120'] if pd.notna(row['ma_120']) else None,
                ma_250=row['ma_250'] if pd.notna(row['ma_250']) else None,
                ma_850=row['ma_850'] if pd.notna(row['ma_850']) else None,
            ))
        self.db.commit()

    def process_finance_dws(self, ts_code: str):
        """DWS: æ ‡å‡†åŒ–è´¢åŠ¡ç‚¼åˆ¶ (è¡Œä¸šæ„ŸçŸ¥ç‰ˆ) [cite: 845-848]"""
        reports = self.db.query(ODSFinanceReport).filter(
            ODSFinanceReport.ts_code == ts_code,
            ODSFinanceReport.report_type == '1'
        ).all()
        
        merged = {}
        for r in reports:
            end_date = r.end_date
            if end_date not in merged:
                merged[end_date] = {"ann_date": r.ann_date}
            
            # å…³é”®ï¼šä» JSONB ä¸­æå–å­—æ®µå¹¶è¦†ç›–åˆå¹¶ [cite: 847]
            data = r.data
            for k in ['revenue', 'n_income_attr_p', 'n_cashflow_act', 'debt_to_assets', 'roe', 'grossprofit_margin']:
                if k in data and data[k] is not None:
                    merged[end_date][k] = data[k]
        
        for end_date, m in merged.items():
            # å¿…é¡»æœ‰å…¬å‘Šæ—¥æœŸæ‰èƒ½è¿›è¡Œåç»­çš„ merge_asof [cite: 847]
            if not m.get('ann_date'): continue 
            
            self.db.merge(DWSFinanceStd(
                ts_code=ts_code, end_date=end_date, ann_date=m.get('ann_date'),
                revenue=m.get('revenue'),
                n_income_attr_p=m.get('n_income_attr_p'),
                n_cashflow_act=m.get('n_cashflow_act'),
                debt_to_assets=m.get('debt_to_assets'),
                roe=m.get('roe'),
                grossprofit_margin=m.get('grossprofit_margin')
            ))
        self.db.commit()

    # --- è°ƒåº¦å™¨ (æ”¯æŒè¿›åº¦è¿”å›) ---

    def run_full_backfill(self, start_date="20150101"):
        """[PRD S5] æ ¸å¿ƒæ± è´¢åŠ¡ä¸è¡Œæƒ…å…¨é‡åˆå§‹åŒ–"""
        yield "ğŸš€ å¼€å§‹å…¨é‡å›æº¯ (Full Backfill)..."
        self.sync_stock_list()
        
        universe = list(self._get_universe_pool())
        total = len(universe)
        
        for i, ts_code in enumerate(universe):
            # ä½¿ç”¨ yield è®©å‰ç«¯ NiceGUI å¯ä»¥å®æ—¶æ›´æ–°è¿›åº¦æ¡ [cite: 107-108]
            yield f"æ­£åœ¨è¡¥å…¨ç¬¬ {i+1}/{total} åª: {ts_code}"
            try:
                self.sync_stock_history(ts_code, start_date)
                # DWS Calculation
                self.process_market_dws(ts_code)
                self.process_finance_dws(ts_code)
                time.sleep(0.1) # é¢‘æ¬¡ä¿æŠ¤
            except Exception as e:
                yield f"âš ï¸ {ts_code} åŒæ­¥å¤±è´¥: {str(e)}"
        yield "âœ… å…¨é‡å›æº¯ä»»åŠ¡å®Œæˆ"

    def run_daily_routine(self):
        """
        [PRD S3/S4 è¿›åŒ–ç‰ˆ] è‡ªåŠ¨åŒºé—´è¡¥å…¨æ—¥æ›´
        é€»è¾‘ï¼šè‡ªåŠ¨è®¡ç®—æ–­æ¡£æœŸå¹¶å¾ªç¯è¡¥å…¨ï¼Œç¡®ä¿éš”å‘¨/éš”æœˆæ›´æ–°ä¸æ¼æ•°æ®
        """
        # 1. ç¡®å®šè¡¥å…¨åŒºé—´
        # æŸ¥æ‰¾æœ¬åœ°æœ€æ–°è¡Œæƒ…æ—¥æœŸä½œä¸ºèµ·ç‚¹
        res = self.db.execute(text("SELECT max(trade_date) FROM ods_market_daily")).fetchone()
        last_date_str = res[0] if res and res[0] else "20241201" # é»˜è®¤å›æº¯èµ·ç‚¹
        
        start_date = (datetime.strptime(last_date_str, "%Y%m%d") + timedelta(days=1))
        end_date = datetime.now()
        
        # è·å–æœŸé—´æ‰€æœ‰äº¤æ˜“æ—¥ (é¿å…éäº¤æ˜“æ—¥æŠ¥é”™)
        # æ³¨æ„ï¼šè¿™é‡Œè°ƒç”¨ tushare äº¤æ˜“æ—¥å†æ¥å£
        cal = ts_client.pro.trade_cal(exchange='', start_date=start_date.strftime('%Y%m%d'), 
                                     end_date=end_date.strftime('%Y%m%d'), is_open='1')
        trade_days = cal['cal_date'].tolist()

        if not trade_days:
            yield "â˜• æ•°æ®å·²æ˜¯æœ€æ–°ï¼Œæ— éœ€æ›´æ–°ã€‚"
            return

        yield f"ğŸš€ å‘ç° {len(trade_days)} ä¸ªäº¤æ˜“æ—¥å¾…è¡¥å…¨: {trade_days[0]} -> {trade_days[-1]}"

        # 2. æ ¸å¿ƒåŒæ­¥å¾ªç¯
        for date_str in trade_days:
            yield f"ğŸ“… æ­£åœ¨å¤„ç†: {date_str} ..."
            
            # A. åŒæ­¥å…¨å¸‚åœºè¡Œæƒ… (S3) 
            self.sync_daily_market(date_str)
            
            # B. åŒæ­¥æ¯æ—¥æŒ‡æ ‡ (PE/PB/å¸‚å€¼) - ä¿®æ­£ï¼šéœ€æ‰‹åŠ¨æ·»åŠ  horizontal æ¨¡å¼
            yield f"  > æ‹‰å–æ¯æ—¥æŒ‡æ ‡ (PE/PB)..."
            df_basic = ts_client.pro.daily_basic(trade_date=date_str)
            if not df_basic.empty:
                # ä»…å­˜ universe å†…çš„
                universe = self._get_universe_pool()
                df_target = df_basic[df_basic['ts_code'].isin(universe)]
                for _, row in df_target.iterrows():
                    self.db.merge(ODSDailyBasic(
                        ts_code=row['ts_code'], trade_date=row['trade_date'],
                        pe_ttm=row.get('pe_ttm'), pb=row.get('pb'),
                        total_mv=row.get('total_mv'), turnover_rate=row.get('turnover_rate')
                    ))
            
            # C. æ£€æŸ¥å¹¶åŒæ­¥å½“æ—¥æŠ«éœ²çš„è´¢æŠ¥ (S4 ä¿®æ­£ç‰ˆ)
            # è¿™é‡Œè°ƒç”¨ä¸Šä¸€å¼ æŒ‡ä»¤å¡ä¿®å¤åçš„ sync_financial_daily
            # ç”±äº sync_financial_daily æ˜¯ç”Ÿæˆå™¨ï¼Œéœ€è¦éå†å®ƒ
            for msg in self.sync_financial_daily(date_str):
                yield f"    {msg}"
            
            self.db.commit()
            time.sleep(0.5) # 2000ç§¯åˆ†é¢‘æ¬¡ä¿æŠ¤ [cite: 345]

        # 3. ç»Ÿä¸€è§¦å‘ DWS é‡ç‚¼ [cite: 140]
        yield "ğŸ”„ æ­£åœ¨é‡æ–°ç‚¼åˆ¶ DWS è¡ç”ŸæŒ‡æ ‡..."
        universe = list(self._get_universe_pool())
        for i, ts_code in enumerate(universe):
            self.process_market_dws(ts_code)
            self.process_finance_dws(ts_code)
            if i % 100 == 0:
                yield f"  > ç‚¼åˆ¶è¿›åº¦: {i}/{len(universe)}"
        
        yield "âœ… å…¨åŒºé—´æ•°æ®è¡¥å…¨å¹¶ç‚¼åˆ¶å®Œæˆï¼"

if __name__ == "__main__":
    u = DataUpdater()
    # u.sync_stock_list()
    u.close()