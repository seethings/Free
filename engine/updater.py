import pandas as pd
import time
from datetime import datetime, timedelta
from sqlalchemy import text
from interface.tushare_client import ts_client
from database.models import (
    SessionLocal, StockBasic, Watchlist, 
    ODSMarketDaily, ODSAdjFactor, ODSFinanceReport, 
    DWSMarketIndicators, DWSFinanceStd, ODSDailyBasic
)
from core.mapping import SOURCE_TABLE_MAP

class DataUpdater:
    def __init__(self):
        self.db = SessionLocal()

    def close(self):
        self.db.close()

    def _get_universe_pool(self) -> set:
        """[PRD 1.2] è·å–ä¸­è¯800+è‡ªé€‰è‚¡çš„å¹¶é›†"""
        csi800 = self.db.query(StockBasic.ts_code).filter(StockBasic.is_csi800 == True).all()
        watchlist = self.db.query(Watchlist.ts_code).all()
        pool = {row.ts_code for row in csi800} | {row.ts_code for row in watchlist}
        return pool

    def sync_stock_list(self):
        """[PRD 3.1] å…¨é‡åŒæ­¥è‚¡ç¥¨åˆ—è¡¨å¹¶æ ‡è®°ä¸­è¯800 (UI é€‚é…ç‰ˆ)"""
        yield "ğŸ”„ æ­£åœ¨ä» Tushare è·å–å…¨å¸‚åœºåŸºç¡€åˆ—è¡¨..."
        df_basics = ts_client.fetch_stock_basic()
        if df_basics.empty: 
            yield "âŒ è·å–å¤±è´¥ï¼šTushare è¿”å›ä¸ºç©ºã€‚"
            return

        yield "ğŸ’ æ­£åœ¨è·å–ä¸­è¯800æœ€æ–°æˆåˆ†è‚¡åå•..."
        try:
            now_str = datetime.now().strftime("%Y%m%d")
            df_csi800 = ts_client.pro.index_weight(index_code='000906.SH', start_date='20240101', end_date=now_str)
            if not df_csi800.empty:
                latest_date = df_csi800['trade_date'].max()
                csi800_set = set(df_csi800[df_csi800['trade_date'] == latest_date]['con_code'].tolist())
            else:
                csi800_set = set()
        except Exception as e:
            yield f"âš ï¸ æŒ‡æ•°è·å–å¼‚å¸¸: {e}"
            csi800_set = set()

        yield f"ğŸ“¥ æ­£åœ¨å†™å…¥æ•°æ®åº“ (å…± {len(df_basics)} æ¡è®°å½•)..."
        for _, row in df_basics.iterrows():
            is_in_index = row['ts_code'] in csi800_set
            stock = StockBasic(
                ts_code=row['ts_code'], symbol=row['symbol'], name=row['name'],
                area=row['area'], industry=row['industry'], market=row['market'],
                list_date=row['list_date'], is_csi800=is_in_index
            )
            self.db.merge(stock)
        
        self.db.commit()
        yield f"âœ… è‚¡ç¥¨åˆ—è¡¨åŒæ­¥å®Œæˆï¼å·²è¯†åˆ«ä¸­è¯800æˆåˆ†è‚¡: {len(csi800_set)} åªã€‚"

    # --- åœºæ™¯ S1/S2/S5: å‚ç›´å†å²å›æº¯ (æŒ‰ä»£ç åŒæ­¥) ---

    def run_watchlist_backfill(self):
        """
        [PRD S1/S2] è‡ªé€‰è‚¡è¡Œæƒ…ä¸è´¢æŠ¥æ·±åº¦ä¿®è¡¥
        é€»è¾‘ï¼šé’ˆå¯¹ Watchlist ä¸­çš„æ ‡çš„ï¼Œä» 20150101 èµ·æ‰§è¡Œå‚ç›´åŒæ­¥ 
        """
        watchlist = self.db.query(Watchlist.ts_code).all()
        targets = [r.ts_code for r in watchlist]
        
        if not targets:
            yield "âš ï¸ è‡ªé€‰æ± ä¸ºç©ºï¼Œè¯·å…ˆåœ¨é¡µé¢æ·»åŠ æ ‡çš„ã€‚"
            return

        total = len(targets)
        yield f"ğŸš€ å¯åŠ¨è‡ªé€‰æ± æ·±åº¦åŒæ­¥ï¼šå…± {total} åªæ ‡çš„"

        for i, ts_code in enumerate(targets):
            yield f"æ­£åœ¨å¤„ç† [{i+1}/{total}]: {ts_code}"
            try:
                # 1. æ‰§è¡Œ ODS å±‚å‚ç›´æ‹‰å– (è¡Œæƒ…+è´¢æŠ¥)
                self.sync_stock_history(ts_code, start_date="20150101")
                
                # 2. æ‰§è¡Œ DWS å±‚æ•°æ®ç‚¼åˆ¶ (è®¡ç®—å‡çº¿ä¸æ ‡å‡†åŒ–è´¢æŠ¥)
                self.process_market_dws(ts_code)
                self.process_finance_dws(ts_code)
                
                # 3. 2000 ç§¯åˆ†é¢‘æ¬¡ä¿æŠ¤ï¼šæ¯æ¬¡åŒæ­¥åä¼‘çœ  0.3s-0.5s [cite: 1635]
                time.sleep(0.3)
            except Exception as e:
                yield f"âŒ {ts_code} åŒæ­¥å¤±è´¥: {str(e)}"
                continue
        
        yield "âœ… è‡ªé€‰æ± å†å²æ•°æ®ä¿®å¤å®Œæˆã€‚"

    def sync_stock_history(self, ts_code: str, start_date="20150101"):
        """è¡¥å…¨å•åªè‚¡ç¥¨çš„æ‰€æœ‰å†å²æ•°æ® (ODS å±‚)"""
        # A. è¡Œæƒ…æ•°æ®åŒæ­¥
        df_daily = ts_client.fetch_daily(ts_code=ts_code, start_date=start_date)
        if not df_daily.empty:
            for _, row in df_daily.iterrows():
                self.db.merge(ODSMarketDaily(
                    ts_code=row['ts_code'], trade_date=row['trade_date'],
                    open=row['open'], high=row['high'], low=row['low'], close=row['close'],
                    pre_close=row['pre_close'], change=row['change'], pct_chg=row['pct_chg'],
                    vol=row['vol'], amount=row['amount']
                ))

        # B. å¤æƒå› å­åŒæ­¥ [cite: 1760]
        df_adj = ts_client.fetch_adj_factor(ts_code=ts_code, start_date=start_date)
        if not df_adj.empty:
            for _, row in df_adj.iterrows():
                self.db.merge(ODSAdjFactor(ts_code=row['ts_code'], trade_date=row['trade_date'], adj_factor=row['adj_factor']))

        # C. æ¯æ—¥æŒ‡æ ‡åŒæ­¥ (PE/PB/å¸‚å€¼) [cite: 1766]
        df_basic = ts_client.pro.daily_basic(ts_code=ts_code, start_date=start_date)
        if not df_basic.empty:
            for _, row in df_basic.iterrows():
                self.db.merge(ODSDailyBasic(
                    ts_code=row['ts_code'], trade_date=row['trade_date'],
                    pe_ttm=row.get('pe_ttm'), pb=row.get('pb'), 
                    turnover_rate=row.get('turnover_rate'), total_mv=row.get('total_mv')
                ))

        # D. å››å¤§è´¢æŠ¥åŒæ­¥ (JSONB å­˜å‚¨) [cite: 1761]
        tasks = {
            "income": ts_client.fetch_income,
            "balancesheet": ts_client.fetch_balancesheet,
            "cashflow": ts_client.fetch_cashflow,
            "fina_indicator": ts_client.fetch_fina_indicator
        }
        for category, api_func in tasks.items():
            df = api_func(ts_code=ts_code, start_date=start_date)
            if df is not None and not df.empty:
                # --- æ¶æ„çº§ä¿®å¤ï¼šåŠ¨æ€æ£€æµ‹ä¸»é”® --- 
                # ç†æƒ³çš„ä¸»é”®å€™é€‰ï¼Œä½†éœ€å…¼å®¹ä¸åŒæ¥å£çš„å­—æ®µå·®å¼‚
                pk_candidates = ['ts_code', 'end_date', 'report_type', 'update_flag']
                actual_pk = [col for col in pk_candidates if col in df.columns]
                
                # æ‰§è¡Œå®‰å…¨å»é‡ï¼šæ ¹æ®å­˜åœ¨çš„å­—æ®µä¿ç•™æœ€æ–°ä¸€æ¡ 
                df = df.drop_duplicates(subset=actual_pk, keep='last')

                # å¤„ç† NaN å¹¶åœ¨å­—å…¸è½¬æ¢æ—¶å¡«å…… Noneï¼Œé˜²æ­¢ JSONB å†™å…¥æŠ¥é”™ 
                df = df.astype(object).where(pd.notnull(df), None)
                
                for record in df.to_dict('records'):
                    # å†™å…¥ ODS æ—¶ä½¿ç”¨ .get() å…œåº•å¯é€‰å­—æ®µ [cite: 864-865]
                    self.db.merge(ODSFinanceReport(
                        ts_code=record['ts_code'], 
                        end_date=record['end_date'],
                        # é»˜è®¤åˆå¹¶æŠ¥è¡¨(1)å’Œåˆå§‹æ•°æ®(0)ä»¥å¯¹é½æ•°æ®åº“æ¨¡å‹è¦æ±‚ [cite: 769, 864]
                        report_type=str(record.get('report_type', '1')), 
                        update_flag=str(record.get('update_flag', '0')), 
                        category=category, 
                        data=record, 
                        ann_date=record.get('ann_date')
                    ))
                self.db.commit() # æ¯ä¸€ç±»æŠ¥è¡¨æäº¤ä¸€æ¬¡ï¼Œç¼©å°å†²çªèŒƒå›´ [cite: 865]

    # --- åœºæ™¯ S3: æ°´å¹³æ¯æ—¥è¡Œæƒ… (æŒ‰æ—¥æœŸåŒæ­¥) ---

    def sync_daily_market(self, trade_date: str):
        """[PRD S3] æ¯æ—¥å¢é‡è¡Œæƒ…åŒæ­¥ (æ°´å¹³æ¨¡å¼)"""
        universe = self._get_universe_pool()
        if not universe: return

        try:
            # 1. Fetch Full Market
            df_daily = ts_client.fetch_daily(trade_date=trade_date)
            df_adj = ts_client.fetch_adj_factor(trade_date=trade_date)
            
            if df_daily.empty: return

            # 2. Funnel Filter
            df_daily_filtered = df_daily[df_daily['ts_code'].isin(universe)]
            
            # 3. Save ODS
            for _, row in df_daily_filtered.iterrows():
                self.db.merge(ODSMarketDaily(
                    ts_code=row['ts_code'], trade_date=row['trade_date'],
                    open=row['open'], high=row['high'], low=row['low'], close=row['close'],
                    pre_close=row['pre_close'], change=row['change'], pct_chg=row['pct_chg'],
                    vol=row['vol'], amount=row['amount']
                ))

            if not df_adj.empty:
                df_adj_filtered = df_adj[df_adj['ts_code'].isin(universe)]
                for _, row in df_adj_filtered.iterrows():
                    self.db.merge(ODSAdjFactor(
                        ts_code=row['ts_code'], trade_date=row['trade_date'],
                        adj_factor=row['adj_factor']
                    ))

            self.db.commit()
            print(f"  âœ… Market Snapshot {trade_date}: Saved {len(df_daily_filtered)} records.")

        except Exception as e:
            self.db.rollback()
            print(f"  âŒ Market Snapshot Failed: {e}")

    # --- åœºæ™¯ S4: æ°´å¹³æ¯æ—¥è´¢æŠ¥ (æŒ‰å…¬å‘Šæ—¥åŒæ­¥) ---

    def sync_financial_daily(self, ann_date: str):
        """
        [PRD S4 ä¿®æ­£ç‰ˆ] æ¯æ—¥å¢é‡è´¢æŠ¥åŒæ­¥
        é’ˆå¯¹ 2000 ç§¯åˆ†ä¼˜åŒ–ï¼šé€šè¿‡æŠ«éœ²è®¡åˆ’åæŸ¥ä¸ªè‚¡ï¼Œé¿å…å…¨å¸‚åœºæ‹‰å–æŠ¥é”™
        """
        universe = self._get_universe_pool()
        if not universe:
            return

        try:
            # 1. è·å–å½“æ—¥å®é™…æŠ«éœ²è´¢æŠ¥çš„åå• (actual_date)
            # Ref: Tushare PDF 
            df_ann = ts_client.pro.disclosure_date(actual_date=ann_date)
            if df_ann.empty:
                yield f"  â˜• {ann_date} æ— è´¢æŠ¥æŠ«éœ²ã€‚"
                return

            # 2. ç­›é€‰å‡ºå±äºæˆ‘ä»¬ Universe çš„æ ‡çš„
            targets = df_ann[df_ann['ts_code'].isin(universe)]['ts_code'].unique().tolist()
            
            if not targets:
                yield f"  â˜• {ann_date} æŠ«éœ²çš„ {len(df_ann)} å®¶å…¬å¸å‡ä¸åœ¨æ ¸å¿ƒæ± ä¸­ã€‚"
                return

            yield f"  ğŸ“¢ å‘ç° {len(targets)} åªæ ¸å¿ƒæ ‡çš„æŠ«éœ²è´¢æŠ¥ï¼Œå¼€å§‹ç²¾å‡†åŒæ­¥..."

            # 3. é€ä¸ªåŒæ­¥ä¸ªè‚¡è´¢æŠ¥ (å¤ç”¨ S1/S2 çš„å‚ç›´åŒæ­¥é€»è¾‘)
            for i, ts_code in enumerate(targets):
                yield f"    > [{i+1}/{len(targets)}] åŒæ­¥è´¢æŠ¥: {ts_code}"
                # æ­¤å¤„ä»…åŒæ­¥å…¬å‘Šæ—¥å‰åçš„æ•°æ®å³å¯ï¼Œä¸ºä¿é™©èµ·è§åŒæ­¥æœ€è¿‘ä¸€å¹´
                # start_date è®¾ä¸ºå…¬å‘Šæ—¥å‰ä¸€å¹´
                sync_start = (datetime.strptime(ann_date, "%Y%m%d") - timedelta(days=365)).strftime("%Y%m%d")
                self.sync_stock_history(ts_code, start_date=sync_start)
                
                # é¢‘æ¬¡ä¿æŠ¤
                time.sleep(0.2)

            self.db.commit()
            yield f"  âœ… {ann_date} è´¢æŠ¥å¢é‡åŒæ­¥å®Œæˆã€‚"

        except Exception as e:
            self.db.rollback()
            yield f"  âŒ è´¢æŠ¥å¢é‡åŒæ­¥å¤±è´¥: {str(e)}"

    # --- DWS è®¡ç®—é€»è¾‘ ---

    def process_market_dws(self, ts_code: str):
        """DWS: è®¡ç®—å‡çº¿ã€QFQ å¹¶è¡¥å…¨åŸºæœ¬é¢æŒ‡æ ‡"""
        # 1. è”åˆæŸ¥è¯¢ ODS è¡Œæƒ…å’Œæ¯æ—¥æŒ‡æ ‡ (daily_basic)
        query = text("""
            SELECT m.*, b.pe_ttm, b.pb, b.total_mv, b.turnover_rate, a.adj_factor
            FROM ods_market_daily m
            LEFT JOIN ods_daily_basic b ON m.ts_code = b.ts_code AND m.trade_date = b.trade_date
            LEFT JOIN ods_adj_factor a ON m.ts_code = a.ts_code AND m.trade_date = a.trade_date
            WHERE m.ts_code = :ts_code
            ORDER BY m.trade_date
        """)
        
        df = pd.read_sql(query, self.db.bind, params={"ts_code": ts_code})
        if df.empty: return

        # 2. è®¡ç®—å‰å¤æƒ
        df['adj_factor'] = df['adj_factor'].ffill()
        latest_factor = df['adj_factor'].iloc[-1] if not df['adj_factor'].isnull().all() else 1.0
        df['close_qfq'] = df['close'] * (df['adj_factor'] / latest_factor)

        # 3. è®¡ç®—å‡çº¿ [cite: 843]
        for ma in [20, 50, 120, 250, 850]:
            df[f'ma_{ma}'] = df['close_qfq'].rolling(window=ma, min_periods=ma).mean()

        # 4. Upsert å†™å…¥ DWS
        for _, row in df.iterrows():
            self.db.merge(DWSMarketIndicators(
                ts_code=row['ts_code'],
                trade_date=row['trade_date'],
                pe_ttm=row.get('pe_ttm'),
                pb=row.get('pb'),
                total_mv=row.get('total_mv'),
                turnover_rate=row.get('turnover_rate'),
                close_qfq=row['close_qfq'],
                ma_20=row['ma_20'] if pd.notna(row['ma_20']) else None,
                ma_50=row['ma_50'] if pd.notna(row['ma_50']) else None,
                ma_120=row['ma_120'] if pd.notna(row['ma_120']) else None,
                ma_250=row['ma_250'] if pd.notna(row['ma_250']) else None,
                ma_850=row['ma_850'] if pd.notna(row['ma_850']) else None,
            ))
        self.db.commit()

    def process_finance_dws(self, ts_code: str):
        """[æ ¸å¿ƒä¿®å¤] ç‚¼åˆ¶æ—¶è‡ªåŠ¨åˆå¹¶ roe ä¸ roe_dtï¼Œå¹¶è®¡ç®—å®¡è®¡æŒ‡æ ‡"""
        reports = self.db.query(ODSFinanceReport).filter(
            ODSFinanceReport.ts_code == ts_code,
            ODSFinanceReport.report_type == '1'
        ).all()
        
        merged = {}
        for r in reports:
            end_date = r.end_date
            if end_date not in merged:
                merged[end_date] = {"ann_date": r.ann_date}
            
            data = r.data
            # æå–åŸºç¡€å­—æ®µ
            fields = [
                'revenue', 'n_income_attr_p', 'n_cashflow_act', 'grossprofit_margin',
                'oth_receiv', 'prepayment', 'goodwill', 'total_assets', 'total_hldr_eqy_exc_min_int',
                'debt_to_assets', 'roe', 'roe_dt', 'total_liab'
            ]
            for k in fields:
                if k in data and data[k] is not None:
                    merged[end_date][k] = data[k]
        
        for end_date, m in merged.items():
            # å¿…é¡»æœ‰å…¬å‘Šæ—¥æœŸæ‰èƒ½è¿›è¡Œåç»­çš„ merge_asof [cite: 847]
            if not m.get('ann_date'): continue 
            
            # 1. å‡†å¤‡è®¡ç®—æ•°æ® (åˆ©ç”¨ .get å®¹é”™)
            net_profit = m.get('n_income_attr_p', 0) or 0
            ocf = m.get('n_cashflow_act', 0) or 0
            oth_receiv = m.get('oth_receiv', 0) or 0
            prepay = m.get('prepayment', 0) or 0
            assets = m.get('total_assets', 0) or 0
            goodwill = m.get('goodwill', 0) or 0
            equity = m.get('total_hldr_eqy_exc_min_int', 0) or 0
            
            # 2. è®¡ç®—å®¡è®¡æŒ‡æ ‡
            # å‡€ç°æ¯”
            ocf_ratio = ocf / net_profit if net_profit and net_profit != 0 else 0
            # åƒåœ¾èµ„äº§å æ¯”
            toxic_ratio = (oth_receiv + prepay) / assets if assets and assets != 0 else 0
            # å•†èª‰å æ¯”
            gw_ratio = goodwill / equity if equity and equity != 0 else 0
            
            # 3. è´Ÿå€ºç‡å¤šè·¯å¾„æå–
            debt_ratio = m.get('debt_to_assets')
            if debt_ratio is None:
                liab = m.get('total_liab')
                if liab and assets and assets != 0:
                    debt_ratio = (liab / assets) * 100
            
            # 4. ROE ä¼˜å…ˆçº§
            roe_final = m.get('roe_dt') if m.get('roe_dt') is not None else m.get('roe')

            self.db.merge(DWSFinanceStd(
                ts_code=ts_code, end_date=end_date, ann_date=m.get('ann_date'),
                revenue=m.get('revenue'),
                n_income_attr_p=m.get('n_income_attr_p'),
                n_cashflow_act=m.get('n_cashflow_act'),
                debt_to_assets=debt_ratio,
                roe=roe_final,
                grossprofit_margin=m.get('grossprofit_margin'),
                oth_receiv=m.get('oth_receiv'),
                prepayment=m.get('prepayment'),
                goodwill=m.get('goodwill'),
                total_assets=m.get('total_assets'),
                total_hldr_eqy_exc_min_int=m.get('total_hldr_eqy_exc_min_int'),
                # å­˜å…¥ç‰©ç†å­—æ®µ
                ocf_to_net_profit=round(ocf_ratio, 4),
                toxic_asset_ratio=round(toxic_ratio, 4),
                goodwill_net_asset_ratio=round(gw_ratio, 4)
            ))
        self.db.commit()

    # --- è°ƒåº¦å™¨ (æ”¯æŒè¿›åº¦è¿”å›) ---

    def run_full_backfill(self, start_date="20150101"):
        """[PRD S5] æ ¸å¿ƒæ± è´¢åŠ¡ä¸è¡Œæƒ…å…¨é‡åˆå§‹åŒ–"""
        yield "ğŸš€ å¼€å§‹å…¨é‡å›æº¯ (Full Backfill)..."
        yield from self.sync_stock_list()
        
        universe = list(self._get_universe_pool())
        total = len(universe)
        
        for i, ts_code in enumerate(universe):
            # ä½¿ç”¨ yield è®©å‰ç«¯ NiceGUI å¯ä»¥å®æ—¶æ›´æ–°è¿›åº¦æ¡ [cite: 107-108]
            yield f"æ­£åœ¨è¡¥å…¨ç¬¬ {i+1}/{total} åª: {ts_code}"
            try:
                self.sync_stock_history(ts_code, start_date)
                # DWS Calculation
                self.process_market_dws(ts_code)
                self.process_finance_dws(ts_code)
                time.sleep(0.1) # é¢‘æ¬¡ä¿æŠ¤
            except Exception as e:
                yield f"âš ï¸ {ts_code} åŒæ­¥å¤±è´¥: {str(e)}"
        yield "âœ… å…¨é‡å›æº¯ä»»åŠ¡å®Œæˆ"

    def run_daily_routine(self):
        """
        [PRD S3/S4 è¿›åŒ–ç‰ˆ] è‡ªåŠ¨åŒºé—´è¡¥å…¨æ—¥æ›´
        é€»è¾‘ï¼šè‡ªåŠ¨è®¡ç®—æ–­æ¡£æœŸå¹¶å¾ªç¯è¡¥å…¨ï¼Œç¡®ä¿éš”å‘¨/éš”æœˆæ›´æ–°ä¸æ¼æ•°æ®
        """
        # 1. ç¡®å®šè¡¥å…¨åŒºé—´
        # æŸ¥æ‰¾æœ¬åœ°æœ€æ–°è¡Œæƒ…æ—¥æœŸä½œä¸ºèµ·ç‚¹
        res = self.db.execute(text("SELECT max(trade_date) FROM ods_market_daily")).fetchone()
        last_date_str = res[0] if res and res[0] else "20241201" # é»˜è®¤å›æº¯èµ·ç‚¹
        
        start_date = (datetime.strptime(last_date_str, "%Y%m%d") + timedelta(days=1))
        end_date = datetime.now()
        
        # è·å–æœŸé—´æ‰€æœ‰äº¤æ˜“æ—¥ (é¿å…éäº¤æ˜“æ—¥æŠ¥é”™)
        # æ³¨æ„ï¼šè¿™é‡Œè°ƒç”¨ tushare äº¤æ˜“æ—¥å†æ¥å£
        cal = ts_client.pro.trade_cal(exchange='', start_date=start_date.strftime('%Y%m%d'), 
                                     end_date=end_date.strftime('%Y%m%d'), is_open='1')
        trade_days = cal['cal_date'].tolist()

        if not trade_days:
            yield "â˜• æ•°æ®å·²æ˜¯æœ€æ–°ï¼Œæ— éœ€æ›´æ–°ã€‚"
            return

        yield f"ğŸš€ å‘ç° {len(trade_days)} ä¸ªäº¤æ˜“æ—¥å¾…è¡¥å…¨: {trade_days[0]} -> {trade_days[-1]}"

        # 2. æ ¸å¿ƒåŒæ­¥å¾ªç¯
        for date_str in trade_days:
            yield f"ğŸ“… æ­£åœ¨å¤„ç†: {date_str} ..."
            
            # A. åŒæ­¥å…¨å¸‚åœºè¡Œæƒ… (S3) 
            self.sync_daily_market(date_str)
            
            # B. åŒæ­¥æ¯æ—¥æŒ‡æ ‡ (PE/PB/å¸‚å€¼) - ä¿®æ­£ï¼šéœ€æ‰‹åŠ¨æ·»åŠ  horizontal æ¨¡å¼
            yield f"  > æ‹‰å–æ¯æ—¥æŒ‡æ ‡ (PE/PB)..."
            df_basic = ts_client.pro.daily_basic(trade_date=date_str)
            if not df_basic.empty:
                # ä»…å­˜ universe å†…çš„
                universe = self._get_universe_pool()
                df_target = df_basic[df_basic['ts_code'].isin(universe)]
                for _, row in df_target.iterrows():
                    self.db.merge(ODSDailyBasic(
                        ts_code=row['ts_code'], trade_date=row['trade_date'],
                        pe_ttm=row.get('pe_ttm'), pb=row.get('pb'),
                        total_mv=row.get('total_mv'), turnover_rate=row.get('turnover_rate')
                    ))
            
            # C. æ£€æŸ¥å¹¶åŒæ­¥å½“æ—¥æŠ«éœ²çš„è´¢æŠ¥ (S4 ä¿®æ­£ç‰ˆ)
            # è¿™é‡Œè°ƒç”¨ä¸Šä¸€å¼ æŒ‡ä»¤å¡ä¿®å¤åçš„ sync_financial_daily
            # ç”±äº sync_financial_daily æ˜¯ç”Ÿæˆå™¨ï¼Œéœ€è¦éå†å®ƒ
            for msg in self.sync_financial_daily(date_str):
                yield f"    {msg}"
            
            self.db.commit()
            time.sleep(0.5) # 2000ç§¯åˆ†é¢‘æ¬¡ä¿æŠ¤ [cite: 345]

        # 3. ç»Ÿä¸€è§¦å‘ DWS é‡ç‚¼ [cite: 140]
        yield "ğŸ”„ æ­£åœ¨é‡æ–°ç‚¼åˆ¶ DWS è¡ç”ŸæŒ‡æ ‡..."
        universe = list(self._get_universe_pool())
        for i, ts_code in enumerate(universe):
            self.process_market_dws(ts_code)
            self.process_finance_dws(ts_code)
            if i % 100 == 0:
                yield f"  > ç‚¼åˆ¶è¿›åº¦: {i}/{len(universe)}"
        
        yield "âœ… å…¨åŒºé—´æ•°æ®è¡¥å…¨å¹¶ç‚¼åˆ¶å®Œæˆï¼"

if __name__ == "__main__":
    u = DataUpdater()
    # u.sync_stock_list()
    u.close()