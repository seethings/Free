import pandas as pd
from sqlalchemy.dialects.postgresql import insert
from interface.tushare_client import ts_client
from database.models import SessionLocal, StockBasic, ODSMarketDaily, ODSAdjFactor, ODSFinanceReport, DWSMarketIndicators, DWSFinanceStd
from core.config import settings
from datetime import datetime

class DataUpdater:
    def __init__(self):
        self.db = SessionLocal()

    def sync_stock_list(self):
        """
        å…¨é‡åŒæ­¥è‚¡ç¥¨åˆ—è¡¨ï¼Œå¹¶æ ‡è®°ä¸­è¯800æˆåˆ†è‚¡ (PRD 3.1)
        """
        print("ğŸ”„ å¼€å§‹åŒæ­¥è‚¡ç¥¨åŸºç¡€åˆ—è¡¨...")
        
        # 1. æ‹‰å–å…¨å¸‚åœºè‚¡ç¥¨ (Tushare API)
        df_basics = ts_client.fetch_stock_basic()
        if df_basics.empty:
            print("âš ï¸ æœªè·å–åˆ°è‚¡ç¥¨åˆ—è¡¨ï¼Œä»»åŠ¡ç»ˆæ­¢")
            return

        # 2. æ‹‰å–ä¸­è¯800æˆåˆ†è‚¡ (ç”¨äºæ ‡è®°æ ¸å¿ƒèµ„äº§)
        # 000906.SH æ˜¯ä¸­è¯800æŒ‡æ•°ä»£ç 
        # æ³¨æ„: index_weight æ¥å£éœ€è¦ 2000 ç§¯åˆ† 
        try:
            # è·å–æœ€æ–°ä¸€ä¸ªæœˆçš„æˆåˆ†è‚¡ï¼ˆè¿™é‡Œç®€åŒ–é€»è¾‘ï¼Œå–ä¸Šä¸ªæœˆçš„æˆåˆ†ï¼‰
            # å®é™…ç”Ÿäº§ä¸­å¯èƒ½éœ€è¦åŠ¨æ€è®¡ç®—æ—¥æœŸï¼Œè¿™é‡Œæš‚å–æœ€è¿‘çš„é€»è¾‘
            # Tushare Pro çš„ index_weight é€šå¸¸æŒ‰æœˆæ›´æ–°
            now_str = datetime.now().strftime("%Y%m%d")
            # å°è¯•æ‹‰å–æœ€æ–°çš„æˆåˆ†
            df_csi800 = ts_client.pro.index_weight(index_code='000906.SH', start_date='20240101', end_date=now_str)
            
            # å¦‚æœæ²¡å–åˆ°ï¼ˆæ¯”å¦‚å¹´åˆè¿˜æ²¡æ›´æ–°ï¼‰ï¼Œå¯ä»¥å°è¯•å–å»å¹´çš„ï¼Œè¿™é‡Œåšç®€å•å®¹é”™
            if df_csi800.empty:
                 print("âš ï¸ è­¦å‘Š: æœªè·å–åˆ°ä¸­è¯800æˆåˆ†è‚¡ï¼Œå°†è·³è¿‡æ ‡è®°æ­¥éª¤")
                 csi800_set = set()
            else:
                 # å–æœ€æ–°æ—¥æœŸçš„æˆåˆ†
                 latest_date = df_csi800['trade_date'].max()
                 df_latest = df_csi800[df_csi800['trade_date'] == latest_date]
                 csi800_set = set(df_latest['con_code'].tolist())
                 print(f"âœ… è·å–åˆ°ä¸­è¯800æˆåˆ†è‚¡ ({latest_date}): {len(csi800_set)} åª")

        except Exception as e:
            print(f"âš ï¸ ä¸­è¯800æ¥å£è°ƒç”¨å¤±è´¥: {e}")
            csi800_set = set()

        # 3. æ•°æ®å¤„ç†ä¸æ ‡è®°
        # é»˜è®¤å…¨éƒ¨ False
        df_basics['is_csi800'] = False
        # å¦‚æœä»£ç åœ¨ csi800_set ä¸­ï¼Œè®¾ä¸º True
        if csi800_set:
            df_basics.loc[df_basics['ts_code'].isin(csi800_set), 'is_csi800'] = True

        # 4. å†™å…¥æ•°æ®åº“ (Upsert æ¨¡å¼)
        # ä½¿ç”¨ SQLAlchemy Core çš„ bulk insert æ•ˆç‡è¾ƒé«˜ï¼Œæˆ–è€…é€è¡Œ merge
        # è¿™é‡Œä¸ºäº†æ¼”ç¤ºæ¸…æ™°ï¼Œä½¿ç”¨ pandas to_sql çš„æ›¿ä»£æ–¹æ¡ˆæˆ– ORM å¾ªç¯
        # è€ƒè™‘åˆ°åªæœ‰ 5000 æ¡æ•°æ®ï¼ŒORM æ•ˆç‡å¯æ¥å—
        
        count = 0
        for _, row in df_basics.iterrows():
            stock = StockBasic(
                ts_code=row['ts_code'],
                symbol=row['symbol'],
                name=row['name'],
                area=row['area'],
                industry=row['industry'],
                market=row['market'],
                list_date=row['list_date'],
                is_csi800=row['is_csi800']
            )
            self.db.merge(stock) # merge ä¼šæ ¹æ®ä¸»é”®è‡ªåŠ¨ insert æˆ– update
            count += 1
            
        self.db.commit()
        print(f"âœ… è‚¡ç¥¨åˆ—è¡¨åŒæ­¥å®Œæˆ! å…±å¤„ç†: {count} åª, å…¶ä¸­ä¸­è¯800: {len(csi800_set)} åª")

    def sync_daily_market(self, start_date: str, end_date: str):
        """
        S3 åœºæ™¯: æ—¥çº¿è¡Œæƒ…å¢é‡æ›´æ–° (ODSå±‚)
        """
        print(f"ğŸ“ˆ å¼€å§‹åŒæ­¥æ—¥çº¿è¡Œæƒ… ({start_date} - {end_date})...")
        
        # 1. è·å–æ—¥çº¿ (å…¨å¸‚åœº)
        # ç­–ç•¥: æŒ‰æ—¥æœŸå¾ªç¯æ‹‰å–ï¼Œæ¯å¤©çº¦ 5000 æ¡ï¼Œé€‚åˆ WideCore æ¨¡å¼
        # [cite_start]Tushare daily æ¥å£æ”¯æŒå•æ—¥å…¨é‡ [cite: 1515]
        
        dates = pd.date_range(start=start_date, end=end_date).strftime('%Y%m%d').tolist()
        
        for trade_date in dates:
            try:
                # 1.1 æ‹‰å–è¡Œæƒ…
                df_daily = ts_client.fetch_daily(trade_date=trade_date)
                if df_daily.empty:
                    print(f"  - {trade_date}: æ— æ•°æ® (ä¼‘å¸‚?)")
                    continue
                
                # 1.2 æ‹‰å–å¤æƒå› å­
                df_adj = ts_client.fetch_adj_factor(trade_date=trade_date)
                
                # 1.3 å…¥åº“ ODSMarketDaily
                # ä½¿ç”¨ to_dict è½¬æ¢ï¼Œåˆ©ç”¨ SQLAlchemy çš„ bulk_insert_mappings (éœ€ Core æ¨¡å¼) 
                # æˆ–å¾ªç¯ ORM merge (ç®€å•ä½†æ…¢)ã€‚é‰´äºæ¯æ—¥ä»… 5000 æ¡ï¼ŒORM merge å°šå¯ï¼Œ
                # ä½†ä¸ºæ€§èƒ½æ¨è bulk insert (è¿™é‡Œç®€åŒ–æ¼”ç¤ºä½¿ç”¨ merge é€»è¾‘çš„å˜ä½“)
                
                daily_objs = []
                for _, row in df_daily.iterrows():
                    daily_objs.append({
                        "ts_code": row['ts_code'],
                        "trade_date": row['trade_date'],
                        "open": row['open'],
                        "high": row['high'],
                        "low": row['low'],
                        "close": row['close'],
                        "pre_close": row['pre_close'],
                        "change": row['change'],
                        "pct_chg": row['pct_chg'],
                        "vol": row['vol'],
                        "amount": row['amount']
                    })
                
                # æ‰¹é‡æ’å…¥ (ä½¿ç”¨ Core çš„ insert..on_conflict_do_update ä¼šæ›´ä¼˜ï¼Œè¿™é‡Œç”¨ ORM é€ä¸ªæ·»åŠ æ¼”ç¤º)
                # å®é™…ç”Ÿäº§å»ºè®®: self.db.execute(insert(ODSMarketDaily).values(daily_objs).on_conflict_do_nothing())
                # è¿™é‡Œä¸ºäº†å…¼å®¹æ€§ä¿æŒç®€å•é€»è¾‘ï¼š
                for obj in daily_objs:
                    self.db.merge(ODSMarketDaily(**obj))
                
                # 1.4 å…¥åº“ ODSAdjFactor
                if not df_adj.empty:
                    for _, row in df_adj.iterrows():
                        self.db.merge(ODSAdjFactor(
                            ts_code=row['ts_code'],
                            trade_date=row['trade_date'],
                            adj_factor=row['adj_factor']
                        ))
                
                self.db.commit()
                print(f"  âœ… {trade_date}: è¡Œæƒ…å…¥åº“å®Œæˆ (Stocks: {len(df_daily)})")
                
            except Exception as e:
                self.db.rollback()
                print(f"  âŒ {trade_date}: å¤„ç†å¤±è´¥ - {e}")

    def sync_financial_report(self, ts_code: str, start_date: str = None, end_date: str = None):
        """
        S2/S4 åœºæ™¯: è´¢æŠ¥æ•°æ®æ›´æ–° (ODSå±‚ - JSONB)
        [FIXED V2]: å¼ºåŠ›ä¿®å¤ NaN -> Noneï¼Œå…¼å®¹ PostgreSQL JSONB
        """
        print(f"ğŸ’° å¼€å§‹åŒæ­¥è´¢æŠ¥: {ts_code}...")
        
        tasks = {
            "income": (ts_client.fetch_income, "income"),
            "balancesheet": (ts_client.fetch_balancesheet, "balance"),
            "cashflow": (ts_client.fetch_cashflow, "cashflow"),
            "fina_indicator": (ts_client.fetch_fina_indicator, "indicator")
        }
        
        for name, (api_func, category) in tasks.items():
            try:
                # 1. æ‹‰å–æ•°æ®
                df = api_func(ts_code=ts_code, start_date=start_date, end_date=end_date)
                if df.empty:
                    continue
                
                # 2. [å…³é”®ä¿®å¤] æ•°æ®æ¸…æ´—
                # å…ˆè½¬ä¸º object ç±»å‹ï¼Œé˜²æ­¢ pandas å°† None è‡ªåŠ¨å›æ»šä¸º NaN
                # ç„¶åå°†æ‰€æœ‰ NaN æ›¿æ¢ä¸º None (JSON null)
                df = df.astype(object).where(pd.notnull(df), None)
                
                # 3. è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
                records = df.to_dict('records')
                
                # 4. é€æ¡å…¥åº“ (Merge)
                # æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨ bulk_insert ä¼šæ›´å¿«ï¼Œä½†ä¸ºäº†æ¼”ç¤º update_flag é€»è¾‘ä¿æŒå¾ªç¯
                # ç”Ÿäº§ç¯å¢ƒå»ºè®®ä¼˜åŒ–ä¸º bulk_insert_mappings
                for record in records:
                    pk_data = {
                        "ts_code": record.get("ts_code"),
                        "end_date": record.get("end_date"),
                        "report_type": record.get("report_type", '1'), 
                        "update_flag": record.get("update_flag", '0'),
                        "ann_date": record.get("ann_date"),
                        "category": category,
                        "data": record # record ä¸­çš„ NaN ç°åœ¨æ˜¯ None äº†
                    }
                    
                    self.db.merge(ODSFinanceReport(**pk_data))
                
                self.db.commit()
                print(f"  - {name}: {len(records)} æ¡è®°å½•")
                
            except Exception as e:
                self.db.rollback()
                print(f"  âš ï¸ {name} åŒæ­¥å¤±è´¥: {e}")

    def process_market_dws(self, ts_code: str):
        """
        DWS æ ¸å¿ƒé€»è¾‘: è®¡ç®—å¤æƒä»·æ ¼ä¸å‡çº¿ (PRD 2.2)
        è§¦å‘æ—¶æœº: å•åªè‚¡ç¥¨ ODS è¡Œæƒ…æ›´æ–°å
        """
        print(f"ğŸ§® è®¡ç®— DWS æŒ‡æ ‡: {ts_code}...")
        
        # 1. è¯»å– ODS æ•°æ® (Raw Price + Adj Factor)
        # ä½¿ç”¨ pandas read_sql ç®€åŒ–å¤„ç†
        query_daily = f"SELECT * FROM ods_market_daily WHERE ts_code = '{ts_code}' ORDER BY trade_date"
        query_adj = f"SELECT trade_date, adj_factor FROM ods_adj_factor WHERE ts_code = '{ts_code}' ORDER BY trade_date"
        
        df_daily = pd.read_sql(query_daily, self.db.bind)
        df_adj = pd.read_sql(query_adj, self.db.bind)
        
        if df_daily.empty or df_adj.empty:
            print("  âš ï¸ æ•°æ®ä¸è¶³ï¼Œè·³è¿‡è®¡ç®—")
            return

        # 2. åˆå¹¶å¤æƒå› å­
        df = pd.merge(df_daily, df_adj, on='trade_date', how='left')
        # å¡«å……ç¼ºå¤±å› å­ (å‘å‰å¡«å……)
        df['adj_factor'] = df['adj_factor'].ffill()
        
        # 3. è®¡ç®—å‰å¤æƒä»·æ ¼ (QFQ)
        # å…¬å¼: P_qfq = P_raw * (Factor_curr / Factor_latest) 
        latest_factor = df['adj_factor'].iloc[-1]
        df['close_qfq'] = df['close'] * (df['adj_factor'] / latest_factor)
        
        # 4. è®¡ç®—å‡çº¿ (MA)
        # PRD 2.2: MA20, MA50, MA120, MA250, MA850
        ma_list = [20, 50, 120, 250, 850]
        for ma in ma_list:
            col_name = f'ma_{ma}'
            # min_periods=ma ç¡®ä¿æ•°æ®ä¸å¤Ÿæ—¶ä¸º NaN (None)
            df[col_name] = df['close_qfq'].rolling(window=ma, min_periods=ma).mean()
            
        # 5. å‡†å¤‡å…¥åº“æ•°æ® (DWSMarketIndicators)
        dws_records = []
        for _, row in df.iterrows():
            # åŸºç¡€æŒ‡æ ‡è½¬æ¢
            record = {
                "ts_code": row['ts_code'],
                "trade_date": row['trade_date'],
                "close_qfq": row['close_qfq'],
                "ma_20": row['ma_20'] if pd.notna(row['ma_20']) else None,
                "ma_50": row['ma_50'] if pd.notna(row['ma_50']) else None,
                "ma_120": row['ma_120'] if pd.notna(row['ma_120']) else None,
                "ma_250": row['ma_250'] if pd.notna(row['ma_250']) else None,
                "ma_850": row['ma_850'] if pd.notna(row['ma_850']) else None,
                # é€ä¼  ODS åŸºç¡€å­—æ®µ (ç”¨äºé›·è¾¾ç­›é€‰)
                "turnover_rate": None, # éœ€ä» daily_basic è¡¥å……ï¼Œæ­¤å¤„æš‚ç•™ç©ºæˆ–åç»­ Join
                "pe_ttm": None,        # åŒä¸Š
                "pb": None,            # åŒä¸Š
                "total_mv": None       # åŒä¸Š
            }
            dws_records.append(record)
            
        # 6. æ‰¹é‡å…¥åº“ (Upsert)
        for r in dws_records:
            self.db.merge(DWSMarketIndicators(**r))
            
        self.db.commit()
        print(f"  âœ… DWS è®¡ç®—å®Œæˆ: {len(dws_records)} æ¡å‡çº¿æ•°æ®")

    def process_finance_dws(self, ts_code: str):
        """
        DWS æ ¸å¿ƒé€»è¾‘: æ ‡å‡†åŒ–è´¢åŠ¡å®½è¡¨æ¸…æ´— (PRD 2.2)
        è§„åˆ™: ä»…æå– report_type='1' (åˆå¹¶æŠ¥è¡¨)
        """
        print(f"ğŸ§¹ æ¸…æ´—è´¢åŠ¡æ•°æ®: {ts_code}...")
        
        # 1. æå–æ‰€æœ‰ç±»å‹çš„ JSONB æ•°æ®
        # è·å–è¯¥è‚¡ç¥¨æ‰€æœ‰ report_type='1' çš„è®°å½•
        reports = self.db.query(ODSFinanceReport).filter(
            ODSFinanceReport.ts_code == ts_code,
            ODSFinanceReport.report_type == '1'
        ).all()
        
        # æŒ‰ end_date èšåˆæ•°æ®
        # ç»“æ„: { '20231231': { 'revenue': 100, 'roe': 5... } }
        merged_data = {}
        
        for r in reports:
            if r.end_date not in merged_data:
                merged_data[r.end_date] = {"ann_date": r.ann_date}
            
            # å°† JSONB ä¸­çš„æ•°æ®æ‰“å¹³åˆå¹¶
            # æ˜ å°„å…³ç³»å‚è€ƒ core/mapping.py
            # å®é™…ç”Ÿäº§å»ºè®®ä¸¥æ ¼æŒ‰ Mapping æå–ï¼Œè¿™é‡Œåšè‡ªåŠ¨æ˜ å°„
            raw_dict = r.data
            target_fields = [
                'revenue', 'n_income_attr_p', 'n_cashflow_act', 
                'debt_to_assets', 'roe', 'grossprofit_margin'
            ]
            
            for field in target_fields:
                if field in raw_dict:
                    merged_data[r.end_date][field] = raw_dict[field]

        # 2. å…¥åº“ DWSFinanceStd
        for end_date, metrics in merged_data.items():
            dws_obj = DWSFinanceStd(
                ts_code=ts_code,
                end_date=end_date,
                ann_date=metrics.get('ann_date'),
                revenue=metrics.get('revenue'),
                n_income_attr_p=metrics.get('n_income_attr_p'),
                n_cashflow_act=metrics.get('n_cashflow_act'),
                debt_to_assets=metrics.get('debt_to_assets'),
                roe=metrics.get('roe'),
                grossprofit_margin=metrics.get('grossprofit_margin')
            )
            self.db.merge(dws_obj)
            
        self.db.commit()
        print(f"  âœ… è´¢åŠ¡æ¸…æ´—å®Œæˆ: {len(merged_data)} ä¸ªæŠ¥å‘ŠæœŸ")

    def close(self):
        self.db.close()

# å¿«æ·å…¥å£
if __name__ == "__main__":
    updater = DataUpdater()
    updater.sync_stock_list()
    updater.close()