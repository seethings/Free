# INVEST SYSTEM CONTEXT DUMP
# Timestamp: 2025-12-20 23:38:46.633044
# Security: Sensitive files (.env) and temp dirs are EXCLUDED.

ğŸ“¦ PROJECT STRUCTURE (Ignored: .env, temp/, note/, data/)
==================================================
ğŸ“‚ ROOT/
    ğŸ“„ .gitignore  # Gitå¿½ç•¥è§„åˆ™ [æ ¸å¿ƒ]
    ğŸ“„ debug_stock.py
    ğŸ“„ main.py
    ğŸ“„ requirements.txt  # Pythonä¾èµ–æ¸…å• [æ ¸å¿ƒ]
    ğŸ“„ run_backfill.py
    ğŸ“„ test_radar.py
    ğŸ“„ test_sync_engine.py
    ğŸ“‚ ui/
        ğŸ“„ __init__.py
        ğŸ“„ layout.py
        ğŸ“‚ pages/
            ğŸ“„ __init__.py
            ğŸ“„ console.py
            ğŸ“„ radar.py
            ğŸ“„ watchlist.py
    ğŸ“‚ database/
        ğŸ“„ models.py  # SQLAlchemyæ•°æ®åº“æ¨¡å‹(ODS/DWS) [æ ¸å¿ƒ]
    ğŸ“‚ interface/
        ğŸ“„ tushare_client.py  # Tushareæ¥å£å°è£…(å¸¦é‡è¯•) [æ ¸å¿ƒ]
    ğŸ“‚ tools/
        ğŸ“„ audit_system.py
        ğŸ“„ db_inspector.py  # æ•°æ®åº“ä½“æ£€å·¥å…· [å·¥å…·]
        ğŸ“„ doc_generator.py  # ä¸Šä¸‹æ–‡ç”Ÿæˆå·¥å…· [å·¥å…·]
        ğŸ“„ git_auto.py  # Gitè‡ªåŠ¨åŠ©ç† [å·¥å…·]
        ğŸ“„ manage_watchlist.py
        ğŸ“„ report_exporter.py
        ğŸ“„ reset_db.py
    ğŸ“‚ core/
        ğŸ“„ config.py  # å…¨å±€é…ç½®åŠ è½½å™¨ [æ ¸å¿ƒ]
        ğŸ“„ mapping.py  # ä¸­è‹±æ–‡æ˜ å°„å­—å…¸ [æ ¸å¿ƒ]
    ğŸ“‚ engine/
        ğŸ“„ radar.py
        ğŸ“„ updater.py  # æ•°æ®æ›´æ–°å¼•æ“ [æ ¸å¿ƒ]
==================================================

ğŸ’» CODE CONTENT
==================================================

------------------------------------------------------------
FILE PATH: .gitignore
------------------------------------------------------------
# System
.DS_Store
*.log
__pycache__/

# Python
venv/
*.pyc

# Configuration & Secrets (ç»å¯¹ä¸èƒ½ä¸Šä¼ !)
.env
core/__pycache__

# IDE
.vscode/
.idea/

# Data (å¯é€‰ï¼Œå¦‚æœä¸æƒ³ä¸Šä¼ ä¸´æ—¶ä¸‹è½½çš„æ•°æ®)
data/*
!data/.gitkeep

------------------------------------------------------------
FILE PATH: debug_stock.py
------------------------------------------------------------
# FILE PATH: debug_stock.py
import sys
import os
sys.path.append(os.path.abspath(os.path.dirname(__file__)))
from database.models import SessionLocal, DWSMarketIndicators, DWSFinanceStd, StockBasic
from sqlalchemy import func

def debug_haier():
    db = SessionLocal()
    ts_code = '600690.SH'
    
    # 1. æ£€æŸ¥åŸºç¡€æ ‡è®°
    basic = db.query(StockBasic).filter(StockBasic.ts_code == ts_code).first()
    print(f"ğŸ—ï¸ åŸºç¡€æ£€æŸ¥: {ts_code} | åç§°: {basic.name if basic else 'æœªæ‰¾åˆ°'}")

    # 2. æ£€æŸ¥ DWS è¡Œæƒ…æŒ‡æ ‡ (å–æœ€æ–°ä¸€æ¡)
    market = db.query(DWSMarketIndicators).filter(DWSMarketIndicators.ts_code == ts_code)\
               .order_by(DWSMarketIndicators.trade_date.desc()).first()
    if market:
        print(f"âš–ï¸ è¡Œæƒ…æ£€æŸ¥: æ—¥æœŸ={market.trade_date}, PE={market.pe_ttm}, PB={market.pb}, å¸‚å€¼={market.total_mv}")
    else:
        print("âŒ è¡Œæƒ…æ£€æŸ¥: DWSMarketIndicators ä¸­æ— æ•°æ®")

    # 3. æ£€æŸ¥ DWS æ ‡å‡†è´¢åŠ¡ (å–æœ€æ–°ä¸€æ¡)
    finance = db.query(DWSFinanceStd).filter(DWSFinanceStd.ts_code == ts_code)\
                .order_by(DWSFinanceStd.end_date.desc()).first()
    if finance:
        print(f"ğŸ° è´¢åŠ¡æ£€æŸ¥: æŠ¥å‘ŠæœŸ={finance.end_date}, ROE={finance.roe}, è´Ÿå€ºç‡={finance.debt_to_assets}")
    else:
        print("âŒ è´¢åŠ¡æ£€æŸ¥: DWSFinanceStd ä¸­æ— æ•°æ®")
    
    db.close()

if __name__ == "__main__":
    debug_haier()

------------------------------------------------------------
FILE PATH: main.py
------------------------------------------------------------
# FILE PATH: main.py
from nicegui import ui
from ui.layout import theme_setup, shared_menu
from ui.pages.console import ConsolePage
from ui.pages.watchlist import WatchlistPage
from ui.pages.radar import RadarPage

# --- æ³¨æ„ï¼šå…¨å±€ä½œç”¨åŸŸä¸¥ç¦å‡ºç° ui.xxx ç»„ä»¶è°ƒç”¨ ---

@ui.page('/')
def index_page():
    theme_setup()   # ç§»åŠ¨åˆ°å‡½æ•°å†…éƒ¨
    shared_menu()
    # å®ä¾‹åŒ–å¹¶æ¸²æŸ“â€œæ•°æ®ç»´æŠ¤â€é¡µé¢å†…å®¹
    ConsolePage().content()

@ui.page('/radar')
def radar_page():
    theme_setup()   # ç§»åŠ¨åˆ°å‡½æ•°å†…éƒ¨
    shared_menu()
    # å®ä¾‹åŒ–å¹¶æ¸²æŸ“â€œé€‰è‚¡é›·è¾¾â€é¡µé¢å†…å®¹
    RadarPage().content()

@ui.page('/watchlist')
def watchlist_page():
    theme_setup()   # ç§»åŠ¨åˆ°å‡½æ•°å†…éƒ¨
    shared_menu()
    # å®ä¾‹åŒ–å¹¶æ¸²æŸ“â€œè‡ªé€‰ç®¡ç†â€é¡µé¢å†…å®¹
    WatchlistPage().content()

# --- æ ¸å¿ƒä¿®å¤ï¼šä¿®æ”¹å¯åŠ¨å®ˆå« ---
# å…è®¸ NiceGUI çš„å¤šè¿›ç¨‹ (Multiprocessing) å’Œé‡è½½æœºåˆ¶æ­£å¸¸è¿è¡Œ
if __name__ in {"__main__", "__mp_main__"}:
    ui.run(
        title='Invest System V7.3',
        port=8080,
        reload=True,  # å¼€å¯çƒ­é‡è½½ï¼Œæ–¹ä¾¿æˆ‘ä»¬å®æ—¶è°ƒè¯• UI
        dark=False
    )

------------------------------------------------------------
FILE PATH: requirements.txt
------------------------------------------------------------
# Data Source
tushare>=1.2.89

# Data Processing
pandas>=2.0.0
numpy>=1.24.0

# Database (PostgreSQL + SQLAlchemy 2.0)
SQLAlchemy>=2.0.0
psycopg2-binary>=2.9.0

# UI Framework
nicegui>=1.4.0

# Utilities
python-dotenv>=1.0.0
pyyaml>=6.0
openpyxl>=3.1.0


------------------------------------------------------------
FILE PATH: run_backfill.py
------------------------------------------------------------
import time
from engine.updater import DataUpdater
from database.models import SessionLocal, StockBasic

def run_industrial_backfill():
    print("ğŸ—ï¸ === Invest System V7.3 å…¨é‡å†å²å›æº¯å¯åŠ¨ ===")
    print("ğŸ“… ç›®æ ‡èµ·ç‚¹: 2015-01-01 | ğŸ¯ ç›®æ ‡æ± : CSI800 + Watchlist")
    
    updater = DataUpdater()
    try:
        # 1. ç¡®ä¿ Universe åå•æ˜¯æœ€æ–°çš„
        print("\nStep 1: æ›´æ–°æ ‡çš„åå•ä¸ä¸­è¯800æ ‡è®°...")
        updater.sync_stock_list()
        
        # 2. è·å–æ‰€æœ‰éœ€è¦å›æº¯çš„æ ‡çš„
        universe = list(updater._get_universe_pool())
        total = len(universe)
        print(f"\nStep 2: å‡†å¤‡å¤„ç†å…± {total} åªæ ¸å¿ƒæ ‡çš„...")

        for i, ts_code in enumerate(universe):
            start_time = time.time()
            print(f"\n--- [{i+1}/{total}] æ­£åœ¨æ·±åº¦å¤„ç†: {ts_code} ---")
            
            try:
                # A. å‚ç›´è¡¥å…¨ ODS åŸå§‹æ•°æ® (è¡Œæƒ… + å››å¤§è´¢æŠ¥)
                print(f"  ğŸ“¥ æ­£åœ¨æŠ“å– 2015 è‡³ä»ŠåŸå§‹æ•°æ®...")
                updater.sync_stock_history(ts_code, start_date="20150101")
                
                # B. ç‚¼åˆ¶ DWS è¡Œæƒ…æŒ‡æ ‡ (QFQ + MAå‡çº¿)
                print(f"  ğŸ“ˆ æ­£åœ¨è®¡ç®— QFQ è¡Œæƒ…ä¸å‡çº¿...")
                updater.process_market_dws(ts_code) 
                
                # C. ç‚¼åˆ¶ DWS è´¢åŠ¡å®½è¡¨ (æ ‡å‡†åŒ– + è¡Œä¸šæ„ŸçŸ¥)
                print(f"  ğŸ’° æ­£åœ¨æ‰§è¡Œæ ‡å‡†åŒ–è´¢åŠ¡ç‚¼åˆ¶...")
                updater.process_finance_dws(ts_code)
                
                elapsed = time.time() - start_time
                print(f"  âœ… {ts_code} å¤„ç†å®Œæˆï¼Œè€—æ—¶: {elapsed:.2f}s")
                
                # é¢‘æ¬¡ä¿æŠ¤ï¼š2000ç§¯åˆ†è´¦æˆ·æ¯åˆ†é’Ÿé™200æ¬¡ï¼Œæ¯åªè‚¡ç¥¨å¤„ç†å®Œå¼ºåˆ¶ä¼‘æ¯ 0.5s
                time.sleep(0.5)

            except Exception as e:
                print(f"  âŒ {ts_code} å¤„ç†å¤±è´¥: {str(e)}")
                continue

        print("\nğŸ‰ === å…¨é‡å†å²å›æº¯ä»»åŠ¡åœ†æ»¡å®Œæˆï¼ ===")
        print("ğŸ’¡ å»ºè®®è¿è¡Œ python3 tools/audit_system.py è¿›è¡Œæœ€ç»ˆè´¨é‡å®¡è®¡ã€‚")

    finally:
        updater.close()

if __name__ == "__main__":
    run_industrial_backfill()

------------------------------------------------------------
FILE PATH: test_radar.py
------------------------------------------------------------
# FILE PATH: test_radar.py
import sys
import os

# 1. è·¯å¾„é˜²å¾¡ï¼šç¡®ä¿è„šæœ¬èƒ½è¯†åˆ«æ ¹ç›®å½•ä¸‹çš„æ¨¡å—
sys.path.append(os.path.abspath(os.path.dirname(__file__)))

from engine.radar import RadarEngine

def run_radar_smoke_test():
    print("ğŸ“¡ === é€‰è‚¡é›·è¾¾åç«¯å¼•æ“ (Bé˜¶æ®µ) å†’çƒŸæµ‹è¯• ===")
    
    # 2. åˆå§‹åŒ–å¼•æ“
    engine = RadarEngine()
    
    try:
        # 3. ä¼ å…¥ Coach è®¾å®šçš„å…¸å‹å‚æ•°è¿›è¡Œå›æµ‹
        # å‚æ•°å«ä¹‰ï¼šROE > 10%, PE < 25, ä»…é™ä¸­è¯800æ± 
        print("ğŸ” æ­£åœ¨æ‰«æä¸­è¯800æˆä»½è‚¡ (åŸºäº T-1 æ•°æ®)...")
        picks = engine.query(
            min_roe=10.0, 
            max_pe=25.0, 
            pool='CSI800',
            trend_up=True  # è¿‡æ»¤æ‰ 20 æ—¥å‡çº¿ä»¥ä¸‹çš„æ ‡çš„
        )
        
        # 4. ç»“æœéªŒè¯
        if picks.empty:
            print("âš ï¸ æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æ ‡çš„ï¼Œè¯·æ£€æŸ¥ï¼š")
            print("   - æ•°æ®åº“ DWS è¡¨æ˜¯å¦æœ‰æ•°æ®ï¼Ÿ")
            print("   - ç­›é€‰æ ‡å‡†æ˜¯å¦è¿‡ä¸¥ï¼Ÿ")
        else:
            print(f"ğŸ¯ æ‰«ææˆåŠŸï¼å‘ç° {len(picks)} åªç¬¦åˆæ ‡å‡†çš„â€œé»„é‡‘æ ‡çš„â€ï¼š")
            # æ‰“å°å‰ 10 åï¼ŒæŸ¥çœ‹å…³é”®æŒ‡æ ‡å¯¹é½æƒ…å†µ
            print("-" * 80)
            print(picks[['ts_code', 'name', 'roe', 'pe_ttm', 'total_mv_unit', 'last_report']].head(10))
            print("-" * 80)

    except Exception as e:
        print(f"âŒ å¼•æ“è¿è¡ŒæŠ¥é”™: {str(e)}")
    finally:
        engine.close()

if __name__ == "__main__":
    run_radar_smoke_test()

------------------------------------------------------------
FILE PATH: test_sync_engine.py
------------------------------------------------------------
# FILE PATH: test_sync_engine.py
import sys
import os

# ç¡®ä¿èƒ½åŠ è½½é¡¹ç›®æ¨¡å—
sys.path.append(os.path.abspath(os.path.dirname(__file__)))

from engine.updater import DataUpdater
from database.models import SessionLocal, ODSMarketDaily, ODSFinanceReport, DWSMarketIndicators, DWSFinanceStd
from sqlalchemy import func

def run_test_sync(ts_code='600519.SH'):
    print(f"ğŸ§ª === Invest System å¼•æ“å†’çƒŸæµ‹è¯•: {ts_code} ===")
    updater = DataUpdater()
    db = SessionLocal()

    try:
        # 1. æ¸…ç†è¯¥æ ‡çš„æ—¢æœ‰æ•°æ® (ä¸ºäº†æµ‹è¯•çº¯å‡€æ€§)
        print(f"ğŸ§¹ æ­£åœ¨æ¸…ç† {ts_code} çš„æ—§æ•°æ®...")
        db.query(ODSMarketDaily).filter(ODSMarketDaily.ts_code == ts_code).delete()
        db.query(ODSFinanceReport).filter(ODSFinanceReport.ts_code == ts_code).delete()
        db.commit()

        # 2. æ¨¡æ‹Ÿ S1/S2 åŒæ­¥è¿‡ç¨‹
        print(f"ğŸ“¥ æ­£åœ¨åŒæ­¥ ODS åŸå§‹æ•°æ® (ä» 2015-01-01 èµ·)...")
        # å¤‡æ³¨ï¼šç”±äºæ˜¯ç”Ÿæˆå™¨ï¼Œè¿™é‡Œæ¨¡æ‹Ÿ UI è°ƒç”¨å¾ªç¯
        updater.sync_stock_history(ts_code, start_date="20150101")
        
        # 3. éªŒè¯ ODS è½åœ°æƒ…å†µ
        daily_count = db.query(ODSMarketDaily).filter(ODSMarketDaily.ts_code == ts_code).count()
        finance_count = db.query(ODSFinanceReport).filter(ODSFinanceReport.ts_code == ts_code).count()
        print(f"âœ… ODS è½åœ°æ£€æŸ¥ï¼šè¡Œæƒ… {daily_count} è¡Œ, è´¢æŠ¥ {finance_count} ä»½ã€‚")

        # 4. æ‰§è¡Œ DWS ç‚¼åˆ¶
        print(f"âš™ï¸ æ­£åœ¨æ‰§è¡Œ DWS å±‚è¡ç”ŸæŒ‡æ ‡è®¡ç®—...")
        updater.process_market_dws(ts_code)
        updater.process_finance_dws(ts_code)

        # 5. éªŒè¯ DWS äº§å‡º
        latest_ma = db.query(DWSMarketIndicators).filter(DWSMarketIndicators.ts_code == ts_code).order_by(DWSMarketIndicators.trade_date.desc()).first()
        std_finance = db.query(DWSFinanceStd).filter(DWSFinanceStd.ts_code == ts_code).count()
        
        if latest_ma:
            print(f"ğŸ“ˆ DWS è¡Œæƒ…æ£€æŸ¥ï¼šæœ€æ–°æ”¶ç›˜ä»·(QFQ): {latest_ma.close_qfq:.2f}, MA250: {latest_ma.ma_250 or 'è®¡ç®—ä¸­'}")
        print(f"ğŸ’° DWS è´¢åŠ¡æ£€æŸ¥ï¼šå·²ç‚¼åˆ¶æ ‡å‡†åŒ–è´¢æŠ¥ {std_finance} æ¡ã€‚")

        if daily_count > 0 and finance_count > 0:
            print("\nğŸ‰ === æµ‹è¯•é€šè¿‡ï¼šåŒæ­¥å¼•æ“é“¾è·¯å·²æ‰“é€šï¼ ===")
        else:
            print("\nâŒ === æµ‹è¯•å¤±è´¥ï¼šæœªè·å–åˆ°æœ‰æ•ˆæ•°æ®ï¼Œè¯·æ£€æŸ¥ Tushare Token å’Œç½‘ç»œ === ")

    finally:
        db.close()
        updater.close()

if __name__ == "__main__":
    # å¦‚æœè¦æµ‹è¯•å¤šåªæ ‡çš„ï¼Œå¯ä»¥åœ¨æ­¤ä¿®æ”¹
    run_test_sync('600519.SH')

------------------------------------------------------------
FILE PATH: ui/__init__.py
------------------------------------------------------------


------------------------------------------------------------
FILE PATH: ui/layout.py
------------------------------------------------------------
from nicegui import ui

def theme_setup():
    # é‡‡ç”¨æ›´å†·é™çš„æç®€é…è‰²ï¼šæ·±ç°è“ (#37474f)
    ui.colors(primary='#37474f', secondary='#eceff1', accent='#607d8b')
    ui.query('body').style('font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif; background-color: #f8fafc;')

def shared_menu():
    """ä¾§è¾¹æ å¯¼èˆªç»„ä»¶ - è¾¹è·å¢å¼ºç‰ˆ"""
    with ui.left_drawer(value=True).classes('bg-slate-50').props('bordered'):
        # æ ‡å¿—åŒº
        ui.label('ğŸ—ï¸ INVEST SYSTEM').classes('text-lg font-bold mt-8 mb-4 ml-10 text-blue-900 tracking-tight')
        ui.separator().classes('mx-6')
        
        # å¯¼èˆªèœå•
        with ui.column().classes('w-full mt-6 gap-2'):
            # å¢åŠ  pl-10 (çº¦ 40px) çš„å·¦ä¾§å†…è¾¹è·ï¼Œç¡®ä¿æ–‡å­—å·¦å¯¹é½ä¸”æœ‰å‘¼å¸æ„Ÿ
            ui.button('æ•°æ®ç»´æŠ¤', icon='settings', on_click=lambda: ui.navigate.to('/')) \
                .props('flat no-caps').classes('w-full justify-start pl-10 text-slate-600 hover:text-blue-700 font-medium')
            
            ui.button('é€‰è‚¡é›·è¾¾', icon='radar', on_click=lambda: ui.navigate.to('/radar')) \
                .props('flat no-caps').classes('w-full justify-start pl-10 text-slate-600 hover:text-blue-700 font-medium')
            
            ui.button('è‡ªé€‰ç®¡ç†', icon='star_border', on_click=lambda: ui.navigate.to('/watchlist')) \
                .props('flat no-caps').classes('w-full justify-start pl-10 text-slate-600 hover:text-blue-700 font-medium')
            
            ui.button('ä¸ªè‚¡é€è§†', icon='insights', on_click=lambda: ui.navigate.to('/stock')) \
                .props('flat no-caps').classes('w-full justify-start pl-10 text-slate-600 hover:text-blue-700 font-medium')
        
        # åº•éƒ¨çŠ¶æ€
        with ui.column().classes('absolute-bottom w-full p-6 text-slate-400 text-[10px]'):
            ui.label('V7.3 Architect Edition')
            ui.label('DB FRESHNESS: 2025-12-19') # åŠ¨æ€æ—¥æœŸå¯åç»­å®è£…

------------------------------------------------------------
FILE PATH: ui/pages/__init__.py
------------------------------------------------------------


------------------------------------------------------------
FILE PATH: ui/pages/console.py
------------------------------------------------------------
# FILE PATH: ui/pages/console.py

from nicegui import ui
from engine.updater import DataUpdater
import asyncio
from datetime import datetime

class ConsolePage:
    def __init__(self):
        self.updater = DataUpdater()
        self.log_view = None

    async def run_task(self, task_func):
        """é€šç”¨å¼‚æ­¥ä»»åŠ¡å¤„ç†å™¨"""
        if self.log_view:
            self.log_view.push(f"[{datetime.now().strftime('%H:%M:%S')}] ğŸš€ å¯åŠ¨...")
        try:
            # è¿™é‡Œçš„ task_func æ˜¯ updater ä¸­çš„ç”Ÿæˆå™¨å‡½æ•°
            for message in task_func():
                self.log_view.push(f"[{datetime.now().strftime('%H:%M:%S')}] {message}")
                # å¼ºåˆ¶ UI åˆ·æ–°ï¼Œé˜²æ­¢æ—¥å¿—å †ç§¯å¯¼è‡´çš„æµè§ˆå™¨å¡é¡¿
                await asyncio.sleep(0.01)
        except Exception as e:
            self.log_view.push(f"âŒ è¿è¡Œå¼‚å¸¸: {str(e)}")

    def content(self):
        with ui.column().classes('w-full p-8 max-w-6xl mx-auto'):
            # æ ‡é¢˜æ›´åï¼šä»â€œç³»ç»Ÿæ§åˆ¶å°â€æ”¹ä¸ºâ€œæ•°æ®ç»´æŠ¤â€
            ui.label('âš™ï¸ æ•°æ®ç»´æŠ¤').classes('text-3xl font-light text-slate-700 mb-8')
            
            # å››ç£è´´å¸ƒå±€ (å¯¹é½ä½ çš„æˆªå›¾æ ·å¼)
            with ui.row().classes('w-full gap-6'):
                
                # ç£è´´ 1: æ—¥å¸¸åŒæ­¥ (S3/S4)
                with ui.card().props('flat bordered').classes('p-6 flex-1 bg-white'):
                    ui.label('æ—¥å¸¸åŒæ­¥').classes('text-xs text-slate-400 uppercase tracking-widest')
                    ui.label('æ”¶ç›˜æ•°æ®è¡¥å…¨').classes('text-lg font-medium mb-4')
                    ui.button('ä¸€é”®æ—¥æ›´', on_click=lambda: self.run_task(self.updater.run_daily_routine)) \
                        .props('flat color=primary').classes('px-4 border border-slate-200')

                # ç£è´´ 2: å…ƒæ•°æ®åŒæ­¥ (CSI800)
                with ui.card().props('flat bordered').classes('p-6 flex-1 bg-white'):
                    ui.label('åº•åº§ç»´æŠ¤').classes('text-xs text-slate-400 uppercase tracking-widest')
                    ui.label('åŒæ­¥æˆåˆ†è‚¡').classes('text-lg font-medium mb-4')
                    ui.button('åŒæ­¥ CSI800', on_click=lambda: self.run_task(self.updater.sync_stock_list)) \
                        .props('flat color=primary').classes('px-4 border border-slate-200')

                # ç£è´´ 3: åˆå§‹åŒ– (S5)
                with ui.card().props('flat bordered').classes('p-6 flex-1 bg-white'):
                    ui.label('åˆå§‹åŒ–').classes('text-xs text-slate-400 uppercase tracking-widest')
                    ui.label('æ ¸å¿ƒæ± å…¨å›æº¯').classes('text-lg font-medium mb-4')
                    ui.button('å¼€å§‹å›æº¯', on_click=lambda: self.run_task(self.updater.run_full_backfill)) \
                        .props('flat color=primary').classes('px-4 border border-slate-200')

                # ç£è´´ 4: ä¸“é¡¹åŒæ­¥ (S1/S2) - ä¿®æ­£ç‚¹
                with ui.card().props('flat bordered').classes('p-6 flex-1 bg-white'):
                    ui.label('ä¸“é¡¹åŒæ­¥').classes('text-xs text-slate-400 uppercase tracking-widest')
                    ui.label('è‡ªé€‰æ± æ·±åº¦åŒæ­¥').classes('text-lg font-medium mb-4')
                    ui.button('ç«‹å³åŒæ­¥è‡ªé€‰æ± ', on_click=lambda: self.run_task(self.updater.run_watchlist_backfill)) \
                        .props('flat color=primary').classes('px-4 border border-slate-200')

            # æç®€æ—¥å¿—åŒº
            ui.label('ğŸ“¡ å®æ—¶æ—¥å¿—').classes('text-sm font-medium text-slate-500 mt-12 mb-2')
            with ui.card().props('flat').classes('w-full bg-slate-900 overflow-hidden rounded-lg'):
                self.log_view = ui.log().classes('w-full h-80 text-emerald-400 font-mono text-[11px] p-6')

------------------------------------------------------------
FILE PATH: ui/pages/radar.py
------------------------------------------------------------
# FILE PATH: ui/pages/radar.py
from nicegui import ui
from engine.radar import RadarEngine
import pandas as pd
import json
import os
from datetime import datetime
from core.mapping import FIELD_MAPPING

class RadarPage:
    def __init__(self):
        self.engine = RadarEngine()
        self.grid = None
        self.stats_label = None
        self.current_df = pd.DataFrame()

    def update_data(self):
        """æ ¸å¿ƒäº¤äº’é€»è¾‘"""
        try:
            df = self.engine.query(
                min_roe=float(self.roe_slider.value),
                max_pe=float(self.pe_slider.value),
                max_pb=float(self.pb_slider.value),
                min_mv=float(self.mv_slider.value),
                pool=self.pool_select.value,
                trend_up=self.trend_toggle.value
            )
            self.current_df = df
            records = json.loads(df.to_json(orient='records', date_format='iso'))
            
            if self.stats_label:
                count = len(records)
                self.stats_label.set_text(f"ğŸ¯ é›·è¾¾å‘ç°: {count} åªæ ‡çš„")
                self.stats_label.classes('text-emerald-600' if count > 0 else 'text-rose-600', remove='text-rose-600 text-emerald-600')

            if self.grid:
                self.grid.options['rowData'] = records
                self.grid.update()
        except Exception as e:
            ui.notify(f"æ‰«æå¼‚å¸¸: {str(e)}", type='negative')

    def get_export_path(self):
        """Chrome é£æ ¼å¯¼å‡ºè·¯å¾„"""
        downloads_path = os.path.join(os.path.expanduser("~"), "Downloads")
        target_dir = os.path.join(downloads_path, "InvestSystem_Exports")
        os.makedirs(target_dir, exist_ok=True)
        return target_dir

    def export_data(self):
        """å¯¼å‡ºç»“æœ"""
        if self.current_df.empty:
            ui.notify("ç»“æœä¸ºç©º", type='warning')
            return
        try:
            target_dir = self.get_export_path()
            filename = f"Radar_Picks_{datetime.now().strftime('%m%d_%H%M')}.xlsx"
            filepath = os.path.join(target_dir, filename)
            available_cols = [col for col in self.current_df.columns if col in FIELD_MAPPING]
            export_df = self.current_df[available_cols].rename(columns=FIELD_MAPPING)
            export_df.to_excel(filepath, index=False)
            ui.notify(f"ğŸš€ å·²å¯¼å‡º: {filename}", type='positive')
        except Exception as e:
            ui.notify(f"å¯¼å‡ºå¤±è´¥: {str(e)}")

    async def add_to_watchlist(self, event):
        """å¤„ç†è¡¨æ ¼å†…çš„â€˜åŠ å…¥è‡ªé€‰â€™ç‚¹å‡»äº‹ä»¶"""
        # ä»…å“åº”â€˜æ“ä½œâ€™åˆ—çš„ç‚¹å‡»
        if event.args['colId'] != 'action':
            return
        
        row_data = event.args['data']
        ts_code = row_data['ts_code']
        name = row_data['name']
        
        # å®ä¾‹åŒ– DB ä¼šè¯ï¼ˆæ³¨æ„ï¼šRadarPage ç›®å‰æœªæŒæœ‰ db å®ä¾‹ï¼Œå»ºè®®å³ç”¨å³åˆ ï¼‰
        from database.models import SessionLocal, Watchlist
        db = SessionLocal()
        
        try:
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ 
            exists = db.query(Watchlist).filter(Watchlist.ts_code == ts_code).first()
            if exists:
                ui.notify(f"âš ï¸ {name} å·²åœ¨è‡ªé€‰æ± ä¸­", type='warning')
                return
                
            # å†™å…¥è‡ªé€‰ 
            new_item = Watchlist(
                ts_code=ts_code, name=name, industry=row_data.get('industry'),
                group_name='é›·è¾¾å‘ç°', weight=1.0
            )
            db.add(new_item)
            db.commit()
            ui.notify(f"ğŸŒŸ å·²å°† {name} åŠ å…¥è‡ªé€‰æ± ", type='positive')
        except Exception as e:
            db.rollback()
            ui.notify(f"æ·»åŠ å¤±è´¥: {str(e)}", type='negative')
        finally:
            db.close()

    def _create_compact_control(self, label, min_v, max_v, step_v, default_v, unit=""):
        """ã€æ¶æ„å¸ˆé‡åˆ¶ã€‘ä¼˜åŒ–å®½åº¦çš„æ°´å¹³æ§åˆ¶ç»„ """
        with ui.row().classes('items-center gap-3 w-full px-2 py-1 hover:bg-slate-50 rounded transition-all'):
            # æ ‡ç­¾åŒº
            ui.label(label).classes('text-[11px] font-bold text-slate-400 uppercase w-12 leading-tight')
            # æ»‘å—åŒº
            slider = ui.slider(min=min_v, max=max_v, step=step_v, value=default_v).classes('flex-grow')
            # æ•°å­—æ¡† (æ‰©å®¹è‡³ w-24ï¼Œå¹¶å¢åŠ å¤–è¾¹è·)
            number = ui.number(value=default_v, min=min_v, max=max_v, step=step_v, format='%.1f') \
                .props('dense outlined size=10').classes('w-24 text-[12px] bg-white') \
                .bind_value(slider, 'value')
            
            ui.label(unit).classes('text-[10px] text-slate-400 w-4')
            
            slider.on_value_change(self.update_data)
            number.on_value_change(self.update_data)
            return slider

    def content(self):
        # ä¿®æ”¹ 1ï¼šå‡çº§ä¸ºå…¨å±æµå¼å¸ƒå±€ (max-w-full)
        with ui.column().classes('w-full p-6 max-w-full mx-auto gap-6 bg-slate-50'):
            # é¡¶å±‚å¤´éƒ¨
            with ui.row().classes('w-full items-center justify-between'):
                with ui.row().classes('items-center gap-4'):
                    ui.label('ğŸ“¡ é€‰è‚¡é›·è¾¾').classes('text-2xl font-light text-slate-700')
                    self.pool_select = ui.select(
                        options={'CSI800': 'ä¸­è¯800', 'Watchlist': 'è‡ªé€‰æ± ', 'All': 'å…¨å¸‚åœº'},
                        value='CSI800'
                    ).props('dense flat').classes('w-32').on_value_change(self.update_data)
                    self.trend_toggle = ui.switch('è¶‹åŠ¿å‘ä¸Š', value=False).props('dense').on_value_change(self.update_data)
                
                with ui.row().classes('gap-3'):
                    self.stats_label = ui.label('æ­£åœ¨é¢„çƒ­...').classes('text-sm font-bold font-mono py-1')
                    ui.button(icon='download', on_click=self.export_data).props('flat round dense').tooltip('å¯¼å‡º Excel')

            # 2. æˆ˜ç•¥å‚æ•°åŒº
            with ui.card().props('flat bordered').classes('w-full p-2 bg-white rounded-lg shadow-sm'):
                with ui.grid(columns=4).classes('w-full divide-x divide-slate-100'):
                    self.roe_slider = self._create_compact_control('ROE%', 0, 40, 0.5, 10)
                    self.pe_slider = self._create_compact_control('PE', 1, 100, 1, 25)
                    self.pb_slider = self._create_compact_control('PB', 0.1, 10, 0.1, 3)
                    self.mv_slider = self._create_compact_control('å¸‚å€¼', 0, 5000, 50, 100, "äº¿")

            # 3. ç»“æœç½‘æ ¼
            with ui.card().props('flat bordered').classes('w-full p-0 overflow-hidden bg-white rounded-lg'):
                self.grid = ui.aggrid({
                    'columnDefs': [
                        {'headerName': 'æ“ä½œ', 'field': 'action', 'width': 70, 'pinned': 'left',
                         ':cellRenderer': 'params => "â­"'},
                        {'headerName': 'ä»£ç ', 'field': 'ts_code', 'width': 100, 'pinned': 'left'},
                        {'headerName': 'åç§°', 'field': 'name', 'width': 110, 'pinned': 'left'},
                        {'headerName': 'å…¥é€‰ç†ç”±/é£é™©æç¤º', 'field': 'selection_reason', 'minWidth': 250,
                         'cellClass': 'text-slate-500 italic text-xs'},
                        {'headerName': 'è¡Œä¸š', 'field': 'industry', 'width': 130},
                        {'headerName': 'ROE %', 'field': 'roe', 'width': 90, 'sortable': True, 
                         ':valueFormatter': 'params => params.value ? params.value.toFixed(2) : "0.00"',
                         'cellClassRules': {
                             'bg-emerald-50 text-emerald-700 font-bold': 'x >= 20',
                             'text-rose-600': 'x < 10'
                         }},
                        {'headerName': 'PE(TTM)', 'field': 'pe_ttm', 'width': 90, 'sortable': True},
                        {'headerName': 'PB', 'field': 'pb', 'width': 85, 'sortable': True},
                        {'headerName': 'å‡€ç°æ¯”', 'field': 'ocf_to_net_profit', 'width': 90, 'sortable': True,
                         ':valueFormatter': 'params => params.value ? params.value.toFixed(2) : "0.00"',
                         'cellClassRules': {
                             'bg-blue-50 text-blue-700': 'x >= 1.2',
                             'text-amber-700': 'x < 0.8'
                         }},
                        {'headerName': 'åƒåœ¾èµ„äº§%', 'field': 'toxic_asset_ratio', 'width': 100, 
                         ':valueFormatter': 'params => params.value ? (params.value * 100).toFixed(2) + "%" : "0.00%"'},
                        {'headerName': 'å¸‚å€¼(äº¿)', 'field': 'total_mv_unit', 'width': 105, 'sortable': True},
                        {'headerName': 'ä»Šæ—¥æ¶¨è·Œ', 'field': 'pct_chg', 'width': 100, 'sortable': True, ':cellRenderer': 'p => p.value > 0 ? "ğŸ”´ " + p.value + "%" : "ğŸŸ¢ " + p.value + "%"'},
                        {'headerName': 'æœ€æ–°è´¢æŠ¥', 'field': 'last_report', 'width': 105},
                    ],
                    'rowData': [],
                    'pagination': True,
                    'paginationPageSize': 50,
                    'autoSizeStrategy': {'type': 'fitCellContents'},
                    'theme': 'balham',
                    'defaultColDef': {'sortable': True, 'filter': True, 'resizable': True} # å…è®¸ç”¨æˆ·æ‰‹åŠ¨è°ƒèŠ‚
                }).classes('w-full h-[600px] shadow-lg border-none').on('cellClicked', self.add_to_watchlist)

            # ä¿®æ”¹ 3ï¼šå‡çº§ç‰ˆâ€œæ·±è“å®¡è®¡çœ‹æ¿â€
            with ui.card().props('flat').classes('w-full bg-slate-900 text-white p-6 rounded-xl'):
                with ui.row().classes('items-center gap-4'):
                    ui.icon('security', color='primary').classes('text-3xl')
                    ui.label('é›·è¾¾å®¡è®¡é€»è¾‘çœ‹æ¿ (V7.4 Forensic Edition)').classes('text-xl font-bold tracking-tight')
                
                ui.separator().classes('my-4 bg-slate-700')
                
                with ui.grid(columns=4).classes('w-full gap-8'):
                    with ui.column():
                        ui.label('ğŸ›¡ï¸ åˆ©æ¶¦æˆè‰²').classes('text-blue-400 text-xs font-bold uppercase')
                        ui.label('å‡€ç°æ¯” â‰¥ 0.8 (å‰”é™¤çº¸é¢å¯Œè´µ)').classes('text-sm')
                    with ui.column():
                        ui.label('ğŸ” èµ„äº§å®¡è®¡').classes('text-blue-400 text-xs font-bold uppercase')
                        ui.label('åƒåœ¾èµ„äº§ < 5% (ä¸¥é˜²è´¢åŠ¡é»‘æ´)').classes('text-sm')
                    with ui.column():
                        ui.label('ğŸ° æ ¸å¿ƒç›ˆåˆ©').classes('text-blue-400 text-xs font-bold uppercase')
                        ui.label(f'ROE (æ‰£é) â‰¥ {self.roe_slider.value}%').classes('text-sm')
                    with ui.column():
                        ui.label('âš–ï¸ ä¼°å€¼è¾¹ç•Œ').classes('text-blue-400 text-xs font-bold uppercase')
                        ui.label(f'PE â‰¤ {self.pe_slider.value} | PB â‰¤ {self.pb_slider.value}').classes('text-sm')

            ui.timer(0.5, self.update_data, once=True)

------------------------------------------------------------
FILE PATH: ui/pages/watchlist.py
------------------------------------------------------------
from nicegui import ui
from database.models import SessionLocal, Watchlist, StockBasic
from core.mapping import FIELD_MAPPING
from datetime import datetime
from sqlalchemy import or_

class WatchlistPage:
    def __init__(self):
        self.db = SessionLocal()
        self.grid = None
        # é¢„åŠ è½½è‚¡ç¥¨å­—å…¸ç”¨äºæœç´¢æç¤º (ä»£ç  + åç§°)
        self.stock_options = self._get_search_options()

    def _get_search_options(self):
        """ç¼“å­˜å…¨é‡è‚¡ç¥¨åˆ—è¡¨ç”¨äºä¸‹æ‹‰æç¤º"""
        stocks = self.db.query(StockBasic).all()
        return {s.ts_code: f"{s.symbol} | {s.name}" for s in stocks}

    def _fetch_data(self):
        """è¯»å–æ•°æ®å¹¶æŒ‰æƒé‡æ’åº """
        rows = self.db.query(Watchlist).order_by(Watchlist.weight.desc()).all()
        return [
            {
                'ts_code': r.ts_code,
                'name': r.name,
                'industry': r.industry,
                'group_name': r.group_name or 'é»˜è®¤',
                'weight': r.weight,
                'add_time': r.add_time.strftime('%Y-%m-%d')
            } for r in rows
        ]

    async def update_cell(self, event):
        """è¡Œå†…ç¼–è¾‘åŒæ­¥è‡³æ•°æ®åº“"""
        row_data = event.args['data']
        field = event.args['colId']
        new_val = event.args['newValue']
        
        target = self.db.query(Watchlist).filter(Watchlist.ts_code == row_data['ts_code']).first()
        if target:
            setattr(target, field, new_val)
            self.db.commit()
            ui.notify(f"å·²æ›´æ–° {target.name} çš„{field}")

    async def add_stock(self, value):
        """å¢å¼ºç‰ˆæ·»åŠ é€»è¾‘ï¼šå¤„ç†ä¸‹æ‹‰é€‰æ‹©çš„å€¼æˆ–æ‰‹åŠ¨è¾“å…¥çš„å€¼"""
        if not value:
            return
            
        # å¦‚æœç”¨æˆ·é€‰çš„æ˜¯æç¤ºé¡¹ï¼Œvalue æ˜¯ ts_codeï¼›å¦‚æœæ˜¯ç›²æ‰“è¾“å…¥ï¼Œvalue ä¹Ÿæ˜¯å­—ç¬¦ä¸²
        ts_code = value.upper().strip()
        
        # åŸºç¡€æ ¡éªŒä¸å†™å…¥é€»è¾‘ (å¤ç”¨ä¹‹å‰é€»è¾‘)
        basic = self.db.query(StockBasic).filter(StockBasic.ts_code == ts_code).first()
        if not basic:
            ui.notify(f'æ ‡çš„ä¸å­˜åœ¨ï¼Œè¯·æ£€æŸ¥ä»£ç æ ¼å¼', type='negative')
            return
            
        if self.db.query(Watchlist).filter(Watchlist.ts_code == ts_code).first():
            ui.notify(f'{basic.name} å·²åœ¨è‡ªé€‰æ± ä¸­', type='info')
            return

        new_item = Watchlist(
            ts_code=basic.ts_code, name=basic.name, 
            industry=basic.industry, weight=1.0, group_name='æ ¸å¿ƒè§‚æœ›'
        )
        self.db.add(new_item)
        self.db.commit()
        ui.notify(f'âœ… å·²æˆåŠŸæ·»åŠ : {basic.name}', type='positive')
        self.update_grid()

    def update_grid(self):
        if self.grid:
            self.grid.options['rowData'] = self._fetch_data()
            self.grid.update()

    def content(self):
        with ui.column().classes('w-full p-8 max-w-7xl mx-auto'):
            ui.label('ğŸŒŸ è‡ªé€‰æ± ç®¡ç†').classes('text-3xl font-light text-slate-700 mb-6')

            # ğŸ› ï¸ äº¤äº’ä¿®æ­£ï¼šæœç´¢æ¡† + æŒ‰é’® + ç¾åŒ–åçš„åˆ é™¤æŒ‰é’®
            with ui.row().classes('w-full items-center gap-4 mb-6 bg-white p-4 rounded-lg border border-slate-100 shadow-sm'):
                
                # æœç´¢æ¡†éƒ¨åˆ†
                search_box = ui.select(
                    options=self.stock_options, 
                    with_input=True, 
                    label='è¾“å…¥ä»£ç  (å¦‚ 600519.SH) æˆ–åç§°',
                ).classes('w-96').props('use-input fill-input hide-selected outlined dense')
                
                # æ·»åŠ æŒ‰é’®
                ui.button('æ·»åŠ ', icon='add', on_click=lambda: self.add_stock(search_box.value)) \
                    .props('flat color=primary').classes('px-4 border border-slate-200 rounded-md')

                search_box.on('keydown.enter', lambda: self.add_stock(search_box.value))

                ui.label('ğŸ’¡ æç¤ºï¼šåŒå‡»è¡¨æ ¼ä¿®æ”¹åˆ†ç»„/æƒé‡').classes('text-xs text-slate-400 ml-2')
                
                # --- ç¾åŒ–åçš„åˆ é™¤æŒ‰é’® ---
                # åˆå§‹çŠ¶æ€ä¸º flat çº¢è‰²ï¼Œå¸¦åˆ é™¤å›¾æ ‡
                self.delete_btn = ui.button('ç§»é™¤é€‰ä¸­', icon='delete_outline', on_click=self.confirm_delete) \
                    .props('flat color=red').classes('ml-auto px-4 hover:bg-red-50 rounded-md transition-all text-sm font-medium')

            # AG Grid
            self.grid = ui.aggrid({
                'columnDefs': [
                    {'headerName': 'ä»£ç ', 'field': 'ts_code', 'checkboxSelection': True, 'headerCheckboxSelection': True},
                    {'headerName': 'åç§°', 'field': 'name'},
                    {'headerName': 'åˆ†ç»„', 'field': 'group_name', 'editable': True, 'cellClass': 'bg-blue-50'},
                    {'headerName': 'æƒé‡', 'field': 'weight', 'editable': True, 'cellClass': 'bg-green-50', 'sort': 'desc'},
                    {'headerName': 'æ‰€å±è¡Œä¸š', 'field': 'industry'},
                ],
                'rowData': self._fetch_data(),
                'rowSelection': 'multiple',
                'theme': 'balham',
                'stopEditingWhenCellsLoseFocus': True
            }).classes('w-full h-[600px] bg-white rounded-lg shadow-sm').on('cellValueChanged', self.update_cell)

    async def confirm_delete(self):
        """å¼¹å‡ºäºŒæ¬¡ç¡®è®¤å¯¹è¯æ¡†"""
        selected = await self.grid.get_selected_rows()
        if not selected:
            ui.notify('è¯·å…ˆåœ¨å·¦ä¾§å‹¾é€‰è¦ç§»é™¤çš„è‚¡ç¥¨', type='warning')
            return

        with ui.dialog() as dialog, ui.card().classes('p-6'):
            ui.label(f'âš ï¸ ç¡®å®šè¦ä»è‡ªé€‰æ± ç§»é™¤è¿™ {len(selected)} åªè‚¡ç¥¨å—ï¼Ÿ').classes('text-lg font-medium')
            ui.label('æ­¤æ“ä½œå°†åˆ é™¤æ‚¨é…ç½®çš„åˆ†ç»„ä¸æƒé‡ä¿¡æ¯ã€‚').classes('text-sm text-slate-500 mb-4')
            with ui.row().classes('w-full justify-end gap-2'):
                ui.button('å–æ¶ˆ', on_click=dialog.close).props('flat')
                ui.button('ç¡®å®šç§»é™¤', color='red', on_click=lambda: self.execute_delete(selected, dialog)).props('unelevated')
        dialog.open()

    async def execute_delete(self, selected, dialog):
        """æ‰§è¡Œå®é™…ç‰©ç†åˆ é™¤"""
        for row in selected:
            self.db.query(Watchlist).filter(Watchlist.ts_code == row['ts_code']).delete()
        self.db.commit()
        dialog.close()
        ui.notify(f'ğŸ—‘ï¸ å·²æˆåŠŸç§»é™¤æ‰€é€‰æ ‡çš„', type='info')
        self.update_grid()

    def __del__(self):
        self.db.close()

------------------------------------------------------------
FILE PATH: database/models.py
------------------------------------------------------------
from sqlalchemy import Column, String, Float, Boolean, DateTime, Integer, Text, PrimaryKeyConstraint, func
from sqlalchemy.dialects.postgresql import JSONB
from sqlalchemy.orm import DeclarativeBase, sessionmaker
from sqlalchemy import create_engine
from datetime import datetime
from core.config import settings

# 1. æ•°æ®åº“è¿æ¥å¼•æ“
engine = create_engine(settings.DB_URL)

# 2. ä¼šè¯å·¥å‚ (è¿™å°±æ˜¯æŠ¥é”™ç¼ºå¤±çš„éƒ¨åˆ†)
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

class Base(DeclarativeBase):
    pass

# --- Meta Data Layer (åŸºç¡€ä¿¡æ¯) ---

class StockBasic(Base):
    """
    è‚¡ç¥¨åŸºç¡€ä¿¡æ¯è¡¨ (PRD 4.1)
    """
    __tablename__ = "stock_basic"

    ts_code = Column(String(20), primary_key=True, comment="TSä»£ç ")
    symbol = Column(String(20), comment="è‚¡ç¥¨ä»£ç ")
    name = Column(String(50), comment="è‚¡ç¥¨åç§°")
    area = Column(String(50), comment="åœ°åŸŸ")
    industry = Column(String(50), comment="æ‰€å±è¡Œä¸š")
    market = Column(String(50), comment="å¸‚åœºç±»å‹")
    list_date = Column(String(8), comment="ä¸Šå¸‚æ—¥æœŸ")
    
    # æ ¸å¿ƒå­—æ®µ: æ ‡è®°æ˜¯å¦ä¸ºä¸­è¯800 (PRD 1.2)
    is_csi800 = Column(Boolean, default=False, index=True, comment="æ˜¯å¦ä¸­è¯800")

class Watchlist(Base):
    """
    ç”¨æˆ·è‡ªé€‰è‚¡æ±  (PRD 1.2)
    """
    __tablename__ = "watchlist"

    ts_code = Column(String(20), primary_key=True)
    name = Column(String(50))
    industry = Column(String(50))
    group_name = Column(String(50), default='æ ¸å¿ƒè§‚æœ›', comment="è‡ªé€‰åˆ†ç»„")
    weight = Column(Float, default=1.0, comment="æƒé‡")
    add_time = Column(DateTime, default=datetime.now)

# --- ODS Layer (åŸå§‹æ•°æ®å±‚ - Store Everything) ---

class ODSMarketDaily(Base):
    """
    æ—¥çº¿è¡Œæƒ… (PRD 2.1)
    """
    __tablename__ = "ods_market_daily"

    ts_code = Column(String(20), primary_key=True)
    trade_date = Column(String(8), primary_key=True, index=True)
    open = Column(Float)
    high = Column(Float)
    low = Column(Float)
    close = Column(Float)
    pre_close = Column(Float)
    change = Column(Float)
    pct_chg = Column(Float)
    vol = Column(Float, comment="æˆäº¤é‡(æ‰‹)")
    amount = Column(Float, comment="æˆäº¤é¢(åƒå…ƒ)")

class ODSAdjFactor(Base):
    """
    å¤æƒå› å­ (PRD 2.1)
    """
    __tablename__ = "ods_adj_factor"

    ts_code = Column(String(20), primary_key=True)
    trade_date = Column(String(8), primary_key=True)
    adj_factor = Column(Float)

class ODSDailyBasic(Base):
    """ODS: æ¯æ—¥æŒ‡æ ‡åŸå§‹è¡¨ (PE/PB/æ¢æ‰‹ç‡/æ€»å¸‚å€¼)"""
    __tablename__ = 'ods_daily_basic'

    ts_code = Column(String(20), primary_key=True)
    trade_date = Column(String(8), primary_key=True)
    pe_ttm = Column(Float)
    pb = Column(Float)
    turnover_rate = Column(Float)
    total_mv = Column(Float) # æ€»å¸‚å€¼
    update_flag = Column(DateTime, default=func.now())

class ODSFinanceReport(Base):
    """
    é€šç”¨è´¢åŠ¡æŠ¥è¡¨å­˜å‚¨ (PRD 4.2)
    ç­–ç•¥: JSONB å®½è¡¨æ¨¡å¼
    """
    __tablename__ = "ods_finance_report"

    # å¤åˆä¸»é”®ï¼šå¿…é¡»åŒ…å« category ä»¥åŒºåˆ† income/balancesheet/cashflow æ¥å£æ•°æ® [cite: 8, 93-95]
    ts_code = Column(String(20), primary_key=True)
    end_date = Column(String(8), primary_key=True, comment="æŠ¥å‘ŠæœŸ")
    report_type = Column(String(10), primary_key=True, comment="æŠ¥è¡¨ç±»å‹")
    update_flag = Column(String(5), primary_key=True, default='0', comment="æ›´æ–°æ ‡è®°")
    category = Column(String(20), primary_key=True, index=True, comment="æŠ¥è¡¨ç±»åˆ«") # å‡çº§ä¸ºä¸»é”®
    
    ann_date = Column(String(8), comment="å…¬å‘Šæ—¥æœŸ")
    
    # æ ¸å¿ƒå­—æ®µ
    data = Column(JSONB, comment="åŸå§‹è´¢åŠ¡æ•°æ®JSON")

# --- DWS Layer (æ ‡å‡†æœåŠ¡å±‚ - Strict Logic) ---

class DWSMarketIndicators(Base):
    """
    å¸‚åœºè¡ç”ŸæŒ‡æ ‡è¡¨ (PRD 2.2)
    åŒ…å«: å¤æƒåå‡çº¿, PE/PB/å¸‚å€¼
    """
    __tablename__ = "dws_market_indicators"

    ts_code = Column(String(20), primary_key=True)
    trade_date = Column(String(8), primary_key=True, index=True)
    
    # åŸºç¡€æŒ‡æ ‡ (æ¥è‡ª daily_basic)
    pe_ttm = Column(Float, comment="PE(TTM)")
    pb = Column(Float, comment="å¸‚å‡€ç‡")
    total_mv = Column(Float, comment="æ€»å¸‚å€¼")
    turnover_rate = Column(Float, comment="æ¢æ‰‹ç‡")
    
    # è®¡ç®—æŒ‡æ ‡ (åŸºäº QFQ)
    close_qfq = Column(Float, comment="å‰å¤æƒæ”¶ç›˜ä»·")
    ma_20 = Column(Float, comment="20æ—¥å‡çº¿")
    ma_50 = Column(Float, comment="50æ—¥å‡çº¿")
    ma_120 = Column(Float, comment="120æ—¥å‡çº¿")
    ma_250 = Column(Float, comment="250æ—¥å‡çº¿ (å¹´çº¿)")
    # PRD 3.1 å®¹é”™: è¡Œæ•°<850æ—¶ï¼Œma_850ä¸ºNULL
    ma_850 = Column(Float, comment="850æ—¥å‡çº¿ (ä¸‰å¹´çº¿)")

class DWSFinanceStd(Base):
    """
    æ ‡å‡†åŒ–è´¢åŠ¡å®½è¡¨ (PRD 2.2)
    é€»è¾‘: ä»…å­˜å‚¨ report_type='1' (åˆå¹¶æŠ¥è¡¨) çš„æ¸…æ´—åæ•°æ®
    """
    __tablename__ = "dws_finance_std"

    ts_code = Column(String(20), primary_key=True)
    end_date = Column(String(8), primary_key=True, index=True, comment="æŠ¥å‘ŠæœŸ")
    ann_date = Column(String(8), comment="å…¬å‘Šæ—¥æœŸ")
    
    # æ ¸å¿ƒå­—æ®µ (æ˜ å°„è‡ª Mapping)
    revenue = Column(Float, comment="è¥ä¸šæ”¶å…¥")
    n_income_attr_p = Column(Float, comment="å½’æ¯å‡€åˆ©æ¶¦")
    n_cashflow_act = Column(Float, comment="ç»è¥ç°é‡‘æµ")
    debt_to_assets = Column(Float, comment="èµ„äº§è´Ÿå€ºç‡")
    roe = Column(Float, comment="ROE")
    grossprofit_margin = Column(Float, comment="æ¯›åˆ©ç‡")
    
    # --- V7.4 æ–°å¢ï¼šå®¡è®¡ä¸é˜²ä¼ªç‰©ç†å­—æ®µ [å…³é”®ä¿®å¤] ---
    # A. åˆ©æ¶¦æˆè‰²
    ocf_to_net_profit = Column(Float, comment="å‡€ç°æ¯”(ç»è¥ç°é‡‘æµ/å½’æ¯å‡€åˆ©)")
    
    # B. èµ„äº§æ°´åˆ†
    toxic_asset_ratio = Column(Float, comment="åƒåœ¾èµ„äº§å æ¯”(å…¶ä»–åº”æ”¶+é¢„ä»˜+å¾…æ‘Š)/æ€»èµ„äº§")
    
    # C. å¢é•¿åŒ¹é…
    ar_rev_gap = Column(Float, comment="åº”æ”¶è¥æ”¶å¢é€Ÿå·®")
    
    # D. æ³¡æ²«æŒ‡æ ‡
    goodwill_net_asset_ratio = Column(Float, comment="å•†èª‰/å½’æ¯å‡€èµ„äº§")

    # --- è¾…åŠ©è®¡ç®—ç”¨çš„åŸå§‹ç§‘ç›® ---
    oth_receiv = Column(Float, comment="å…¶ä»–åº”æ”¶æ¬¾")
    prepayment = Column(Float, comment="é¢„ä»˜æ¬¾é¡¹")
    goodwill = Column(Float, comment="å•†èª‰")
    total_assets = Column(Float, comment="èµ„äº§æ€»è®¡")
    total_hldr_eqy_exc_min_int = Column(Float, comment="å½’æ¯å‡€èµ„äº§")

# --- å·¥å…·å‡½æ•° ---
def init_db():
    """åˆå§‹åŒ–æ•°æ®åº“è¡¨ç»“æ„"""
    Base.metadata.create_all(bind=engine)

------------------------------------------------------------
FILE PATH: interface/tushare_client.py
------------------------------------------------------------
import tushare as ts
import pandas as pd
import time
from core.config import settings
from functools import wraps

class TushareClient:
    def __init__(self):
        if not settings.TS_TOKEN:
            raise ValueError("Tushare Token is missing in settings")
        
        # åˆå§‹åŒ– Pro æ¥å£ (PRD 1.1)
        self.pro = ts.pro_api(settings.TS_TOKEN)
        print(f"ğŸ“¡ Tushare Client Initialized. Token: {settings.TS_TOKEN[:5]}***")

    def retry_policy(func):
        """
        è£…é¥°å™¨: Tushare å®˜æ–¹å»ºè®®çš„é‡è¯•æœºåˆ¶
        Ref: Tushare PDF [cite: 18]
        """
        @wraps(func)
        def wrapper(*args, **kwargs):
            max_retries = 3
            for i in range(max_retries):
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    print(f"âš ï¸ API Warning: {e}, Retrying ({i+1}/{max_retries})...")
                    time.sleep(1)
            raise Exception(f"âŒ API Failed after {max_retries} retries.")
        return wrapper

    # --- 1. åŸºç¡€æ•°æ® ---
    
    @retry_policy
    def fetch_stock_basic(self):
        """è·å–å…¨å¸‚åœºè‚¡ç¥¨åˆ—è¡¨ (PRD 2.1)"""
        fields = 'ts_code,symbol,name,area,industry,market,list_date'
        return self.pro.stock_basic(exchange='', list_status='L', fields=fields)

    # --- 2. å¸‚åœºè¡Œæƒ… (Column Storage) ---

    @retry_policy
    def fetch_daily(self, ts_code=None, trade_date=None, start_date=None, end_date=None):
        """
        æ—¥çº¿è¡Œæƒ…
        Ref: Tushare PDF Daily Interface [cite: 252]
        """
        return self.pro.daily(ts_code=ts_code, trade_date=trade_date, 
                              start_date=start_date, end_date=end_date)

    @retry_policy
    def fetch_adj_factor(self, ts_code=None, trade_date=None, start_date=None, end_date=None):
        """å¤æƒå› å­"""
        return self.pro.adj_factor(ts_code=ts_code, trade_date=trade_date, 
                                   start_date=start_date, end_date=end_date)

    # --- 3. è´¢åŠ¡æ•°æ® (JSONB Storage) ---
    @retry_policy
    def fetch_income(self, ts_code=None, ann_date=None, start_date=None, end_date=None, period=None):
        """åˆ©æ¶¦è¡¨ - å°†å‚æ•°è®¾ä¸ºå¯é€‰ï¼Œæ”¯æŒå‚ç›´å›æº¯ [cite: 631-632]"""
        return self.pro.income(ts_code=ts_code, ann_date=ann_date, 
                               start_date=start_date, end_date=end_date, period=period)

    @retry_policy
    def fetch_balancesheet(self, ts_code=None, ann_date=None, start_date=None, end_date=None, period=None):
        """èµ„äº§è´Ÿå€ºè¡¨ [cite: 654-655]"""
        return self.pro.balancesheet(ts_code=ts_code, ann_date=ann_date, 
                                     start_date=start_date, end_date=end_date, period=period)

    @retry_policy
    def fetch_cashflow(self, ts_code=None, ann_date=None, start_date=None, end_date=None, period=None):
        """ç°é‡‘æµé‡è¡¨ [cite: 692-693]"""
        return self.pro.cashflow(ts_code=ts_code, ann_date=ann_date, 
                                 start_date=start_date, end_date=end_date, period=period)

    @retry_policy
    def fetch_fina_indicator(self, ts_code=None, ann_date=None, start_date=None, end_date=None, period=None):
        """è´¢åŠ¡æŒ‡æ ‡è¡¨ [cite: 753-754]"""
        return self.pro.fina_indicator(ts_code=ts_code, ann_date=ann_date, 
                                       start_date=start_date, end_date=end_date, period=period)

# å•ä¾‹æ¨¡å¼
ts_client = TushareClient()

------------------------------------------------------------
FILE PATH: tools/audit_system.py
------------------------------------------------------------
import sys
import os
import pandas as pd
from sqlalchemy import func, text

# è·¯å¾„è®¾ç½®
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from database.models import SessionLocal, StockBasic, ODSMarketDaily, ODSFinanceReport
from core.mapping import SOURCE_TABLE_MAP

class DataAuditor:
    def __init__(self):
        self.db = SessionLocal()
        print("\nâš–ï¸ === Invest System æ•°æ®å®¡è®¡ä¸­å¿ƒ V1.0 ===")

    def audit_market_data(self):
        """å®¡è®¡è¡Œæƒ…è¿ç»­æ€§"""
        print("\n[1. è¡Œæƒ…è¿ç»­æ€§å®¡è®¡]")
        # ç»Ÿè®¡ Universe ä¸­æ¯åªè‚¡ç¥¨çš„è®°å½•æ•°
        query = self.db.query(
            ODSMarketDaily.ts_code, 
            func.count(ODSMarketDaily.trade_date).label('count'),
            func.min(ODSMarketDaily.trade_date).label('start'),
            func.max(ODSMarketDaily.trade_date).label('end')
        ).group_by(ODSMarketDaily.ts_code).all()

        if not query:
            print("  âš ï¸ ODS Market è¡¨ä¸ºç©ºï¼Œè¯·å…ˆè¿è¡ŒåŒæ­¥ã€‚")
            return

        df = pd.DataFrame(query)
        print(f"  - è¦†ç›–æ ‡çš„æ€»æ•°: {len(df)}")
        # æ‰¾å‡ºè®°å½•æ•°æ˜¾è‘—åå°‘çš„æ ‡çš„ (ä¾‹å¦‚å°‘äº 100 è¡Œ)
        gaps = df[df['count'] < 100]
        if not gaps.empty:
            print(f"  - âš ï¸ è­¦å‘Š: å‘ç° {len(gaps)} åªè‚¡ç¥¨è®°å½•ä¸¥é‡ä¸è¶³ (å°‘äº 100 å¤©)ã€‚")

    def audit_financial_completeness(self):
        """å®¡è®¡è´¢åŠ¡æŠ¥è¡¨é½å¤‡æ€§ (å››å¤§é‡‘åˆš)"""
        print("\n[2. è´¢åŠ¡æŠ¥è¡¨é½å¤‡æ€§å®¡è®¡ (PRD 1.3 2015+ æ ‡å‡†)]")
        
        # ä¿®æ”¹ç‚¹ï¼šå¢åŠ æ—¥æœŸè¿‡æ»¤ï¼Œç¡®ä¿ä¸å®¡è®¡ 2015 ä¹‹å‰çš„æ— æ•ˆæ•°æ®
        query = text("""
            WITH report_stats AS (
                SELECT ts_code, end_date, COUNT(DISTINCT category) as cat_count
                FROM ods_finance_report
                WHERE report_type = '1' AND end_date >= '20150101'
                GROUP BY ts_code, end_date
            )
            SELECT 
                COUNT(*) as total_reports,
                SUM(CASE WHEN cat_count = 4 THEN 1 ELSE 0 END) as perfect_reports
            FROM report_stats
        """)
        
        res = self.db.execute(query).fetchone()
        total = res.total_reports
        perfect = res.perfect_reports or 0
        health_rate = (perfect / total * 100) if total > 0 else 0
        
        print(f"  - å®¡è®¡æŠ¥å‘ŠæœŸæ€»æ•°: {total}")
        print(f"  - å®Œæ•´æŠ¥å‘ŠæœŸ (4/4): {perfect}")
        print(f"  - 2015åè´¢åŠ¡åº•åº§å¥åº·åº¦: {health_rate:.2f}%")
        
        if health_rate < 100:
            # å±•ç¤ºçœŸæ­£çš„ 2015 åçš„å¼‚å¸¸
            error_query = text("""
                SELECT ts_code, end_date, COUNT(DISTINCT category) as cat_count
                FROM ods_finance_report
                WHERE report_type = '1' AND end_date >= '20150101'
                GROUP BY ts_code, end_date
                HAVING COUNT(DISTINCT category) < 4
                LIMIT 5
            """)
            errors = self.db.execute(error_query).fetchall()
            if errors:
                print(f"  âŒ å‘ç° {total - perfect} ç»„å¼‚å¸¸ï¼Œæ ·æœ¬å¦‚ä¸‹:")
                for r in errors:
                    print(f"    - {r.ts_code} [{r.end_date}]: ä»…æœ‰ {r.cat_count}/4")

    def run_full_audit(self):
        try:
            self.audit_market_data()
            self.audit_financial_completeness()
        finally:
            self.db.close()
            print("\n" + "="*40)

if __name__ == "__main__":
    auditor = DataAuditor()
    auditor.run_full_audit()

------------------------------------------------------------
FILE PATH: tools/db_inspector.py
------------------------------------------------------------
import sys
import os
import pandas as pd
from sqlalchemy import text, func, distinct
from datetime import datetime

# Path setup
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from database.models import (
    SessionLocal, StockBasic, Watchlist, 
    ODSMarketDaily, ODSFinanceReport, 
    DWSMarketIndicators, DWSFinanceStd
)

class DBInspectorV2:
    def __init__(self):
        self.db = SessionLocal()
        print(f"\nğŸ©º === Invest System DB Inspector V2.0 (Funnel Edition) ===")
        print(f"ğŸ“… Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("="*60)

    def close(self):
        self.db.close()

    def _get_universe_count(self):
        """Helper to get universe set size"""
        csi800_count = self.db.query(StockBasic).filter(StockBasic.is_csi800 == True).count()
        watchlist_count = self.db.query(Watchlist).count()
        # Note: Set union size logic is complex in SQL without subqueries, 
        # listing counts separately is enough for inspection.
        return csi800_count, watchlist_count

    def check_asset_structure(self):
        """1. æ£€æŸ¥èµ„äº§æ„æˆ (Universe Structure)"""
        print("\n[1. Asset Universe Structure]")
        
        total_stocks = self.db.query(StockBasic).count()
        csi800, watchlist = self._get_universe_count()
        
        print(f"  - ğŸ¢ Total Stocks Listed: {total_stocks}")
        print(f"  - ğŸ’ CSI 800 Components:  {csi800}  (Target: ~800)")
        print(f"  - ğŸŒŸ User Watchlist:      {watchlist}")
        
        if csi800 == 0:
            print("  âš ï¸ CRITICAL: CSI 800 not marked! Run 'updater.sync_stock_list()' ASAP.")
        else:
            print("  âœ… Core Assets marked.")

    def check_data_density(self):
        """2. æ£€æŸ¥æ•°æ®å¯†åº¦ (Data Density)"""
        print("\n[2. Data Layer Density]")
        
        counts = {
            "ODS Market (Rows)": self.db.query(ODSMarketDaily).count(),
            "ODS Finance (Reports)": self.db.query(ODSFinanceReport).count(),
            "DWS Market (Indicators)": self.db.query(DWSMarketIndicators).count(),
            "DWS Finance (Std Rows)": self.db.query(DWSFinanceStd).count()
        }
        
        for k, v in counts.items():
            print(f"  - {k:<25}: {v}")

    def check_funnel_health(self):
        """3. æ¼æ–—æœºåˆ¶éªŒè¯ (Funnel Validation)"""
        print("\n[3. Funnel Mechanism Check]")
        
        # Logic: Pick a non-universe stock and ensure it has NO financial data
        # 1. Find a stock NOT in CSI800 and NOT in Watchlist
        # This is a bit heavy for SQL, we do a simple sampling
        
        subquery = self.db.query(Watchlist.ts_code)
        sample_trash = self.db.query(StockBasic.ts_code).filter(
            StockBasic.is_csi800 == False,
            StockBasic.ts_code.not_in(subquery)
        ).limit(1).scalar()
        
        if sample_trash:
            # Check if this "trash" stock has data in ODS Finance
            junk_data = self.db.query(ODSFinanceReport).filter(ODSFinanceReport.ts_code == sample_trash).count()
            if junk_data > 0:
                print(f"  âŒ LEAK DETECTED! Non-universe stock {sample_trash} has {junk_data} financial reports.")
            else:
                print(f"  âœ… Funnel Working: Non-universe stock {sample_trash} has 0 financial reports.")
        else:
            print("  âš ï¸ Cannot verify funnel (No non-universe stocks found or DB empty).")

    def check_latest_status(self):
        """4. æœ€æ–°çŠ¶æ€ (Freshness)"""
        print("\n[4. Data Freshness]")
        
        latest_daily = self.db.query(func.max(ODSMarketDaily.trade_date)).scalar()
        latest_report = self.db.query(func.max(ODSFinanceReport.ann_date)).scalar()
        
        print(f"  - Latest Market Date:   {latest_daily or 'N/A'}")
        print(f"  - Latest Report Ann:    {latest_report or 'N/A'}")

    def run(self):
        try:
            self.check_asset_structure()
            self.check_data_density()
            self.check_funnel_health()
            self.check_latest_status()
        except Exception as e:
            print(f"âŒ Inspection Failed: {e}")
        finally:
            self.close()
        print("\n" + "="*60)

if __name__ == "__main__":
    inspector = DBInspectorV2()
    inspector.run()

------------------------------------------------------------
FILE PATH: tools/doc_generator.py
------------------------------------------------------------
import os
import datetime

# --- é…ç½®åŒºåŸŸ ---
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
OUTPUT_DIR = os.path.join(PROJECT_ROOT, 'note')

# 1. å¿½ç•¥ç›®å½•
IGNORE_DIRS = {
    'venv', '__pycache__', '.git', '.idea', '.vscode', 
    'data', 'temp', 'note', 'dist', 'build', 'logs'
}

# 2. å¿½ç•¥æ–‡ä»¶ (.env ç»å¯¹ä¸èƒ½ä¸Šä¼ !)
IGNORE_FILES = {
    '.DS_Store', 'poetry.lock', 'package-lock.json', 'LICENSE', 
    '.env', 'requirements.txt.bak'
}

# 3. å…è®¸è¯»å–åç¼€
INCLUDE_EXTENSIONS = ('.py', '.txt', '.md', '.gitignore', '.ini', '.yaml', '.yml', '.sh', '.json')

# æ–‡ä»¶æ³¨é‡Šå­—å…¸
FILE_META = {
    "requirements.txt": "Pythonä¾èµ–æ¸…å• [æ ¸å¿ƒ]",
    ".gitignore": "Gitå¿½ç•¥è§„åˆ™ [æ ¸å¿ƒ]",
    "core/config.py": "å…¨å±€é…ç½®åŠ è½½å™¨ [æ ¸å¿ƒ]",
    "core/mapping.py": "ä¸­è‹±æ–‡æ˜ å°„å­—å…¸ [æ ¸å¿ƒ]",
    "database/models.py": "SQLAlchemyæ•°æ®åº“æ¨¡å‹(ODS/DWS) [æ ¸å¿ƒ]",
    "interface/tushare_client.py": "Tushareæ¥å£å°è£…(å¸¦é‡è¯•) [æ ¸å¿ƒ]",
    "engine/updater.py": "æ•°æ®æ›´æ–°å¼•æ“ [æ ¸å¿ƒ]",
    "tools/doc_generator.py": "ä¸Šä¸‹æ–‡ç”Ÿæˆå·¥å…· [å·¥å…·]",
    "tools/git_auto.py": "Gitè‡ªåŠ¨åŠ©ç† [å·¥å…·]",
    "tools/db_inspector.py": "æ•°æ®åº“ä½“æ£€å·¥å…· [å·¥å…·]",
}

def get_daily_filename():
    """
    ç”Ÿæˆæ¯æ—¥å”¯ä¸€çš„ä¸Šä¸‹æ–‡æ–‡ä»¶å
    æ ¼å¼: context_mm-dd.txt
    ç­–ç•¥: æ¯æ—¥ä»…ç”Ÿæˆä¸€ä»½ï¼Œå¤šæ¬¡è¿è¡Œç›´æ¥è¦†ç›–ï¼Œé¿å…æ–‡ä»¶çˆ†ç‚¸
    """
    today = datetime.datetime.now().strftime("%m-%d")
    if not os.path.exists(OUTPUT_DIR):
        os.makedirs(OUTPUT_DIR)
    return f"context_{today}.txt"

def get_tree_str():
    """ç”Ÿæˆç›®å½•æ ‘å­—ç¬¦ä¸²"""
    lines = []
    lines.append(f"ğŸ“¦ PROJECT STRUCTURE (Ignored: .env, temp/, note/, data/)")
    lines.append(f"{'='*50}")
    
    for root, dirs, files in os.walk(PROJECT_ROOT):
        # è¿‡æ»¤ç›®å½•
        dirs[:] = [d for d in dirs if d not in IGNORE_DIRS]
        
        level = root.replace(PROJECT_ROOT, '').count(os.sep)
        indent = ' ' * 4 * level
        folder_name = os.path.basename(root)
        if folder_name == os.path.basename(PROJECT_ROOT):
            folder_name = "ROOT"
            
        lines.append(f"{indent}ğŸ“‚ {folder_name}/")
        
        for f in sorted(files):
            if f in IGNORE_FILES:
                continue
            
            # ç®€å•çš„åç¼€è¿‡æ»¤
            if not any(f.endswith(ext) for ext in INCLUDE_EXTENSIONS) and f not in FILE_META:
                continue

            rel_path = os.path.relpath(os.path.join(root, f), PROJECT_ROOT)
            meta = FILE_META.get(rel_path, "")
            desc = f"  # {meta}" if meta else ""
            
            lines.append(f"{indent}    ğŸ“„ {f}{desc}")
            
    lines.append(f"{'='*50}\n\n")
    return "\n".join(lines)

def generate_context_dump():
    """ç”Ÿæˆå•ä¸€æ•´åˆæ–‡ä»¶"""
    filename = get_daily_filename()
    filepath = os.path.join(OUTPUT_DIR, filename)
    
    tree_str = get_tree_str()
    
    with open(filepath, 'w', encoding='utf-8') as outfile:
        # Header
        outfile.write(f"# INVEST SYSTEM CONTEXT DUMP\n")
        outfile.write(f"# Timestamp: {datetime.datetime.now()}\n")
        outfile.write(f"# Security: Sensitive files (.env) and temp dirs are EXCLUDED.\n\n")
        
        # Part 1: Tree
        outfile.write(tree_str)
        
        # Part 2: Content
        outfile.write(f"ğŸ’» CODE CONTENT\n")
        outfile.write(f"{'='*50}\n")
        
        file_count = 0
        for root, dirs, files in os.walk(PROJECT_ROOT):
            dirs[:] = [d for d in dirs if d not in IGNORE_DIRS]
            
            for f in sorted(files):
                if f in IGNORE_FILES or not f.endswith(INCLUDE_EXTENSIONS):
                    continue
                
                abs_path = os.path.join(root, f)
                rel_path = os.path.relpath(abs_path, PROJECT_ROOT)
                
                outfile.write(f"\n{'-'*60}\n")
                outfile.write(f"FILE PATH: {rel_path}\n")
                outfile.write(f"{'-'*60}\n")
                
                try:
                    with open(abs_path, 'r', encoding='utf-8') as infile:
                        content = infile.read()
                        outfile.write(content)
                        outfile.write("\n")
                        file_count += 1
                except Exception as e:
                    outfile.write(f"[Error reading file: {e}]\n")

    print(f"âœ… ä¸Šä¸‹æ–‡å¿«ç…§å·²æ›´æ–°: note/{filename}")
    print(f"ğŸ›¡ï¸ å·²å±è”½ .env åŠä¸´æ—¶ç›®å½• | åŒ…å« {file_count} ä¸ªæ ¸å¿ƒæ–‡ä»¶")

if __name__ == "__main__":
    generate_context_dump()

------------------------------------------------------------
FILE PATH: tools/git_auto.py
------------------------------------------------------------
import os
import sys
import subprocess
from datetime import datetime

# --- é…ç½® ---
BRANCH = "main"
DOC_GEN_SCRIPT = "tools/doc_generator.py"

def run_cmd(cmd, desc, ignore_error=False):
    """æ‰§è¡Œç³»ç»Ÿå‘½ä»¤"""
    try:
        # capture_output=False è®©å‘½ä»¤è¾“å‡ºç›´æ¥æ˜¾ç¤ºåœ¨å±å¹•ä¸Š
        result = subprocess.run(cmd, shell=True, check=True, text=True, capture_output=False)
        return True
    except subprocess.CalledProcessError as e:
        if not ignore_error:
            print(f"âŒ æ‰§è¡Œå¤±è´¥ [{desc}]: {e}")
        return False

def get_cmd_output(cmd):
    """è·å–å‘½ä»¤è¿”å›çš„æ–‡æœ¬ (é™é»˜æ‰§è¡Œ)"""
    try:
        result = subprocess.run(cmd, shell=True, check=True, text=True, capture_output=True)
        return result.stdout.strip()
    except subprocess.CalledProcessError:
        return ""

def auto_save():
    """åŠŸèƒ½ 1: ä¿å­˜è¿›åº¦"""
    print("\nğŸ’¾ --- æ­£åœ¨ä¿å­˜è¿›åº¦ ---")
    
    # 1. ç”Ÿæˆå¿«ç…§
    if os.path.exists(DOC_GEN_SCRIPT):
        print("1ï¸âƒ£ æ›´æ–° AI ä¸Šä¸‹æ–‡å¿«ç…§...")
        run_cmd(f"python3 {DOC_GEN_SCRIPT}", "ç”Ÿæˆæ–‡æ¡£", ignore_error=True)
    
    # 2. Add
    run_cmd("git add .", "æ·»åŠ æ–‡ä»¶(git add)")
    
    # 3. Commit å‰çš„æ£€æŸ¥
    status_short = get_cmd_output("git status --short")
    if not status_short:
        print("âš ï¸ å½“å‰æ²¡æœ‰æ–‡ä»¶å˜åŠ¨ï¼Œæ— éœ€æäº¤ã€‚")
        # å³ä½¿æ²¡æœ‰å˜åŠ¨ï¼Œå¦‚æœäº‘ç«¯æ»åï¼Œç”¨æˆ·å¯èƒ½åªæƒ³ pushï¼Œæ‰€ä»¥ä¸ç›´æ¥ return
        # ä½†é€šå¸¸ save æ˜¯ä¸ºäº†å­˜æ–°ä¸œè¥¿ã€‚è¿™é‡Œæˆ‘ä»¬ç»§ç»­èµ°ï¼Œæ–¹ä¾¿å•çº¯çš„ push æ“ä½œã€‚
    else:
        print("\nğŸ“ æ£€æµ‹åˆ°ä»¥ä¸‹æ–‡ä»¶å˜åŠ¨ï¼š")
        print("-" * 30)
        print(status_short)
        print("-" * 30)

        # 4. è·å–å¤‡æ³¨
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M')
        default_msg = f"è‡ªåŠ¨å­˜æ¡£: {timestamp}"
        
        print(f"ğŸ’¡ æç¤ºï¼šè¾“å…¥å…·ä½“ä¿®æ”¹å†…å®¹å¯æ–¹ä¾¿æ—¥åå›æº¯")
        user_msg = input(f"âœï¸ æäº¤å¤‡æ³¨ (ç›´æ¥å›è½¦ = '{default_msg}'): ").strip()
        commit_msg = user_msg if user_msg else default_msg
        
        # 5. æ‰§è¡Œæäº¤
        run_cmd(f'git commit -m "{commit_msg}"', "æäº¤ä»£ç (git commit)")
    
    # 6. Push
    print("â˜ï¸ åŒæ­¥åˆ° GitHub...")
    if run_cmd(f"git push origin {BRANCH}", "æ¨é€åˆ°äº‘ç«¯(git push)", ignore_error=True):
        print(f"âœ… ä¿å­˜æˆåŠŸï¼")
    else:
        print("âš ï¸ æ™®é€šæ¨é€å¤±è´¥ï¼è¿™é€šå¸¸æ˜¯å› ä¸ºä½ å›æ»šè¿‡ç‰ˆæœ¬ã€‚")
        print("ğŸ’¡ å»ºè®®ï¼šè¯·å°è¯•ä½¿ç”¨ä¸»èœå•çš„ [4] å¼ºåˆ¶åŒæ­¥ã€‚")

def show_history():
    """åŠŸèƒ½ 2: æŸ¥çœ‹å†å²"""
    print("\nğŸ“œ --- æœ€è¿‘ 10 æ¬¡å­˜æ¡£è®°å½• ---")
    cmd = 'git log -n 10 --pretty=format:"%C(yellow)%h%Creset | %C(cyan)%cd%Creset | %s" --date=format:"%m-%d %H:%M"'
    os.system(cmd) 
    print("\n")

def time_travel():
    """åŠŸèƒ½ 3: æ—¶å…‰å€’æµ"""
    print("\nâ³ --- æ—¶å…‰å€’æµ (å±é™©åŒº) ---")
    print("æ­¤åŠŸèƒ½å¯ä»¥å°†é¡¹ç›®é‡ç½®åˆ°è¿‡å»çš„çŠ¶æ€ã€‚")
    
    confirm = input("ç¡®å®šè¦å›æ»šå—ï¼Ÿ(è¾“å…¥ y ç¡®è®¤): ").lower()
    if confirm != 'y':
        return

    timestamp_str = datetime.now().strftime('%m%d_%H%M%S')
    broken_branch = f"backup/mess_{timestamp_str}"
    
    print(f"\nğŸ›¡ï¸ æ­£åœ¨åˆ›å»ºæ•‘æ´å¤‡ä»½åˆ†æ”¯: {broken_branch} ...")
    run_cmd("git add .", "å¤‡ä»½å½“å‰çŠ¶æ€")
    
    backup_msg = f"[ç³»ç»Ÿ] é‡ç½®å‰è‡ªåŠ¨å¤‡ä»½ (æ—¶é—´: {datetime.now().strftime('%H:%M:%S')})"
    run_cmd(f'git commit -m "{backup_msg}"', "æäº¤å¤‡ä»½", ignore_error=True)
    
    run_cmd(f"git branch {broken_branch}", "åˆ›å»ºå¤‡ä»½åˆ†æ”¯")
    print(f"âœ… å½“å‰çŠ¶æ€å·²å®‰å…¨ä¿å­˜åœ¨åˆ†æ”¯ [{broken_branch}]ã€‚")

    show_history()
    target_hash = input("\nğŸ¯ è¯·è¾“å…¥ä½ è¦å›åˆ°çš„é‚£ä¸ª [Hashç ] (ä¾‹å¦‚ a1b2c3d): ").strip()
    
    if not target_hash:
        print("âŒ æœªè¾“å…¥ Hashï¼Œæ“ä½œå–æ¶ˆã€‚")
        return

    print(f"\nğŸš€ æ­£åœ¨ç©¿è¶Šå› {target_hash} ...")
    if run_cmd(f"git reset --hard {target_hash}", "ç¡¬é‡ç½®(Hard Reset)"):
        print(f"\nâœ… ç©¿è¶ŠæˆåŠŸï¼")
        print("âš ï¸ æ³¨æ„ï¼šä½ éœ€è¦ä½¿ç”¨ä¸»èœå•çš„ [4] å¼ºåˆ¶åŒæ­¥ æ‰èƒ½æŠŠè¿™ä¸ªå˜æ›´æ¨é€åˆ°äº‘ç«¯ã€‚")

def force_sync():
    """åŠŸèƒ½ 4: å¼ºåˆ¶åŒæ­¥ (æ–°å¢)"""
    print("\nâ˜¢ï¸ --- æš´åŠ›åŒæ­¥ (å¼ºåˆ¶è¦†ç›–äº‘ç«¯) ---")
    print("âš ï¸ è­¦å‘Šï¼šè¿™ä¼šå¼ºåˆ¶å°† GitHub ä¸Šçš„ä»£ç æ›¿æ¢ä¸ºä½ ç°åœ¨æœ¬åœ°çš„æ ·å­ã€‚")
    print("âš ï¸ é€‚ç”¨åœºæ™¯ï¼šå½“ä½ æ‰§è¡Œè¿‡ [æ—¶å…‰å€’æµ] åï¼Œæ™®é€šä¿å­˜æŠ¥é”™æ—¶ã€‚")
    
    confirm = input("â“ ç¡®å®šè¦æ‰§è¡Œå—ï¼Ÿ(è¾“å…¥ yes ç¡®è®¤): ").strip()
    if confirm != "yes":
        print("å·²å–æ¶ˆã€‚")
        return

    print(f"ğŸš€ æ­£åœ¨å¼ºåˆ¶æ¨é€ (Force Push) åˆ° {BRANCH} åˆ†æ”¯...")
    if run_cmd(f"git push -f origin {BRANCH}", "å¼ºåˆ¶æ¨é€"):
        print("\nâœ… äº‘ç«¯å·²å¼ºåˆ¶åŒæ­¥ï¼ç°åœ¨ GitHub å’Œä½ æœ¬åœ°å®Œå…¨ä¸€è‡´äº†ã€‚")

def main_menu():
    while True:
        print("\nğŸ¤– === Git æ™ºèƒ½åŠ©ç† (Invest System) ===")
        print("1. ğŸ’¾ ä¿å­˜è¿›åº¦ (Save)  -> æ—¥å¸¸ä½¿ç”¨")
        print("2. ğŸ“œ æŸ¥çœ‹å†å² (Log)   -> çœ‹çœ‹å¹²äº†å•¥")
        print("3. ğŸ”™ æ—¶å…‰å€’æµ (Reset) -> æ•‘å‘½ç”¨çš„")
        print("4. â˜¢ï¸ å¼ºåˆ¶åŒæ­¥ (Force) -> ä¸“æ²»æŠ¥é”™")
        print("0. ğŸšª é€€å‡º (Exit)")
        
        choice = input("ğŸ‘‰ è¯·é€‰æ‹©: ").strip()
        
        if choice == '1':
            auto_save()
        elif choice == '2':
            show_history()
        elif choice == '3':
            time_travel()
        elif choice == '4':
            force_sync()
        elif choice == '0':
            print("Bye! ğŸ‘‹")
            break
        else:
            print("æ— æ•ˆé€‰é¡¹")

if __name__ == "__main__":
    if not os.path.exists(".gitignore"):
        print("âš ï¸ é”™è¯¯ï¼šè¯·åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹è¿è¡Œæ­¤è„šæœ¬ï¼")
    else:
        main_menu()

------------------------------------------------------------
FILE PATH: tools/manage_watchlist.py
------------------------------------------------------------
import sys
import os
import argparse
from datetime import datetime

# Path setup
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from database.models import SessionLocal, StockBasic, Watchlist
from sqlalchemy.exc import IntegrityError

class WatchlistManager:
    def __init__(self):
        self.db = SessionLocal()

    def list_all(self):
        """åˆ—å‡ºå½“å‰è‡ªé€‰è‚¡"""
        stocks = self.db.query(Watchlist).all()
        print(f"\nğŸŒŸ å½“å‰è‡ªé€‰è‚¡ ({len(stocks)}):")
        print(f"{'TS Code':<12} {'Name':<10} {'Industry':<10} {'Added Time'}")
        print("-" * 50)
        for s in stocks:
            print(f"{s.ts_code:<12} {s.name:<10} {s.industry:<10} {s.add_time.strftime('%Y-%m-%d')}")
        print("-" * 50)

    def add_stock(self, ts_code_input: str):
        """æ·»åŠ è‚¡ç¥¨ (å¸¦æ ¡éªŒ)"""
        ts_code = ts_code_input.upper()
        
        # 1. æ ¡éªŒæ˜¯å¦å­˜åœ¨äºåŸºç¡€åˆ—è¡¨
        basic = self.db.query(StockBasic).filter(StockBasic.ts_code == ts_code).first()
        if not basic:
            print(f"âŒ é”™è¯¯: ä»£ç  {ts_code} ä¸å­˜åœ¨äº StockBasic è¡¨ä¸­ã€‚è¯·å…ˆè¿è¡Œ updater æ›´æ–°åˆ—è¡¨ã€‚")
            return

        # 2. æ·»åŠ åˆ° Watchlist
        try:
            new_watch = Watchlist(
                ts_code=basic.ts_code,
                name=basic.name,
                industry=basic.industry,
                weight=1.0, # é»˜è®¤æƒé‡
                add_time=datetime.now()
            )
            self.db.add(new_watch)
            self.db.commit()
            print(f"âœ… æˆåŠŸæ·»åŠ : {basic.name} ({ts_code})")
        except IntegrityError:
            self.db.rollback()
            print(f"âš ï¸ è­¦å‘Š: {ts_code} å·²ç»åœ¨è‡ªé€‰è‚¡ä¸­äº†ã€‚")

    def remove_stock(self, ts_code_input: str):
        """ç§»é™¤è‚¡ç¥¨"""
        ts_code = ts_code_input.upper()
        res = self.db.query(Watchlist).filter(Watchlist.ts_code == ts_code).delete()
        self.db.commit()
        if res:
            print(f"ğŸ—‘ï¸ å·²ç§»é™¤: {ts_code}")
        else:
            print(f"âš ï¸ æœªæ‰¾åˆ°: {ts_code}")

    def close(self):
        self.db.close()

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Invest System Watchlist Manager")
    parser.add_argument("-l", "--list", action="store_true", help="List all watchlist stocks")
    parser.add_argument("-a", "--add", type=str, help="Add a stock by TS_CODE (e.g., 600519.SH)")
    parser.add_argument("-r", "--remove", type=str, help="Remove a stock by TS_CODE")
    
    args = parser.parse_args()
    
    wm = WatchlistManager()
    
    if args.add:
        wm.add_stock(args.add)
    elif args.remove:
        wm.remove_stock(args.remove)
    elif args.list:
        wm.list_all()
    else:
        parser.print_help()
    
    wm.close()

------------------------------------------------------------
FILE PATH: tools/report_exporter.py
------------------------------------------------------------
import pandas as pd
import os
import sys
from sqlalchemy import text

# è·¯å¾„è®¾ç½®ï¼šç¡®ä¿å¯ä»¥å¯¼å…¥ database å’Œ core æ¨¡å—
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from database.models import SessionLocal, StockBasic, DWSMarketIndicators, DWSFinanceStd
from core.mapping import FIELD_MAPPING

class ReportFactory:
    def __init__(self, ts_code: str):
        self.ts_code = ts_code
        self.db = SessionLocal()
        self.stock = self.db.query(StockBasic).filter(StockBasic.ts_code == ts_code).first()

    def _calculate_shield_metrics(self, df_f: pd.DataFrame):
        """
        [ğŸ›¡ï¸ç›¾] ç»´åº¦ï¼šæ ¸å¿ƒé£é™©æŒ‡æ ‡äºŒæ¬¡è®¡ç®—
        """
        if df_f.empty:
            return df_f
        
        # 1. è®¡ç®—å‡€ç°æ¯” (ç»è¥ç°é‡‘æµ / å½’æ¯å‡€åˆ©æ¶¦)
        # å¤„ç†åˆ†æ¯ä¸º0çš„æƒ…å†µ
        df_f['ocf_to_profit'] = df_f.apply(
            lambda x: x['n_cashflow_act'] / x['n_income_attr_p'] if x['n_income_attr_p'] and x['n_income_attr_p'] != 0 else 0, 
            axis=1
        )
        
        # 2. è®¡ç®—å•†èª‰å æ¯” (å•†èª‰ / æ€»èµ„äº§)
        # æ³¨æ„ï¼šæ­¤å¤„éœ€ç¡®ä¿ DWSFinanceStd åŒ…å« goodwill å’Œ total_assets
        if 'goodwill' in df_f.columns and 'total_assets' in df_f.columns:
            df_f['goodwill_to_assets'] = df_f['goodwill'] / df_f['total_assets']
            
        return df_f

    def fetch_full_dataset(self):
        """æŠ“å–å¹¶èšåˆäº”å¤§ç»´åº¦æ•°æ®"""
        # A. æå– DWS è´¢åŠ¡æ ‡å‡†åŒ–æ•°æ® (å« ğŸ°æ ¸ã€ğŸš€çŸ›ã€ğŸ›¡ï¸ç›¾ åŸºç¡€å­—æ®µ) [cite: 25]
        f_query = self.db.query(DWSFinanceStd).filter(DWSFinanceStd.ts_code == self.ts_code).statement
        df_f = pd.read_sql(f_query, self.db.bind).sort_values('end_date', ascending=False)
        
        # æ‰§è¡Œæ·±åº¦è¯Šæ–­è®¡ç®—
        df_f = self._calculate_shield_metrics(df_f)
        
        # B. æå– DWS è¡Œæƒ…æŒ‡æ ‡ (âš–ï¸ç§¤) [cite: 24]
        m_query = self.db.query(DWSMarketIndicators).filter(DWSMarketIndicators.ts_code == self.ts_code).statement
        df_m = pd.read_sql(m_query, self.db.bind).sort_values('trade_date', ascending=False)
        
        return df_f, df_m

    def generate_excel(self):
        """ç”Ÿæˆæ ¼å¼åŒ– Excel æŠ¥å‘Š"""
        if not self.stock:
            print(f"âŒ é”™è¯¯ï¼šæœªåœ¨æ•°æ®åº“ä¸­æ‰¾åˆ°æ ‡çš„ {self.ts_code}")
            return

        print(f"ğŸš€ æ­£åœ¨ä¸º [{self.stock.name}] ç”Ÿæˆäº”ç»´ç ”æŠ¥å·¥å‚æ•°æ®...")
        df_f, df_m = self.fetch_full_dataset()

        # åˆ›å»ºå¯¼å‡ºç›®å½•
        out_dir = "data/reports"
        if not os.path.exists(out_dir):
            os.makedirs(out_dir)
        file_path = f"{out_dir}/Report_{self.ts_code}_{self.stock.name}.xlsx"

        with pd.ExcelWriter(file_path, engine='openpyxl') as writer:
            # --- Sheet 1: è´¢åŠ¡è¯Šæ–­ (ğŸ›¡ï¸ç›¾ã€ğŸ°æ ¸ã€ğŸš€çŸ›) ---
            # è¿‡æ»¤ Mapping ä¸­å®šä¹‰çš„å­—æ®µè¿›è¡Œå¯¼å‡º
            available_f = [col for col in df_f.columns if col in FIELD_MAPPING]
            df_f_final = df_f[available_f].rename(columns=FIELD_MAPPING)
            df_f_final.to_excel(writer, sheet_name='åŸºæœ¬é¢è¯Šæ–­', index=False)
            
            # --- Sheet 2: ä¼°å€¼è¡Œæƒ… (âš–ï¸ç§¤) ---
            available_m = [col for col in df_m.columns if col in FIELD_MAPPING]
            df_m_final = df_m[available_m].head(500).rename(columns=FIELD_MAPPING) # å–æœ€è¿‘ä¸¤å¹´äº¤æ˜“æ—¥ [cite: 24]
            df_m_final.to_excel(writer, sheet_name='è¡Œæƒ…ä¸ä¼°å€¼', index=False)

            # --- Sheet 3: æ ‡çš„ä¿¡æ¯ (ğŸ—ï¸åŸº) ---
            df_info = pd.DataFrame([self.stock.__dict__])
            available_i = [col for col in df_info.columns if col in FIELD_MAPPING]
            df_info_final = df_info[available_i].rename(columns=FIELD_MAPPING)
            df_info_final.to_excel(writer, sheet_name='å…¬å¸åŸºçŸ³', index=False)
            
        print(f"âœ… æŠ¥å‘ŠæˆåŠŸå¯¼å‡ºè‡³: {file_path}")
        return file_path

    def close(self):
        self.db.close()

if __name__ == "__main__":
    # é’ˆå¯¹æ ¸å¿ƒæ ‡çš„è¿›è¡ŒéªŒè¯ [cite: 4, 5]
    test_targets = ['600519.SH', '600036.SH']
    for code in test_targets:
        factory = ReportFactory(code)
        try:
            factory.generate_excel()
        finally:
            factory.close()

------------------------------------------------------------
FILE PATH: tools/reset_db.py
------------------------------------------------------------
import sys
import os

# å°†é¡¹ç›®æ ¹ç›®å½•æ·»åŠ åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from database.models import engine, Base, init_db

def perform_reset():
    print("âš ï¸ æ­£åœ¨å‡†å¤‡é‡ç½®æ•°æ®åº“...")
    confirm = input("ç¡®å®šè¦åˆ é™¤æ‰€æœ‰æ•°æ®è¡¨å¹¶é‡å»ºå—ï¼Ÿ(è¾“å…¥ 'yes' ç¡®è®¤): ")
    
    if confirm.lower() == 'yes':
        try:
            # 1. ç‰©ç†åˆ é™¤æ‰€æœ‰è¡¨
            print("æ­£åœ¨åˆ é™¤æ—§è¡¨...")
            Base.metadata.drop_all(bind=engine)
            
            # 2. è°ƒç”¨æ¨¡å‹ä¸­çš„åˆå§‹åŒ–å‡½æ•°åˆ›å»ºæ–°è¡¨ 
            print("æ­£åœ¨æ ¹æ®æ–°æ¨¡å‹åˆ›å»ºè¡¨ç»“æ„...")
            init_db()
            
            print("âœ… æ•°æ®åº“é‡ç½®å®Œæˆï¼æ–°çš„ä¸»é”®çº¦æŸå·²ç”Ÿæ•ˆã€‚")
        except Exception as e:
            print(f"âŒ é‡ç½®å¤±è´¥: {e}")
    else:
        print("æ“ä½œå·²å–æ¶ˆã€‚")

if __name__ == "__main__":
    perform_reset()

------------------------------------------------------------
FILE PATH: core/config.py
------------------------------------------------------------
import os
from dotenv import load_dotenv

# åŠ è½½ .env æ–‡ä»¶
load_dotenv()

class Config:
    # åŸºç¡€é‰´æƒ
    TS_TOKEN = os.getenv("TS_TOKEN")
    DB_URL = os.getenv("DB_URL")
    
    # ç³»ç»Ÿå¸¸é‡ (PRD 1.3)
    START_DATE = "20150101"
    
    # å®Œæ•´æ€§æ£€æŸ¥
    if not TS_TOKEN:
        raise ValueError("âŒ é”™è¯¯: æœªåœ¨ .env ä¸­æ‰¾åˆ° TS_TOKENï¼Œè¯·æ£€æŸ¥é…ç½®æ–‡ä»¶ã€‚")
    if not DB_URL:
        raise ValueError("âŒ é”™è¯¯: æœªåœ¨ .env ä¸­æ‰¾åˆ° DB_URLï¼Œè¯·æ£€æŸ¥é…ç½®æ–‡ä»¶ã€‚")

settings = Config()

------------------------------------------------------------
FILE PATH: core/mapping.py
------------------------------------------------------------
# core/mapping.py

# ==============================================================================
# INVEST SYSTEM MASTER MAPPING V7.1 - æ ¸å¿ƒæ˜ å°„çŸ©é˜µ
# ==============================================================================

# 1. ä¸šåŠ¡æœ¯è¯­æ ‡å‡†åŒ–æ˜ å°„ (ç”¨äº UIã€Excel å¯¼å‡ºåŠå®¡è®¡)
# ä¸¥æ ¼éµå¾ªäº”å¤§ç»´åº¦åˆ†ç±»ï¼šğŸ—ï¸åŸºã€ğŸ›¡ï¸ç›¾ã€ğŸ°æ ¸ã€ğŸš€çŸ›ã€âš–ï¸ç§¤
FIELD_MAPPING = {
    # --- ğŸ—ï¸åŸº (Base: åŸºç¡€ä¿¡æ¯) ---
    "ts_code": "TSä»£ç ",
    "symbol": "è‚¡ç¥¨ä»£ç ",
    "name": "è‚¡ç¥¨åç§°",
    "industry": "æ‰€å±è¡Œä¸š",
    "area": "åœ°åŸŸ",
    "list_date": "ä¸Šå¸‚æ—¥æœŸ",
    "is_csi800": "ä¸­è¯800",

    # --- ğŸ›¡ï¸ç›¾ (Shield: é£é™©æ’é›·) ---
    "debt_to_assets": "èµ„äº§è´Ÿå€ºç‡(%)",
    "current_ratio": "æµåŠ¨æ¯”ç‡",
    "quick_ratio": "é€ŸåŠ¨æ¯”ç‡",
    "ocf_to_profit": "å‡€ç°æ¯”(ç»è¥ç°é‡‘æµ/å‡€åˆ©æ¶¦)",  # æ ¸å¿ƒæ’é›·ï¼šé˜²æ­¢åˆ©æ¶¦é€ å‡
    "goodwill": "å•†èª‰",
    "goodwill_to_assets": "å•†èª‰å æ€»èµ„äº§æ¯”(%)",      # æ’é™¤é¸µé¸Ÿèµ„äº§é£é™©
    "intan_assets": "æ— å½¢èµ„äº§",
    "money_cap": "è´§å¸èµ„é‡‘",
    "st_borr": "çŸ­æœŸå€Ÿæ¬¾",

    # --- ğŸ°æ ¸ (Core: å•†ä¸šå£å’ä¸ç›ˆåˆ©) ---
    "roe": "ROE(å‡€èµ„äº§æ”¶ç›Šç‡)",
    "roe_dt": "ROE(æ‰£é)",
    "grossprofit_margin": "æ¯›åˆ©ç‡(%)",
    "netprofit_margin": "å‡€åˆ©ç‡(%)",
    "roic": "ROIC(æŠ•å…¥èµ„æœ¬å›æŠ¥ç‡)",
    "asset_turn": "æ€»èµ„äº§å‘¨è½¬ç‡",
    "n_income_attr_p": "å½’æ¯å‡€åˆ©æ¶¦",
    "ocf_to_net_profit": "å‡€ç°æ¯”(ç°é‡‘æµ/å‡€åˆ©)",
    "toxic_asset_ratio": "åƒåœ¾èµ„äº§å æ¯”(%)",
    "goodwill_net_asset_ratio": "å•†èª‰å æ¯”(%)",
    "ar_rev_gap": "åº”æ”¶è¥æ”¶å¢é€Ÿå·®(%)",
    "selection_reason": "å…¥é€‰ç†ç”±/é£é™©æç¤º",

    # --- ğŸš€çŸ› (Spear: æˆé•¿é©±åŠ¨) ---
    "tr_yoy": "è¥æ”¶åŒæ¯”å¢é•¿(%)",
    "netprofit_yoy": "å‡€åˆ©åŒæ¯”å¢é•¿(%)",
    "dt_netprofit_yoy": "æ‰£éå‡€åˆ©åŒæ¯”å¢é•¿(%)",
    "contract_liab": "åˆåŒè´Ÿå€º(è“„æ°´æ± )",
    "total_revenue": "è¥ä¸šæ€»æ”¶å…¥",
    "revenue": "è¥ä¸šæ”¶å…¥",

    # --- âš–ï¸ç§¤ (Scale: ä¼°å€¼ä¸è¡Œæƒ…) ---
    "trade_date": "äº¤æ˜“æ—¥æœŸ",
    "close_qfq": "å‰å¤æƒæ”¶ç›˜ä»·",
    "pe_ttm": "å¸‚ç›ˆç‡(TTM)",
    "pb": "å¸‚å‡€ç‡",
    "total_mv": "æ€»å¸‚å€¼(ä¸‡)",
    "turnover_rate": "æ¢æ‰‹ç‡(%)",
    "ma_20": "20æ—¥å‡çº¿",
    "ma_250": "250æ—¥å‡çº¿(å¹´çº¿)",
    "pct_chg": "æ¶¨è·Œå¹…(%)",
    "vol": "æˆäº¤é‡(æ‰‹)",
    "amount": "æˆäº¤é¢(åƒå…ƒ)",
}

# 2. è¡Œä¸šæ„ŸçŸ¥æå–è§„åˆ™ (è§£å†³è·¨è¡¨å­—æ®µå¯¹é½çš„å…³é”®é€»è¾‘) 
# é€»è¾‘ï¼šå½“ç³»ç»Ÿè®¡ç®—æ ‡å‡†åŒ–è´¢åŠ¡å®½è¡¨æ—¶ï¼Œæ ¹æ® industry å­—æ®µåŠ¨æ€é€‰æ‹© ODS åŸå§‹å­—æ®µ
FINANCE_EXTRACT_PIPELINE = {
    "General": { # ä¸€èˆ¬å·¥å•†ä¸š
        "revenue": ["revenue"],
        "n_income": ["n_income_attr_p"],
        "cash_flow": ["n_cashflow_act"]
    },
    "Bank": { # é“¶è¡Œ
        "revenue": ["int_income", "comm_income", "n_oth_b_income"], # æ”¶å…¥ = åˆ©æ¯æ”¶å…¥+ä½£é‡‘æ”¶å…¥+å…¶ä»–
        "n_income": ["n_income_attr_p"],
        "cash_flow": ["n_cashflow_act"]
    },
    "Insurance": { # ä¿é™©
        "revenue": ["prem_earned"], # å·²èµšä¿è´¹
        "n_income": ["n_income_attr_p"],
    },
    "Securities": { # è¯åˆ¸
        "revenue": ["n_sec_tb_income", "n_sec_uw_income"], # ä»£ç†ä¹°å–è¯åˆ¸+æ‰¿é”€
        "n_income": ["n_income_attr_p"],
    }
}

# 3. æ¥å£å½’å±æ˜ å°„ (å®¡è®¡ç³»ç»Ÿä¸ ReportFactory ä½¿ç”¨ï¼šç¡®å®šå­—æ®µæ¥æº) [cite: 983]
SOURCE_TABLE_MAP = {
    "income": ["revenue", "int_income", "n_income_attr_p", "prem_earned", "total_revenue"],
    "balancesheet": ["total_assets", "total_liab", "money_cap", "goodwill", "intan_assets", "contract_liab", "st_borr"],
    "cashflow": ["n_cashflow_act", "n_cashflow_fnc_act"],
    "fina_indicator": ["roe", "debt_to_assets", "grossprofit_margin", "netprofit_margin", "current_ratio", "quick_ratio", "roic"]
}

# 4. æŠ¥è¡¨ç±»å‹æ˜ å°„ (ç”¨äºæ•°æ®æ¸…æ´—è¿‡æ»¤) [cite: 1566, 1604, 1627]
REPORT_TYPE_MAP = {
    "1": "åˆå¹¶æŠ¥è¡¨",
    "6": "æ¯å…¬å¸æŠ¥è¡¨",
    "11": "è°ƒæ•´å‰åˆå¹¶æŠ¥è¡¨"
}

------------------------------------------------------------
FILE PATH: engine/radar.py
------------------------------------------------------------
# FILE PATH: engine/radar.py
import pandas as pd
from sqlalchemy import text, func
from database.models import SessionLocal, StockBasic, DWSMarketIndicators, DWSFinanceStd

class RadarEngine:
    def __init__(self):
        self.db = SessionLocal()

    def query(self, 
              min_roe=8.0,           # æ ¸å¿ƒï¼šROE æ‰£é
              max_pe=30.0,           # ä¼°å€¼ï¼šPE(TTM)
              max_pb=3.0,            # ä¼°å€¼ï¼šPB
              min_mv=100.0,          # è§„æ¨¡ï¼šæ€»å¸‚å€¼(äº¿)
              max_debt=60.0,         # é£é™©ï¼šè´Ÿå€ºç‡
              trend_up=True,         # è¶‹åŠ¿ï¼šæ”¶ç›˜ > MA20
              pool='CSI800'          # èŒƒå›´ï¼šCSI800 / Watchlist / All
              ):
        """
        [PRD 3.2] é€‰è‚¡é›·è¾¾æ ¸å¿ƒç­›é€‰é€»è¾‘
        """
        # 1. è·å–æ•°æ®åº“æœ€æ–°è¡Œæƒ…æ—¥æœŸ (T-1 åè§†é•œ)
        latest_date = self.db.query(func.max(DWSMarketIndicators.trade_date)).scalar()
        if not latest_date:
            return pd.DataFrame()

        # 2. æ„å»ºä¸‰è¡¨å…³è”æŸ¥è¯¢ (SQL æ¨¡å¼ä»¥æå‡æ€§èƒ½)
        # å…³è”: Basic(B) -> Indicators(I) -> Finance(F)
        # æ³¨æ„: Finance å–æœ€è¿‘ä¸€ä¸ªæŠ¥å‘ŠæœŸ (end_date)
        # --- æ¶æ„çº§ä¿®å¤ï¼šè”æ¥ ODS è·å–åŸå§‹æ¶¨è·Œå¹… ---
        sql = text("""
            SELECT 
                b.ts_code, b.name, b.industry,
                i.trade_date, i.close_qfq, i.pe_ttm, i.pb, i.total_mv, i.ma_20,
                m.pct_chg,
                f.end_date as last_report, 
                COALESCE(f.roe, 0) as roe, -- è¿™é‡Œæš‚æ—¶å– f.roeï¼Œæˆ‘ä»¬å°†ä¿®æ”¹ process_finance_dws æ¥å¡«å……å®ƒ
                f.debt_to_assets,
                -- V7.4 ä¾¦æ¢æŒ‡æ ‡è®¡ç®— 
                COALESCE(f.n_cashflow_act / NULLIF(f.n_income_attr_p, 0), 0) as ocf_to_net_profit,
                -- åƒåœ¾èµ„äº§æ¯”: (å…¶ä»–åº”æ”¶+é¢„ä»˜) / æ€»èµ„äº§
                COALESCE((f.oth_receiv + f.prepayment) / NULLIF(f.total_assets, 0), 0) as toxic_asset_ratio,
                -- å•†èª‰å æ¯”: å•†èª‰ / å½’æ¯å‡€èµ„äº§
                COALESCE(f.goodwill / NULLIF(f.total_hldr_eqy_exc_min_int, 0), 0) as goodwill_net_asset_ratio
            FROM stock_basic b
            JOIN dws_market_indicators i ON b.ts_code = i.ts_code
            JOIN ods_market_daily m ON i.ts_code = m.ts_code AND i.trade_date = m.trade_date
            LEFT JOIN (
                SELECT DISTINCT ON (ts_code) *
                FROM dws_finance_std
                ORDER BY ts_code, end_date DESC
            ) f ON b.ts_code = f.ts_code
            WHERE i.trade_date = :t_date
            AND (:pool = 'All' OR 
                (:pool = 'CSI800' AND b.is_csi800 = True) OR
                (:pool = 'Watchlist' AND b.ts_code IN (SELECT ts_code FROM watchlist))
            )
        """)

        df = pd.read_sql(sql, self.db.bind, params={"t_date": latest_date, "pool": pool})
        if df.empty: return df

        # --- æ¶æ„çº§ä¿®å¤ï¼šå¤„ç†ç©ºå€¼é˜²æ­¢è¯¯æ€ ---
        # å°† ROE ç¼ºå¤±å¡«å……ä¸º 0ï¼Œè´Ÿå€ºç‡ç¼ºå¤±å¡«å……ä¸º 0 (ä»£è¡¨é£é™©æœªçŸ¥ä½†ä¸æ‹¦æˆª)
        df['roe'] = df['roe'].fillna(0)
        df['debt_to_assets'] = df['debt_to_assets'].fillna(0)
        df['pe_ttm'] = df['pe_ttm'].fillna(999) # PE ç¼ºå¤±åˆ™è®¾ä¸ºæå¤§å€¼æ‹¦æˆª
        df['ocf_to_net_profit'] = df['ocf_to_net_profit'].fillna(0)
        df['toxic_asset_ratio'] = df['toxic_asset_ratio'].fillna(0)
        df['goodwill_net_asset_ratio'] = df['goodwill_net_asset_ratio'].fillna(0)

        # 3. æ‰§è¡Œå¤šå› å­è¿‡æ»¤
        mask = (
            (df['pe_ttm'] > 0) & (df['pe_ttm'] < max_pe) &
            (df['pb'] < max_pb) &
            (df['total_mv'] >= min_mv * 10000) & # äº¿å…ƒè½¬ä¸‡å…ƒ
            (df['roe'] >= min_roe) &
            (df['debt_to_assets'] <= max_debt) &
            (df['ocf_to_net_profit'] >= 0.8) & 
            (df['toxic_asset_ratio'] < 0.05) & 
            (df['goodwill_net_asset_ratio'] < 0.25)
        )
        
        if trend_up:
            mask = mask & (df['close_qfq'] > df['ma_20'])

        result = df[mask].copy()

        # --- V7.4 åŠ¨æ€ç†ç”±ç”Ÿæˆ ---
        def generate_reason(row):
            reasons = []
            # äº®ç‚¹æŒ–æ˜
            if row['roe'] >= 20: reasons.append("é«˜ROE(>20%)")
            if row['ocf_to_net_profit'] >= 1.2: reasons.append("ç°é‡‘å«é‡æé«˜")
            
            # é£é™©æç¤º
            if row['goodwill_net_asset_ratio'] > 0.2: reasons.append("âš å•†èª‰åé«˜")
            if row['toxic_asset_ratio'] > 0.04: reasons.append("âš èµ„äº§æˆè‰²ä¸€èˆ¬")
            
            return " | ".join(reasons) if reasons else "å¤šå› å­å‡è¡¡"

        result['selection_reason'] = result.apply(generate_reason, axis=1)
        
        # æ ¼å¼åŒ–è¾“å‡º
        result['total_mv_unit'] = (result['total_mv'] / 10000).round(2) # è½¬å›äº¿å…ƒæ˜¾ç¤º
        
        # ç»Ÿä¸€ä¿ç•™ä¸¤ä½å°æ•°
        numeric_cols = result.select_dtypes(include=['number']).columns
        result[numeric_cols] = result[numeric_cols].round(2)

        return result.sort_values('roe', ascending=False)

    def close(self):
        self.db.close()

------------------------------------------------------------
FILE PATH: engine/updater.py
------------------------------------------------------------
import pandas as pd
import time
from datetime import datetime, timedelta
from sqlalchemy import text
from interface.tushare_client import ts_client
from database.models import (
    SessionLocal, StockBasic, Watchlist, 
    ODSMarketDaily, ODSAdjFactor, ODSFinanceReport, 
    DWSMarketIndicators, DWSFinanceStd, ODSDailyBasic
)
from core.mapping import SOURCE_TABLE_MAP

class DataUpdater:
    def __init__(self):
        self.db = SessionLocal()

    def close(self):
        self.db.close()

    def _get_universe_pool(self) -> set:
        """[PRD 1.2] è·å–ä¸­è¯800+è‡ªé€‰è‚¡çš„å¹¶é›†"""
        csi800 = self.db.query(StockBasic.ts_code).filter(StockBasic.is_csi800 == True).all()
        watchlist = self.db.query(Watchlist.ts_code).all()
        pool = {row.ts_code for row in csi800} | {row.ts_code for row in watchlist}
        return pool

    def sync_stock_list(self):
        """[PRD 3.1] å…¨é‡åŒæ­¥è‚¡ç¥¨åˆ—è¡¨å¹¶æ ‡è®°ä¸­è¯800 (UI é€‚é…ç‰ˆ)"""
        yield "ğŸ”„ æ­£åœ¨ä» Tushare è·å–å…¨å¸‚åœºåŸºç¡€åˆ—è¡¨..."
        df_basics = ts_client.fetch_stock_basic()
        if df_basics.empty: 
            yield "âŒ è·å–å¤±è´¥ï¼šTushare è¿”å›ä¸ºç©ºã€‚"
            return

        yield "ğŸ’ æ­£åœ¨è·å–ä¸­è¯800æœ€æ–°æˆåˆ†è‚¡åå•..."
        try:
            now_str = datetime.now().strftime("%Y%m%d")
            df_csi800 = ts_client.pro.index_weight(index_code='000906.SH', start_date='20240101', end_date=now_str)
            if not df_csi800.empty:
                latest_date = df_csi800['trade_date'].max()
                csi800_set = set(df_csi800[df_csi800['trade_date'] == latest_date]['con_code'].tolist())
            else:
                csi800_set = set()
        except Exception as e:
            yield f"âš ï¸ æŒ‡æ•°è·å–å¼‚å¸¸: {e}"
            csi800_set = set()

        yield f"ğŸ“¥ æ­£åœ¨å†™å…¥æ•°æ®åº“ (å…± {len(df_basics)} æ¡è®°å½•)..."
        for _, row in df_basics.iterrows():
            is_in_index = row['ts_code'] in csi800_set
            stock = StockBasic(
                ts_code=row['ts_code'], symbol=row['symbol'], name=row['name'],
                area=row['area'], industry=row['industry'], market=row['market'],
                list_date=row['list_date'], is_csi800=is_in_index
            )
            self.db.merge(stock)
        
        self.db.commit()
        yield f"âœ… è‚¡ç¥¨åˆ—è¡¨åŒæ­¥å®Œæˆï¼å·²è¯†åˆ«ä¸­è¯800æˆåˆ†è‚¡: {len(csi800_set)} åªã€‚"

    # --- åœºæ™¯ S1/S2/S5: å‚ç›´å†å²å›æº¯ (æŒ‰ä»£ç åŒæ­¥) ---

    def run_watchlist_backfill(self):
        """
        [PRD S1/S2] è‡ªé€‰è‚¡è¡Œæƒ…ä¸è´¢æŠ¥æ·±åº¦ä¿®è¡¥
        é€»è¾‘ï¼šé’ˆå¯¹ Watchlist ä¸­çš„æ ‡çš„ï¼Œä» 20150101 èµ·æ‰§è¡Œå‚ç›´åŒæ­¥ 
        """
        watchlist = self.db.query(Watchlist.ts_code).all()
        targets = [r.ts_code for r in watchlist]
        
        if not targets:
            yield "âš ï¸ è‡ªé€‰æ± ä¸ºç©ºï¼Œè¯·å…ˆåœ¨é¡µé¢æ·»åŠ æ ‡çš„ã€‚"
            return

        total = len(targets)
        yield f"ğŸš€ å¯åŠ¨è‡ªé€‰æ± æ·±åº¦åŒæ­¥ï¼šå…± {total} åªæ ‡çš„"

        for i, ts_code in enumerate(targets):
            yield f"æ­£åœ¨å¤„ç† [{i+1}/{total}]: {ts_code}"
            try:
                # 1. æ‰§è¡Œ ODS å±‚å‚ç›´æ‹‰å– (è¡Œæƒ…+è´¢æŠ¥)
                self.sync_stock_history(ts_code, start_date="20150101")
                
                # 2. æ‰§è¡Œ DWS å±‚æ•°æ®ç‚¼åˆ¶ (è®¡ç®—å‡çº¿ä¸æ ‡å‡†åŒ–è´¢æŠ¥)
                self.process_market_dws(ts_code)
                self.process_finance_dws(ts_code)
                
                # 3. 2000 ç§¯åˆ†é¢‘æ¬¡ä¿æŠ¤ï¼šæ¯æ¬¡åŒæ­¥åä¼‘çœ  0.3s-0.5s [cite: 1635]
                time.sleep(0.3)
            except Exception as e:
                yield f"âŒ {ts_code} åŒæ­¥å¤±è´¥: {str(e)}"
                continue
        
        yield "âœ… è‡ªé€‰æ± å†å²æ•°æ®ä¿®å¤å®Œæˆã€‚"

    def sync_stock_history(self, ts_code: str, start_date="20150101"):
        """è¡¥å…¨å•åªè‚¡ç¥¨çš„æ‰€æœ‰å†å²æ•°æ® (ODS å±‚)"""
        # A. è¡Œæƒ…æ•°æ®åŒæ­¥
        df_daily = ts_client.fetch_daily(ts_code=ts_code, start_date=start_date)
        if not df_daily.empty:
            for _, row in df_daily.iterrows():
                self.db.merge(ODSMarketDaily(
                    ts_code=row['ts_code'], trade_date=row['trade_date'],
                    open=row['open'], high=row['high'], low=row['low'], close=row['close'],
                    pre_close=row['pre_close'], change=row['change'], pct_chg=row['pct_chg'],
                    vol=row['vol'], amount=row['amount']
                ))

        # B. å¤æƒå› å­åŒæ­¥ [cite: 1760]
        df_adj = ts_client.fetch_adj_factor(ts_code=ts_code, start_date=start_date)
        if not df_adj.empty:
            for _, row in df_adj.iterrows():
                self.db.merge(ODSAdjFactor(ts_code=row['ts_code'], trade_date=row['trade_date'], adj_factor=row['adj_factor']))

        # C. æ¯æ—¥æŒ‡æ ‡åŒæ­¥ (PE/PB/å¸‚å€¼) [cite: 1766]
        df_basic = ts_client.pro.daily_basic(ts_code=ts_code, start_date=start_date)
        if not df_basic.empty:
            for _, row in df_basic.iterrows():
                self.db.merge(ODSDailyBasic(
                    ts_code=row['ts_code'], trade_date=row['trade_date'],
                    pe_ttm=row.get('pe_ttm'), pb=row.get('pb'), 
                    turnover_rate=row.get('turnover_rate'), total_mv=row.get('total_mv')
                ))

        # D. å››å¤§è´¢æŠ¥åŒæ­¥ (JSONB å­˜å‚¨) [cite: 1761]
        tasks = {
            "income": ts_client.fetch_income,
            "balancesheet": ts_client.fetch_balancesheet,
            "cashflow": ts_client.fetch_cashflow,
            "fina_indicator": ts_client.fetch_fina_indicator
        }
        for category, api_func in tasks.items():
            df = api_func(ts_code=ts_code, start_date=start_date)
            if df is not None and not df.empty:
                # --- æ¶æ„çº§ä¿®å¤ï¼šåŠ¨æ€æ£€æµ‹ä¸»é”® --- 
                # ç†æƒ³çš„ä¸»é”®å€™é€‰ï¼Œä½†éœ€å…¼å®¹ä¸åŒæ¥å£çš„å­—æ®µå·®å¼‚
                pk_candidates = ['ts_code', 'end_date', 'report_type', 'update_flag']
                actual_pk = [col for col in pk_candidates if col in df.columns]
                
                # æ‰§è¡Œå®‰å…¨å»é‡ï¼šæ ¹æ®å­˜åœ¨çš„å­—æ®µä¿ç•™æœ€æ–°ä¸€æ¡ 
                df = df.drop_duplicates(subset=actual_pk, keep='last')

                # å¤„ç† NaN å¹¶åœ¨å­—å…¸è½¬æ¢æ—¶å¡«å…… Noneï¼Œé˜²æ­¢ JSONB å†™å…¥æŠ¥é”™ 
                df = df.astype(object).where(pd.notnull(df), None)
                
                for record in df.to_dict('records'):
                    # å†™å…¥ ODS æ—¶ä½¿ç”¨ .get() å…œåº•å¯é€‰å­—æ®µ [cite: 864-865]
                    self.db.merge(ODSFinanceReport(
                        ts_code=record['ts_code'], 
                        end_date=record['end_date'],
                        # é»˜è®¤åˆå¹¶æŠ¥è¡¨(1)å’Œåˆå§‹æ•°æ®(0)ä»¥å¯¹é½æ•°æ®åº“æ¨¡å‹è¦æ±‚ [cite: 769, 864]
                        report_type=str(record.get('report_type', '1')), 
                        update_flag=str(record.get('update_flag', '0')), 
                        category=category, 
                        data=record, 
                        ann_date=record.get('ann_date')
                    ))
                self.db.commit() # æ¯ä¸€ç±»æŠ¥è¡¨æäº¤ä¸€æ¬¡ï¼Œç¼©å°å†²çªèŒƒå›´ [cite: 865]

    # --- åœºæ™¯ S3: æ°´å¹³æ¯æ—¥è¡Œæƒ… (æŒ‰æ—¥æœŸåŒæ­¥) ---

    def sync_daily_market(self, trade_date: str):
        """[PRD S3] æ¯æ—¥å¢é‡è¡Œæƒ…åŒæ­¥ (æ°´å¹³æ¨¡å¼)"""
        universe = self._get_universe_pool()
        if not universe: return

        try:
            # 1. Fetch Full Market
            df_daily = ts_client.fetch_daily(trade_date=trade_date)
            df_adj = ts_client.fetch_adj_factor(trade_date=trade_date)
            
            if df_daily.empty: return

            # 2. Funnel Filter
            df_daily_filtered = df_daily[df_daily['ts_code'].isin(universe)]
            
            # 3. Save ODS
            for _, row in df_daily_filtered.iterrows():
                self.db.merge(ODSMarketDaily(
                    ts_code=row['ts_code'], trade_date=row['trade_date'],
                    open=row['open'], high=row['high'], low=row['low'], close=row['close'],
                    pre_close=row['pre_close'], change=row['change'], pct_chg=row['pct_chg'],
                    vol=row['vol'], amount=row['amount']
                ))

            if not df_adj.empty:
                df_adj_filtered = df_adj[df_adj['ts_code'].isin(universe)]
                for _, row in df_adj_filtered.iterrows():
                    self.db.merge(ODSAdjFactor(
                        ts_code=row['ts_code'], trade_date=row['trade_date'],
                        adj_factor=row['adj_factor']
                    ))

            self.db.commit()
            print(f"  âœ… Market Snapshot {trade_date}: Saved {len(df_daily_filtered)} records.")

        except Exception as e:
            self.db.rollback()
            print(f"  âŒ Market Snapshot Failed: {e}")

    # --- åœºæ™¯ S4: æ°´å¹³æ¯æ—¥è´¢æŠ¥ (æŒ‰å…¬å‘Šæ—¥åŒæ­¥) ---

    def sync_financial_daily(self, ann_date: str):
        """
        [PRD S4 ä¿®æ­£ç‰ˆ] æ¯æ—¥å¢é‡è´¢æŠ¥åŒæ­¥
        é’ˆå¯¹ 2000 ç§¯åˆ†ä¼˜åŒ–ï¼šé€šè¿‡æŠ«éœ²è®¡åˆ’åæŸ¥ä¸ªè‚¡ï¼Œé¿å…å…¨å¸‚åœºæ‹‰å–æŠ¥é”™
        """
        universe = self._get_universe_pool()
        if not universe:
            return

        try:
            # 1. è·å–å½“æ—¥å®é™…æŠ«éœ²è´¢æŠ¥çš„åå• (actual_date)
            # Ref: Tushare PDF 
            df_ann = ts_client.pro.disclosure_date(actual_date=ann_date)
            if df_ann.empty:
                yield f"  â˜• {ann_date} æ— è´¢æŠ¥æŠ«éœ²ã€‚"
                return

            # 2. ç­›é€‰å‡ºå±äºæˆ‘ä»¬ Universe çš„æ ‡çš„
            targets = df_ann[df_ann['ts_code'].isin(universe)]['ts_code'].unique().tolist()
            
            if not targets:
                yield f"  â˜• {ann_date} æŠ«éœ²çš„ {len(df_ann)} å®¶å…¬å¸å‡ä¸åœ¨æ ¸å¿ƒæ± ä¸­ã€‚"
                return

            yield f"  ğŸ“¢ å‘ç° {len(targets)} åªæ ¸å¿ƒæ ‡çš„æŠ«éœ²è´¢æŠ¥ï¼Œå¼€å§‹ç²¾å‡†åŒæ­¥..."

            # 3. é€ä¸ªåŒæ­¥ä¸ªè‚¡è´¢æŠ¥ (å¤ç”¨ S1/S2 çš„å‚ç›´åŒæ­¥é€»è¾‘)
            for i, ts_code in enumerate(targets):
                yield f"    > [{i+1}/{len(targets)}] åŒæ­¥è´¢æŠ¥: {ts_code}"
                # æ­¤å¤„ä»…åŒæ­¥å…¬å‘Šæ—¥å‰åçš„æ•°æ®å³å¯ï¼Œä¸ºä¿é™©èµ·è§åŒæ­¥æœ€è¿‘ä¸€å¹´
                # start_date è®¾ä¸ºå…¬å‘Šæ—¥å‰ä¸€å¹´
                sync_start = (datetime.strptime(ann_date, "%Y%m%d") - timedelta(days=365)).strftime("%Y%m%d")
                self.sync_stock_history(ts_code, start_date=sync_start)
                
                # é¢‘æ¬¡ä¿æŠ¤
                time.sleep(0.2)

            self.db.commit()
            yield f"  âœ… {ann_date} è´¢æŠ¥å¢é‡åŒæ­¥å®Œæˆã€‚"

        except Exception as e:
            self.db.rollback()
            yield f"  âŒ è´¢æŠ¥å¢é‡åŒæ­¥å¤±è´¥: {str(e)}"

    # --- DWS è®¡ç®—é€»è¾‘ ---

    def process_market_dws(self, ts_code: str):
        """DWS: è®¡ç®—å‡çº¿ã€QFQ å¹¶è¡¥å…¨åŸºæœ¬é¢æŒ‡æ ‡"""
        # 1. è”åˆæŸ¥è¯¢ ODS è¡Œæƒ…å’Œæ¯æ—¥æŒ‡æ ‡ (daily_basic)
        query = text("""
            SELECT m.*, b.pe_ttm, b.pb, b.total_mv, b.turnover_rate, a.adj_factor
            FROM ods_market_daily m
            LEFT JOIN ods_daily_basic b ON m.ts_code = b.ts_code AND m.trade_date = b.trade_date
            LEFT JOIN ods_adj_factor a ON m.ts_code = a.ts_code AND m.trade_date = a.trade_date
            WHERE m.ts_code = :ts_code
            ORDER BY m.trade_date
        """)
        
        df = pd.read_sql(query, self.db.bind, params={"ts_code": ts_code})
        if df.empty: return

        # 2. è®¡ç®—å‰å¤æƒ
        df['adj_factor'] = df['adj_factor'].ffill()
        latest_factor = df['adj_factor'].iloc[-1] if not df['adj_factor'].isnull().all() else 1.0
        df['close_qfq'] = df['close'] * (df['adj_factor'] / latest_factor)

        # 3. è®¡ç®—å‡çº¿ [cite: 843]
        for ma in [20, 50, 120, 250, 850]:
            df[f'ma_{ma}'] = df['close_qfq'].rolling(window=ma, min_periods=ma).mean()

        # 4. Upsert å†™å…¥ DWS
        for _, row in df.iterrows():
            self.db.merge(DWSMarketIndicators(
                ts_code=row['ts_code'],
                trade_date=row['trade_date'],
                pe_ttm=row.get('pe_ttm'),
                pb=row.get('pb'),
                total_mv=row.get('total_mv'),
                turnover_rate=row.get('turnover_rate'),
                close_qfq=row['close_qfq'],
                ma_20=row['ma_20'] if pd.notna(row['ma_20']) else None,
                ma_50=row['ma_50'] if pd.notna(row['ma_50']) else None,
                ma_120=row['ma_120'] if pd.notna(row['ma_120']) else None,
                ma_250=row['ma_250'] if pd.notna(row['ma_250']) else None,
                ma_850=row['ma_850'] if pd.notna(row['ma_850']) else None,
            ))
        self.db.commit()

    def process_finance_dws(self, ts_code: str):
        """[æ ¸å¿ƒä¿®å¤] ç‚¼åˆ¶æ—¶è‡ªåŠ¨åˆå¹¶ roe ä¸ roe_dtï¼Œå¹¶è®¡ç®—å®¡è®¡æŒ‡æ ‡"""
        reports = self.db.query(ODSFinanceReport).filter(
            ODSFinanceReport.ts_code == ts_code,
            ODSFinanceReport.report_type == '1'
        ).all()
        
        merged = {}
        for r in reports:
            end_date = r.end_date
            if end_date not in merged:
                merged[end_date] = {"ann_date": r.ann_date}
            
            data = r.data
            # æå–åŸºç¡€å­—æ®µ
            fields = [
                'revenue', 'n_income_attr_p', 'n_cashflow_act', 'grossprofit_margin',
                'oth_receiv', 'prepayment', 'goodwill', 'total_assets', 'total_hldr_eqy_exc_min_int',
                'debt_to_assets', 'roe', 'roe_dt', 'total_liab'
            ]
            for k in fields:
                if k in data and data[k] is not None:
                    merged[end_date][k] = data[k]
        
        for end_date, m in merged.items():
            # å¿…é¡»æœ‰å…¬å‘Šæ—¥æœŸæ‰èƒ½è¿›è¡Œåç»­çš„ merge_asof [cite: 847]
            if not m.get('ann_date'): continue 
            
            # 1. å‡†å¤‡è®¡ç®—æ•°æ® (åˆ©ç”¨ .get å®¹é”™)
            net_profit = m.get('n_income_attr_p', 0) or 0
            ocf = m.get('n_cashflow_act', 0) or 0
            oth_receiv = m.get('oth_receiv', 0) or 0
            prepay = m.get('prepayment', 0) or 0
            assets = m.get('total_assets', 0) or 0
            goodwill = m.get('goodwill', 0) or 0
            equity = m.get('total_hldr_eqy_exc_min_int', 0) or 0
            
            # 2. è®¡ç®—å®¡è®¡æŒ‡æ ‡
            # å‡€ç°æ¯”
            ocf_ratio = ocf / net_profit if net_profit and net_profit != 0 else 0
            # åƒåœ¾èµ„äº§å æ¯”
            toxic_ratio = (oth_receiv + prepay) / assets if assets and assets != 0 else 0
            # å•†èª‰å æ¯”
            gw_ratio = goodwill / equity if equity and equity != 0 else 0
            
            # 3. è´Ÿå€ºç‡å¤šè·¯å¾„æå–
            debt_ratio = m.get('debt_to_assets')
            if debt_ratio is None:
                liab = m.get('total_liab')
                if liab and assets and assets != 0:
                    debt_ratio = (liab / assets) * 100
            
            # 4. ROE ä¼˜å…ˆçº§
            roe_final = m.get('roe_dt') if m.get('roe_dt') is not None else m.get('roe')

            self.db.merge(DWSFinanceStd(
                ts_code=ts_code, end_date=end_date, ann_date=m.get('ann_date'),
                revenue=m.get('revenue'),
                n_income_attr_p=m.get('n_income_attr_p'),
                n_cashflow_act=m.get('n_cashflow_act'),
                debt_to_assets=debt_ratio,
                roe=roe_final,
                grossprofit_margin=m.get('grossprofit_margin'),
                oth_receiv=m.get('oth_receiv'),
                prepayment=m.get('prepayment'),
                goodwill=m.get('goodwill'),
                total_assets=m.get('total_assets'),
                total_hldr_eqy_exc_min_int=m.get('total_hldr_eqy_exc_min_int'),
                # å­˜å…¥ç‰©ç†å­—æ®µ
                ocf_to_net_profit=round(ocf_ratio, 4),
                toxic_asset_ratio=round(toxic_ratio, 4),
                goodwill_net_asset_ratio=round(gw_ratio, 4)
            ))
        self.db.commit()

    # --- è°ƒåº¦å™¨ (æ”¯æŒè¿›åº¦è¿”å›) ---

    def run_full_backfill(self, start_date="20150101"):
        """[PRD S5] æ ¸å¿ƒæ± è´¢åŠ¡ä¸è¡Œæƒ…å…¨é‡åˆå§‹åŒ–"""
        yield "ğŸš€ å¼€å§‹å…¨é‡å›æº¯ (Full Backfill)..."
        yield from self.sync_stock_list()
        
        universe = list(self._get_universe_pool())
        total = len(universe)
        
        for i, ts_code in enumerate(universe):
            # ä½¿ç”¨ yield è®©å‰ç«¯ NiceGUI å¯ä»¥å®æ—¶æ›´æ–°è¿›åº¦æ¡ [cite: 107-108]
            yield f"æ­£åœ¨è¡¥å…¨ç¬¬ {i+1}/{total} åª: {ts_code}"
            try:
                self.sync_stock_history(ts_code, start_date)
                # DWS Calculation
                self.process_market_dws(ts_code)
                self.process_finance_dws(ts_code)
                time.sleep(0.1) # é¢‘æ¬¡ä¿æŠ¤
            except Exception as e:
                yield f"âš ï¸ {ts_code} åŒæ­¥å¤±è´¥: {str(e)}"
        yield "âœ… å…¨é‡å›æº¯ä»»åŠ¡å®Œæˆ"

    def run_daily_routine(self):
        """
        [PRD S3/S4 è¿›åŒ–ç‰ˆ] è‡ªåŠ¨åŒºé—´è¡¥å…¨æ—¥æ›´
        é€»è¾‘ï¼šè‡ªåŠ¨è®¡ç®—æ–­æ¡£æœŸå¹¶å¾ªç¯è¡¥å…¨ï¼Œç¡®ä¿éš”å‘¨/éš”æœˆæ›´æ–°ä¸æ¼æ•°æ®
        """
        # 1. ç¡®å®šè¡¥å…¨åŒºé—´
        # æŸ¥æ‰¾æœ¬åœ°æœ€æ–°è¡Œæƒ…æ—¥æœŸä½œä¸ºèµ·ç‚¹
        res = self.db.execute(text("SELECT max(trade_date) FROM ods_market_daily")).fetchone()
        last_date_str = res[0] if res and res[0] else "20241201" # é»˜è®¤å›æº¯èµ·ç‚¹
        
        start_date = (datetime.strptime(last_date_str, "%Y%m%d") + timedelta(days=1))
        end_date = datetime.now()
        
        # è·å–æœŸé—´æ‰€æœ‰äº¤æ˜“æ—¥ (é¿å…éäº¤æ˜“æ—¥æŠ¥é”™)
        # æ³¨æ„ï¼šè¿™é‡Œè°ƒç”¨ tushare äº¤æ˜“æ—¥å†æ¥å£
        cal = ts_client.pro.trade_cal(exchange='', start_date=start_date.strftime('%Y%m%d'), 
                                     end_date=end_date.strftime('%Y%m%d'), is_open='1')
        trade_days = cal['cal_date'].tolist()

        if not trade_days:
            yield "â˜• æ•°æ®å·²æ˜¯æœ€æ–°ï¼Œæ— éœ€æ›´æ–°ã€‚"
            return

        yield f"ğŸš€ å‘ç° {len(trade_days)} ä¸ªäº¤æ˜“æ—¥å¾…è¡¥å…¨: {trade_days[0]} -> {trade_days[-1]}"

        # 2. æ ¸å¿ƒåŒæ­¥å¾ªç¯
        for date_str in trade_days:
            yield f"ğŸ“… æ­£åœ¨å¤„ç†: {date_str} ..."
            
            # A. åŒæ­¥å…¨å¸‚åœºè¡Œæƒ… (S3) 
            self.sync_daily_market(date_str)
            
            # B. åŒæ­¥æ¯æ—¥æŒ‡æ ‡ (PE/PB/å¸‚å€¼) - ä¿®æ­£ï¼šéœ€æ‰‹åŠ¨æ·»åŠ  horizontal æ¨¡å¼
            yield f"  > æ‹‰å–æ¯æ—¥æŒ‡æ ‡ (PE/PB)..."
            df_basic = ts_client.pro.daily_basic(trade_date=date_str)
            if not df_basic.empty:
                # ä»…å­˜ universe å†…çš„
                universe = self._get_universe_pool()
                df_target = df_basic[df_basic['ts_code'].isin(universe)]
                for _, row in df_target.iterrows():
                    self.db.merge(ODSDailyBasic(
                        ts_code=row['ts_code'], trade_date=row['trade_date'],
                        pe_ttm=row.get('pe_ttm'), pb=row.get('pb'),
                        total_mv=row.get('total_mv'), turnover_rate=row.get('turnover_rate')
                    ))
            
            # C. æ£€æŸ¥å¹¶åŒæ­¥å½“æ—¥æŠ«éœ²çš„è´¢æŠ¥ (S4 ä¿®æ­£ç‰ˆ)
            # è¿™é‡Œè°ƒç”¨ä¸Šä¸€å¼ æŒ‡ä»¤å¡ä¿®å¤åçš„ sync_financial_daily
            # ç”±äº sync_financial_daily æ˜¯ç”Ÿæˆå™¨ï¼Œéœ€è¦éå†å®ƒ
            for msg in self.sync_financial_daily(date_str):
                yield f"    {msg}"
            
            self.db.commit()
            time.sleep(0.5) # 2000ç§¯åˆ†é¢‘æ¬¡ä¿æŠ¤ [cite: 345]

        # 3. ç»Ÿä¸€è§¦å‘ DWS é‡ç‚¼ [cite: 140]
        yield "ğŸ”„ æ­£åœ¨é‡æ–°ç‚¼åˆ¶ DWS è¡ç”ŸæŒ‡æ ‡..."
        universe = list(self._get_universe_pool())
        for i, ts_code in enumerate(universe):
            self.process_market_dws(ts_code)
            self.process_finance_dws(ts_code)
            if i % 100 == 0:
                yield f"  > ç‚¼åˆ¶è¿›åº¦: {i}/{len(universe)}"
        
        yield "âœ… å…¨åŒºé—´æ•°æ®è¡¥å…¨å¹¶ç‚¼åˆ¶å®Œæˆï¼"

if __name__ == "__main__":
    u = DataUpdater()
    # u.sync_stock_list()
    u.close()
